## Content of LTCAL032
``````

## Content of LTCAL032
``````

## Content of LTCAL042
``````

## Content of LTCAL032
``````

## Content of LTCAL042
``````

## Content of LTDRG031
``````

## Content of LTCAL032
``````

## Content of LTCAL032
``````

## Content of LTCAL042
``````

## Content of LTCAL032
``````

## Content of LTCAL042
``````

## Content of LTDRG031
``````

## Content of 01_transaction_data_import
``````

## Content of 01_transaction_data_import
``````

## Content of 02_data_quality_cleaning
``````

## Content of 01_transaction_data_import
``````

## Content of 02_data_quality_cleaning
``````

## Content of 03_feature_engineering
``````

## Content of 01_transaction_data_import
``````

## Content of 02_data_quality_cleaning
``````

## Content of 03_feature_engineering
``````

## Content of 04_rule_based_detection
``````

## Content of 01_transaction_data_import
``````

## Content of 02_data_quality_cleaning
``````

## Content of 03_feature_engineering
``````

## Content of 04_rule_based_detection
``````

## Content of 05_ml_scoring_model
``````

## Content of 01_transaction_data_import
``````

## Content of 02_data_quality_cleaning
``````

## Content of 03_feature_engineering
``````

## Content of 04_rule_based_detection
``````

## Content of 05_ml_scoring_model
``````

## Content of 06_case_management_output
``````

## Content of 01_transaction_data_import
``````

## Content of 01_transaction_data_import
``````

## Content of 02_data_quality_cleaning
``````

## Content of 01_transaction_data_import
``````

## Content of 02_data_quality_cleaning
``````

## Content of 03_feature_engineering
``````

## Content of 01_transaction_data_import
``````

## Content of 02_data_quality_cleaning
``````

## Content of 03_feature_engineering
``````

## Content of 04_rule_based_detection
``````

## Content of 01_transaction_data_import
``````

## Content of 02_data_quality_cleaning
``````

## Content of 03_feature_engineering
``````

## Content of 04_rule_based_detection
``````

## Content of 05_ml_scoring_model
``````

## Content of 01_transaction_data_import
``````

## Content of 02_data_quality_cleaning
``````

## Content of 03_feature_engineering
``````

## Content of 04_rule_based_detection
``````

## Content of 05_ml_scoring_model
``````

## Content of 06_case_management_output
``````

## Content of 01_transaction_data_import
``````

## Content of 01_transaction_data_import
``````

## Content of 02_data_quality_cleaning
``````

## Content of 01_transaction_data_import
``````

## Content of 02_data_quality_cleaning
``````

## Content of 03_feature_engineering
``````

## Content of 01_transaction_data_import
``````

## Content of 02_data_quality_cleaning
``````

## Content of 03_feature_engineering
``````

## Content of 04_rule_based_detection
``````

## Content of 01_transaction_data_import
``````

## Content of 02_data_quality_cleaning
``````

## Content of 03_feature_engineering
``````

## Content of 04_rule_based_detection
``````

## Content of 05_ml_scoring_model
``````

## Content of 01_transaction_data_import
``````

## Content of 02_data_quality_cleaning
``````

## Content of 03_feature_engineering
``````

## Content of 04_rule_based_detection
``````

## Content of 05_ml_scoring_model
``````

## Content of 06_case_management_output
``````

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 02_data_quality_cleaning
```sas
/*******************************************************************************
* Program: 02_data_quality_cleaning.sas
* Purpose: Clean and standardize transaction data
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Clean transaction data */
%macro CLEAN_TRANSACTIONS(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Standardize transaction type */
        length transaction_type_clean $20;
        transaction_type_clean = UPCASE(STRIP(transaction_type));

        /* Clean merchant name */
        length merchant_name_clean $100;
        merchant_name_clean = PROPCASE(STRIP(merchant_name));

        /* Standardize country code */
        length country_code_clean $2;
        country_code_clean = UPCASE(SUBSTR(country_code, 1, 2));

        /* Handle missing amounts - replace with 0 */
        if missing(amount) then amount = 0;

        /* Convert transaction date to SAS date */
        if NOT missing(transaction_date) then do;
            transaction_date_sas = INPUT(transaction_date, YYMMDD10.);
            FORMAT transaction_date_sas DATE9.;
        end;

        /* Create transaction timestamp */
        transaction_datetime = DHMS(transaction_date_sas, 
                                   HOUR(transaction_time), 
                                   MINUTE(transaction_time), 
                                   SECOND(transaction_time));
        FORMAT transaction_datetime DATETIME20.;

    RUN;

    %PUT NOTE: Cleaned &inds to &outds;

%mend CLEAN_TRANSACTIONS;

/* MACRO 2: Remove duplicates */
%macro REMOVE_DUPLICATES(inds=, outds=, key=);

    /* Sort by key */
    PROC SORT DATA=&inds OUT=&outds NODUPKEY;
        BY &key;
    RUN;

    /* Log duplicate removal */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :before_count FROM &inds;
        SELECT COUNT(*) INTO :after_count FROM &outds;
    QUIT;

    %let dup_count = %EVAL(&before_count - &after_count);
    %PUT NOTE: Removed &dup_count duplicate records;

%mend REMOVE_DUPLICATES;

/* MACRO 3: Handle outliers */
%macro HANDLE_OUTLIERS(inds=, outds=, var=, method=WINSORIZE);

    /* Calculate percentiles */
    PROC MEANS DATA=&inds NOPRINT;
        VAR &var;
        OUTPUT OUT=percentiles
            P1=p1 P99=p99;
    RUN;

    /* Get percentile values */
    DATA _NULL_;
        SET percentiles;
        CALL SYMPUTX('p1_value', p1);
        CALL SYMPUTX('p99_value', p99);
    RUN;

    /* Apply outlier handling */
    DATA &outds;
        SET &inds;

        %if &method = WINSORIZE %then %do;
            /* Winsorize: Cap at 1st and 99th percentiles */
            if &var < &p1_value then &var = &p1_value;
            else if &var > &p99_value then &var = &p99_value;
        %end;
        %else %if &method = REMOVE %then %do;
            /* Remove outliers */
            if &var >= &p1_value AND &var <= &p99_value;
        %end;

    RUN;

    %PUT NOTE: Handled outliers in &var using &method method;

%mend HANDLE_OUTLIERS;

/* Execute cleaning pipeline */
%CLEAN_TRANSACTIONS(
    inds=&input_lib..transactions_validated,
    outds=&output_lib..transactions_cleaned
);

%REMOVE_DUPLICATES(
    inds=&output_lib..transactions_cleaned,
    outds=&output_lib..transactions_deduped,
    key=transaction_id
);

%HANDLE_OUTLIERS(
    inds=&output_lib..transactions_deduped,
    outds=&output_lib..transactions_final,
    var=amount,
    method=WINSORIZE
);

/* Display results */
PROC MEANS DATA=&output_lib..transactions_final N MEAN STD MIN MAX;
    VAR amount;
    TITLE 'Transaction Amount Statistics After Cleaning';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 02_data_quality_cleaning
```sas
/*******************************************************************************
* Program: 02_data_quality_cleaning.sas
* Purpose: Clean and standardize transaction data
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Clean transaction data */
%macro CLEAN_TRANSACTIONS(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Standardize transaction type */
        length transaction_type_clean $20;
        transaction_type_clean = UPCASE(STRIP(transaction_type));

        /* Clean merchant name */
        length merchant_name_clean $100;
        merchant_name_clean = PROPCASE(STRIP(merchant_name));

        /* Standardize country code */
        length country_code_clean $2;
        country_code_clean = UPCASE(SUBSTR(country_code, 1, 2));

        /* Handle missing amounts - replace with 0 */
        if missing(amount) then amount = 0;

        /* Convert transaction date to SAS date */
        if NOT missing(transaction_date) then do;
            transaction_date_sas = INPUT(transaction_date, YYMMDD10.);
            FORMAT transaction_date_sas DATE9.;
        end;

        /* Create transaction timestamp */
        transaction_datetime = DHMS(transaction_date_sas, 
                                   HOUR(transaction_time), 
                                   MINUTE(transaction_time), 
                                   SECOND(transaction_time));
        FORMAT transaction_datetime DATETIME20.;

    RUN;

    %PUT NOTE: Cleaned &inds to &outds;

%mend CLEAN_TRANSACTIONS;

/* MACRO 2: Remove duplicates */
%macro REMOVE_DUPLICATES(inds=, outds=, key=);

    /* Sort by key */
    PROC SORT DATA=&inds OUT=&outds NODUPKEY;
        BY &key;
    RUN;

    /* Log duplicate removal */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :before_count FROM &inds;
        SELECT COUNT(*) INTO :after_count FROM &outds;
    QUIT;

    %let dup_count = %EVAL(&before_count - &after_count);
    %PUT NOTE: Removed &dup_count duplicate records;

%mend REMOVE_DUPLICATES;

/* MACRO 3: Handle outliers */
%macro HANDLE_OUTLIERS(inds=, outds=, var=, method=WINSORIZE);

    /* Calculate percentiles */
    PROC MEANS DATA=&inds NOPRINT;
        VAR &var;
        OUTPUT OUT=percentiles
            P1=p1 P99=p99;
    RUN;

    /* Get percentile values */
    DATA _NULL_;
        SET percentiles;
        CALL SYMPUTX('p1_value', p1);
        CALL SYMPUTX('p99_value', p99);
    RUN;

    /* Apply outlier handling */
    DATA &outds;
        SET &inds;

        %if &method = WINSORIZE %then %do;
            /* Winsorize: Cap at 1st and 99th percentiles */
            if &var < &p1_value then &var = &p1_value;
            else if &var > &p99_value then &var = &p99_value;
        %end;
        %else %if &method = REMOVE %then %do;
            /* Remove outliers */
            if &var >= &p1_value AND &var <= &p99_value;
        %end;

    RUN;

    %PUT NOTE: Handled outliers in &var using &method method;

%mend HANDLE_OUTLIERS;

/* Execute cleaning pipeline */
%CLEAN_TRANSACTIONS(
    inds=&input_lib..transactions_validated,
    outds=&output_lib..transactions_cleaned
);

%REMOVE_DUPLICATES(
    inds=&output_lib..transactions_cleaned,
    outds=&output_lib..transactions_deduped,
    key=transaction_id
);

%HANDLE_OUTLIERS(
    inds=&output_lib..transactions_deduped,
    outds=&output_lib..transactions_final,
    var=amount,
    method=WINSORIZE
);

/* Display results */
PROC MEANS DATA=&output_lib..transactions_final N MEAN STD MIN MAX;
    VAR amount;
    TITLE 'Transaction Amount Statistics After Cleaning';
RUN;
```

## Content of 03_feature_engineering
```sas
/*******************************************************************************
* Program: 03_feature_engineering.sas
* Purpose: Create features for fraud detection
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Calculate velocity features */
%macro CALCULATE_VELOCITY(inds=, outds=, window_days=7);

    /* Sort by customer and date */
    PROC SORT DATA=&inds;
        BY customer_id transaction_date_sas transaction_time;
    RUN;

    /* Calculate velocity features */
    DATA &outds;
        SET &inds;
        BY customer_id;

        /* Retain variables for calculations */
        RETAIN txn_count_&window_days.d 0
               txn_amount_&window_days.d 0
               last_txn_date .;

        /* Reset on new customer */
        if FIRST.customer_id then do;
            txn_count_&window_days.d = 0;
            txn_amount_&window_days.d = 0;
            last_txn_date = .;
        end;

        /* Calculate days since last transaction */
        if NOT missing(last_txn_date) then 
            days_since_last_txn = transaction_date_sas - last_txn_date;
        else 
            days_since_last_txn = .;

        /* Update counters (rolling window) */
        if NOT missing(last_txn_date) then do;
            if days_since_last_txn <= &window_days then do;
                txn_count_&window_days.d + 1;
                txn_amount_&window_days.d + amount;
            end;
            else do;
                txn_count_&window_days.d = 1;
                txn_amount_&window_days.d = amount;
            end;
        end;
        else do;
            txn_count_&window_days.d = 1;
            txn_amount_&window_days.d = amount;
        end;

        /* Update last transaction date */
        last_txn_date = transaction_date_sas;

        /* Calculate average transaction amount in window */
        if txn_count_&window_days.d > 0 then 
            avg_txn_amount_&window_days.d = txn_amount_&window_days.d / txn_count_&window_days.d;
        else 
            avg_txn_amount_&window_days.d = 0;

        DROP last_txn_date;

    RUN;

    %PUT NOTE: Calculated velocity features for &window_days day window;

%mend CALCULATE_VELOCITY;

/* MACRO 2: Calculate amount deviation */
%macro CALCULATE_AMOUNT_DEVIATION(inds=, outds=);

    /* Calculate customer statistics */
    PROC MEANS DATA=&inds NOPRINT;
        BY customer_id;
        VAR amount;
        OUTPUT OUT=customer_stats
            MEAN=customer_avg_amount
            STD=customer_std_amount
            N=customer_txn_count;
    RUN;

    /* Merge statistics back */
    PROC SQL;
        CREATE TABLE &outds AS
        SELECT 
            a.*,
            b.customer_avg_amount,
            b.customer_std_amount,
            b.customer_txn_count,
            /* Calculate z-score */
            CASE 
                WHEN b.customer_std_amount > 0 THEN
                    (a.amount - b.customer_avg_amount) / b.customer_std_amount
                ELSE 0
            END AS amount_zscore,
            /* Calculate percentage deviation */
            CASE
                WHEN b.customer_avg_amount > 0 THEN
                    ((a.amount - b.customer_avg_amount) / b.customer_avg_amount) * 100
                ELSE 0
            END AS amount_pct_deviation
        FROM &inds a
        LEFT JOIN customer_stats b
        ON a.customer_id = b.customer_id;
    QUIT;

    %PUT NOTE: Calculated amount deviation features;

%mend CALCULATE_AMOUNT_DEVIATION;

/* MACRO 3: Create time-based features */
%macro CREATE_TIME_FEATURES(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Extract time components */
        txn_hour = HOUR(transaction_time);
        txn_day_of_week = WEEKDAY(transaction_date_sas);
        txn_day_of_month = DAY(transaction_date_sas);
        txn_month = MONTH(transaction_date_sas);

        /* Create time-of-day categories */
        length time_of_day $20;
        if txn_hour >= 0 AND txn_hour < 6 then time_of_day = 'NIGHT';
        else if txn_hour >= 6 AND txn_hour < 12 then time_of_day = 'MORNING';
        else if txn_hour >= 12 AND txn_hour < 18 then time_of_day = 'AFTERNOON';
        else time_of_day = 'EVENING';

        /* Create weekend flag */
        is_weekend = (txn_day_of_week IN (1, 7));  /* Sunday=1, Saturday=7 */

        /* Create unusual hour flag */
        is_unusual_hour = (txn_hour >= 0 AND txn_hour < 6);

    RUN;

    %PUT NOTE: Created time-based features;

%mend CREATE_TIME_FEATURES;

/* MACRO 4: Create location features */
%macro CREATE_LOCATION_FEATURES(inds=, outds=);

    /* Calculate country transaction counts */
    PROC SQL;
        CREATE TABLE country_counts AS
        SELECT 
            country_code_clean,
            COUNT(*) AS country_txn_count
        FROM &inds
        GROUP BY country_code_clean;
    QUIT;

    /* Merge back and create features */
    PROC SQL;
        CREATE TABLE &outds AS
        SELECT 
            a.*,
            b.country_txn_count,
            /* Flag for rare countries */
            CASE 
                WHEN b.country_txn_count < 10 THEN 1
                ELSE 0
            END AS is_rare_country,
            /* Check if international transaction */
            CASE
                WHEN a.country_code_clean NE 'US' THEN 1
                ELSE 0
            END AS is_international
        FROM &inds a
        LEFT JOIN country_counts b
        ON a.country_code_clean = b.country_code_clean;
    QUIT;

    %PUT NOTE: Created location-based features;

%mend CREATE_LOCATION_FEATURES;

/* Execute feature engineering pipeline */
%CALCULATE_VELOCITY(
    inds=&input_lib..transactions_final,
    outds=&output_lib..txn_with_velocity,
    window_days=7
);

%CALCULATE_AMOUNT_DEVIATION(
    inds=&output_lib..txn_with_velocity,
    outds=&output_lib..txn_with_deviation
);

%CREATE_TIME_FEATURES(
    inds=&output_lib..txn_with_deviation,
    outds=&output_lib..txn_with_time_features
);

%CREATE_LOCATION_FEATURES(
    inds=&output_lib..txn_with_time_features,
    outds=&output_lib..transactions_engineered
);

/* Display sample of engineered features */
PROC PRINT DATA=&output_lib..transactions_engineered(OBS=10);
    VAR transaction_id customer_id amount 
        txn_count_7d avg_txn_amount_7d amount_zscore
        time_of_day is_weekend is_unusual_hour;
    TITLE 'Sample of Engineered Features';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 02_data_quality_cleaning
```sas
/*******************************************************************************
* Program: 02_data_quality_cleaning.sas
* Purpose: Clean and standardize transaction data
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Clean transaction data */
%macro CLEAN_TRANSACTIONS(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Standardize transaction type */
        length transaction_type_clean $20;
        transaction_type_clean = UPCASE(STRIP(transaction_type));

        /* Clean merchant name */
        length merchant_name_clean $100;
        merchant_name_clean = PROPCASE(STRIP(merchant_name));

        /* Standardize country code */
        length country_code_clean $2;
        country_code_clean = UPCASE(SUBSTR(country_code, 1, 2));

        /* Handle missing amounts - replace with 0 */
        if missing(amount) then amount = 0;

        /* Convert transaction date to SAS date */
        if NOT missing(transaction_date) then do;
            transaction_date_sas = INPUT(transaction_date, YYMMDD10.);
            FORMAT transaction_date_sas DATE9.;
        end;

        /* Create transaction timestamp */
        transaction_datetime = DHMS(transaction_date_sas, 
                                   HOUR(transaction_time), 
                                   MINUTE(transaction_time), 
                                   SECOND(transaction_time));
        FORMAT transaction_datetime DATETIME20.;

    RUN;

    %PUT NOTE: Cleaned &inds to &outds;

%mend CLEAN_TRANSACTIONS;

/* MACRO 2: Remove duplicates */
%macro REMOVE_DUPLICATES(inds=, outds=, key=);

    /* Sort by key */
    PROC SORT DATA=&inds OUT=&outds NODUPKEY;
        BY &key;
    RUN;

    /* Log duplicate removal */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :before_count FROM &inds;
        SELECT COUNT(*) INTO :after_count FROM &outds;
    QUIT;

    %let dup_count = %EVAL(&before_count - &after_count);
    %PUT NOTE: Removed &dup_count duplicate records;

%mend REMOVE_DUPLICATES;

/* MACRO 3: Handle outliers */
%macro HANDLE_OUTLIERS(inds=, outds=, var=, method=WINSORIZE);

    /* Calculate percentiles */
    PROC MEANS DATA=&inds NOPRINT;
        VAR &var;
        OUTPUT OUT=percentiles
            P1=p1 P99=p99;
    RUN;

    /* Get percentile values */
    DATA _NULL_;
        SET percentiles;
        CALL SYMPUTX('p1_value', p1);
        CALL SYMPUTX('p99_value', p99);
    RUN;

    /* Apply outlier handling */
    DATA &outds;
        SET &inds;

        %if &method = WINSORIZE %then %do;
            /* Winsorize: Cap at 1st and 99th percentiles */
            if &var < &p1_value then &var = &p1_value;
            else if &var > &p99_value then &var = &p99_value;
        %end;
        %else %if &method = REMOVE %then %do;
            /* Remove outliers */
            if &var >= &p1_value AND &var <= &p99_value;
        %end;

    RUN;

    %PUT NOTE: Handled outliers in &var using &method method;

%mend HANDLE_OUTLIERS;

/* Execute cleaning pipeline */
%CLEAN_TRANSACTIONS(
    inds=&input_lib..transactions_validated,
    outds=&output_lib..transactions_cleaned
);

%REMOVE_DUPLICATES(
    inds=&output_lib..transactions_cleaned,
    outds=&output_lib..transactions_deduped,
    key=transaction_id
);

%HANDLE_OUTLIERS(
    inds=&output_lib..transactions_deduped,
    outds=&output_lib..transactions_final,
    var=amount,
    method=WINSORIZE
);

/* Display results */
PROC MEANS DATA=&output_lib..transactions_final N MEAN STD MIN MAX;
    VAR amount;
    TITLE 'Transaction Amount Statistics After Cleaning';
RUN;
```

## Content of 03_feature_engineering
```sas
/*******************************************************************************
* Program: 03_feature_engineering.sas
* Purpose: Create features for fraud detection
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Calculate velocity features */
%macro CALCULATE_VELOCITY(inds=, outds=, window_days=7);

    /* Sort by customer and date */
    PROC SORT DATA=&inds;
        BY customer_id transaction_date_sas transaction_time;
    RUN;

    /* Calculate velocity features */
    DATA &outds;
        SET &inds;
        BY customer_id;

        /* Retain variables for calculations */
        RETAIN txn_count_&window_days.d 0
               txn_amount_&window_days.d 0
               last_txn_date .;

        /* Reset on new customer */
        if FIRST.customer_id then do;
            txn_count_&window_days.d = 0;
            txn_amount_&window_days.d = 0;
            last_txn_date = .;
        end;

        /* Calculate days since last transaction */
        if NOT missing(last_txn_date) then 
            days_since_last_txn = transaction_date_sas - last_txn_date;
        else 
            days_since_last_txn = .;

        /* Update counters (rolling window) */
        if NOT missing(last_txn_date) then do;
            if days_since_last_txn <= &window_days then do;
                txn_count_&window_days.d + 1;
                txn_amount_&window_days.d + amount;
            end;
            else do;
                txn_count_&window_days.d = 1;
                txn_amount_&window_days.d = amount;
            end;
        end;
        else do;
            txn_count_&window_days.d = 1;
            txn_amount_&window_days.d = amount;
        end;

        /* Update last transaction date */
        last_txn_date = transaction_date_sas;

        /* Calculate average transaction amount in window */
        if txn_count_&window_days.d > 0 then 
            avg_txn_amount_&window_days.d = txn_amount_&window_days.d / txn_count_&window_days.d;
        else 
            avg_txn_amount_&window_days.d = 0;

        DROP last_txn_date;

    RUN;

    %PUT NOTE: Calculated velocity features for &window_days day window;

%mend CALCULATE_VELOCITY;

/* MACRO 2: Calculate amount deviation */
%macro CALCULATE_AMOUNT_DEVIATION(inds=, outds=);

    /* Calculate customer statistics */
    PROC MEANS DATA=&inds NOPRINT;
        BY customer_id;
        VAR amount;
        OUTPUT OUT=customer_stats
            MEAN=customer_avg_amount
            STD=customer_std_amount
            N=customer_txn_count;
    RUN;

    /* Merge statistics back */
    PROC SQL;
        CREATE TABLE &outds AS
        SELECT 
            a.*,
            b.customer_avg_amount,
            b.customer_std_amount,
            b.customer_txn_count,
            /* Calculate z-score */
            CASE 
                WHEN b.customer_std_amount > 0 THEN
                    (a.amount - b.customer_avg_amount) / b.customer_std_amount
                ELSE 0
            END AS amount_zscore,
            /* Calculate percentage deviation */
            CASE
                WHEN b.customer_avg_amount > 0 THEN
                    ((a.amount - b.customer_avg_amount) / b.customer_avg_amount) * 100
                ELSE 0
            END AS amount_pct_deviation
        FROM &inds a
        LEFT JOIN customer_stats b
        ON a.customer_id = b.customer_id;
    QUIT;

    %PUT NOTE: Calculated amount deviation features;

%mend CALCULATE_AMOUNT_DEVIATION;

/* MACRO 3: Create time-based features */
%macro CREATE_TIME_FEATURES(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Extract time components */
        txn_hour = HOUR(transaction_time);
        txn_day_of_week = WEEKDAY(transaction_date_sas);
        txn_day_of_month = DAY(transaction_date_sas);
        txn_month = MONTH(transaction_date_sas);

        /* Create time-of-day categories */
        length time_of_day $20;
        if txn_hour >= 0 AND txn_hour < 6 then time_of_day = 'NIGHT';
        else if txn_hour >= 6 AND txn_hour < 12 then time_of_day = 'MORNING';
        else if txn_hour >= 12 AND txn_hour < 18 then time_of_day = 'AFTERNOON';
        else time_of_day = 'EVENING';

        /* Create weekend flag */
        is_weekend = (txn_day_of_week IN (1, 7));  /* Sunday=1, Saturday=7 */

        /* Create unusual hour flag */
        is_unusual_hour = (txn_hour >= 0 AND txn_hour < 6);

    RUN;

    %PUT NOTE: Created time-based features;

%mend CREATE_TIME_FEATURES;

/* MACRO 4: Create location features */
%macro CREATE_LOCATION_FEATURES(inds=, outds=);

    /* Calculate country transaction counts */
    PROC SQL;
        CREATE TABLE country_counts AS
        SELECT 
            country_code_clean,
            COUNT(*) AS country_txn_count
        FROM &inds
        GROUP BY country_code_clean;
    QUIT;

    /* Merge back and create features */
    PROC SQL;
        CREATE TABLE &outds AS
        SELECT 
            a.*,
            b.country_txn_count,
            /* Flag for rare countries */
            CASE 
                WHEN b.country_txn_count < 10 THEN 1
                ELSE 0
            END AS is_rare_country,
            /* Check if international transaction */
            CASE
                WHEN a.country_code_clean NE 'US' THEN 1
                ELSE 0
            END AS is_international
        FROM &inds a
        LEFT JOIN country_counts b
        ON a.country_code_clean = b.country_code_clean;
    QUIT;

    %PUT NOTE: Created location-based features;

%mend CREATE_LOCATION_FEATURES;

/* Execute feature engineering pipeline */
%CALCULATE_VELOCITY(
    inds=&input_lib..transactions_final,
    outds=&output_lib..txn_with_velocity,
    window_days=7
);

%CALCULATE_AMOUNT_DEVIATION(
    inds=&output_lib..txn_with_velocity,
    outds=&output_lib..txn_with_deviation
);

%CREATE_TIME_FEATURES(
    inds=&output_lib..txn_with_deviation,
    outds=&output_lib..txn_with_time_features
);

%CREATE_LOCATION_FEATURES(
    inds=&output_lib..txn_with_time_features,
    outds=&output_lib..transactions_engineered
);

/* Display sample of engineered features */
PROC PRINT DATA=&output_lib..transactions_engineered(OBS=10);
    VAR transaction_id customer_id amount 
        txn_count_7d avg_txn_amount_7d amount_zscore
        time_of_day is_weekend is_unusual_hour;
    TITLE 'Sample of Engineered Features';
RUN;
```

## Content of 04_rule_based_detection
```sas
/*******************************************************************************
* Program: 04_rule_based_detection.sas
* Purpose: Apply rule-based fraud detection logic
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Define fraud detection rules */
%macro APPLY_FRAUD_RULES(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Initialize rule flags and scores */
        length rule_triggered $200;
        rule_triggered = '';
        rule_score = 0;

        /* RULE 1: High velocity (>10 transactions in 7 days) */
        if txn_count_7d > 10 then do;
            rule_triggered = CATX(', ', rule_triggered, 'HIGH_VELOCITY');
            rule_score = rule_score + 25;
        end;

        /* RULE 2: Large amount deviation (>3 standard deviations) */
        if ABS(amount_zscore) > 3 then do;
            rule_triggered = CATX(', ', rule_triggered, 'AMOUNT_DEVIATION');
            rule_score = rule_score + 30;
        end;

        /* RULE 3: High amount (>$5000) */
        if amount > 5000 then do;
            rule_triggered = CATX(', ', rule_triggered, 'HIGH_AMOUNT');
            rule_score = rule_score + 20;
        end;

        /* RULE 4: Unusual hour transaction */
        if is_unusual_hour = 1 then do;
            rule_triggered = CATX(', ', rule_triggered, 'UNUSUAL_HOUR');
            rule_score = rule_score + 15;
        end;

        /* RULE 5: International transaction */
        if is_international = 1 then do;
            rule_triggered = CATX(', ', rule_triggered, 'INTERNATIONAL');
            rule_score = rule_score + 10;
        end;

        /* RULE 6: Rare country */
        if is_rare_country = 1 then do;
            rule_triggered = CATX(', ', rule_triggered, 'RARE_COUNTRY');
            rule_score = rule_score + 15;
        end;

        /* RULE 7: Multiple transactions in short time */
        if days_since_last_txn < 0.042 then do;  /* Less than 1 hour */
            rule_triggered = CATX(', ', rule_triggered, 'RAPID_SUCCESSION');
            rule_score = rule_score + 25;
        end;

        /* RULE 8: Round amount (potentially suspicious) */
        if MOD(amount, 100) = 0 AND amount >= 1000 then do;
            rule_triggered = CATX(', ', rule_triggered, 'ROUND_AMOUNT');
            rule_score = rule_score + 10;
        end;

        /* Calculate final rule-based risk level */
        length rule_risk_level $10;
        if rule_score >= 75 then rule_risk_level = 'CRITICAL';
        else if rule_score >= 50 then rule_risk_level = 'HIGH';
        else if rule_score >= 25 then rule_risk_level = 'MEDIUM';
        else rule_risk_level = 'LOW';

        /* Flag for investigation */
        is_suspicious = (rule_score >= 50);

    RUN;

    %PUT NOTE: Applied fraud detection rules;

%mend APPLY_FRAUD_RULES;

/* MACRO 2: Generate rule-based alerts */
%macro GENERATE_RULE_ALERTS(inds=, outds=, threshold=50);

    /* Filter suspicious transactions */
    DATA &outds;
        SET &inds;
        WHERE rule_score >= &threshold;
    RUN;

    /* Sort by risk score */
    PROC SORT DATA=&outds;
        BY DESCENDING rule_score transaction_date_sas;
    RUN;

    /* Count alerts by risk level */
    PROC FREQ DATA=&outds;
        TABLES rule_risk_level / NOCUM;
        TITLE "Rule-Based Alerts by Risk Level (Score >= &threshold)";
    RUN;

    /* Log alert counts */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :alert_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %let alert_rate = %SYSEVALF((&alert_count / &total_count) * 100);
    %PUT NOTE: Generated &alert_count alerts (&alert_rate% of transactions);

%mend GENERATE_RULE_ALERTS;

/* MACRO 3: Create rule summary report */
%macro RULE_SUMMARY_REPORT(inds=);

    /* Count by rule */
    PROC SQL;
        CREATE TABLE rule_summary AS
        SELECT 
            'HIGH_VELOCITY' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'HIGH_VELOCITY') > 0 THEN 1 ELSE 0 END) AS trigger_count
        FROM &inds
        UNION ALL
        SELECT 
            'AMOUNT_DEVIATION' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'AMOUNT_DEVIATION') > 0 THEN 1 ELSE 0 END)
        FROM &inds
        UNION ALL
        SELECT 
            'HIGH_AMOUNT' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'HIGH_AMOUNT') > 0 THEN 1 ELSE 0 END)
        FROM &inds
        UNION ALL
        SELECT 
            'UNUSUAL_HOUR' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'UNUSUAL_HOUR') > 0 THEN 1 ELSE 0 END)
        FROM &inds
        UNION ALL
        SELECT 
            'INTERNATIONAL' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'INTERNATIONAL') > 0 THEN 1 ELSE 0 END)
        FROM &inds;
    QUIT;

    /* Display summary */
    PROC PRINT DATA=rule_summary;
        TITLE 'Fraud Rule Trigger Summary';
    RUN;

%mend RULE_SUMMARY_REPORT;

/* Execute rule-based detection */
%APPLY_FRAUD_RULES(
    inds=&input_lib..transactions_engineered,
    outds=&output_lib..transactions_with_rules
);

%GENERATE_RULE_ALERTS(
    inds=&output_lib..transactions_with_rules,
    outds=&output_lib..rule_based_alerts,
    threshold=50
);

%RULE_SUMMARY_REPORT(
    inds=&output_lib..transactions_with_rules
);

/* Display top alerts */
PROC PRINT DATA=&output_lib..rule_based_alerts(OBS=20);
    VAR transaction_id customer_id amount rule_score rule_risk_level rule_triggered;
    TITLE 'Top 20 Rule-Based Fraud Alerts';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 02_data_quality_cleaning
```sas
/*******************************************************************************
* Program: 02_data_quality_cleaning.sas
* Purpose: Clean and standardize transaction data
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Clean transaction data */
%macro CLEAN_TRANSACTIONS(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Standardize transaction type */
        length transaction_type_clean $20;
        transaction_type_clean = UPCASE(STRIP(transaction_type));

        /* Clean merchant name */
        length merchant_name_clean $100;
        merchant_name_clean = PROPCASE(STRIP(merchant_name));

        /* Standardize country code */
        length country_code_clean $2;
        country_code_clean = UPCASE(SUBSTR(country_code, 1, 2));

        /* Handle missing amounts - replace with 0 */
        if missing(amount) then amount = 0;

        /* Convert transaction date to SAS date */
        if NOT missing(transaction_date) then do;
            transaction_date_sas = INPUT(transaction_date, YYMMDD10.);
            FORMAT transaction_date_sas DATE9.;
        end;

        /* Create transaction timestamp */
        transaction_datetime = DHMS(transaction_date_sas, 
                                   HOUR(transaction_time), 
                                   MINUTE(transaction_time), 
                                   SECOND(transaction_time));
        FORMAT transaction_datetime DATETIME20.;

    RUN;

    %PUT NOTE: Cleaned &inds to &outds;

%mend CLEAN_TRANSACTIONS;

/* MACRO 2: Remove duplicates */
%macro REMOVE_DUPLICATES(inds=, outds=, key=);

    /* Sort by key */
    PROC SORT DATA=&inds OUT=&outds NODUPKEY;
        BY &key;
    RUN;

    /* Log duplicate removal */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :before_count FROM &inds;
        SELECT COUNT(*) INTO :after_count FROM &outds;
    QUIT;

    %let dup_count = %EVAL(&before_count - &after_count);
    %PUT NOTE: Removed &dup_count duplicate records;

%mend REMOVE_DUPLICATES;

/* MACRO 3: Handle outliers */
%macro HANDLE_OUTLIERS(inds=, outds=, var=, method=WINSORIZE);

    /* Calculate percentiles */
    PROC MEANS DATA=&inds NOPRINT;
        VAR &var;
        OUTPUT OUT=percentiles
            P1=p1 P99=p99;
    RUN;

    /* Get percentile values */
    DATA _NULL_;
        SET percentiles;
        CALL SYMPUTX('p1_value', p1);
        CALL SYMPUTX('p99_value', p99);
    RUN;

    /* Apply outlier handling */
    DATA &outds;
        SET &inds;

        %if &method = WINSORIZE %then %do;
            /* Winsorize: Cap at 1st and 99th percentiles */
            if &var < &p1_value then &var = &p1_value;
            else if &var > &p99_value then &var = &p99_value;
        %end;
        %else %if &method = REMOVE %then %do;
            /* Remove outliers */
            if &var >= &p1_value AND &var <= &p99_value;
        %end;

    RUN;

    %PUT NOTE: Handled outliers in &var using &method method;

%mend HANDLE_OUTLIERS;

/* Execute cleaning pipeline */
%CLEAN_TRANSACTIONS(
    inds=&input_lib..transactions_validated,
    outds=&output_lib..transactions_cleaned
);

%REMOVE_DUPLICATES(
    inds=&output_lib..transactions_cleaned,
    outds=&output_lib..transactions_deduped,
    key=transaction_id
);

%HANDLE_OUTLIERS(
    inds=&output_lib..transactions_deduped,
    outds=&output_lib..transactions_final,
    var=amount,
    method=WINSORIZE
);

/* Display results */
PROC MEANS DATA=&output_lib..transactions_final N MEAN STD MIN MAX;
    VAR amount;
    TITLE 'Transaction Amount Statistics After Cleaning';
RUN;
```

## Content of 03_feature_engineering
```sas
/*******************************************************************************
* Program: 03_feature_engineering.sas
* Purpose: Create features for fraud detection
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Calculate velocity features */
%macro CALCULATE_VELOCITY(inds=, outds=, window_days=7);

    /* Sort by customer and date */
    PROC SORT DATA=&inds;
        BY customer_id transaction_date_sas transaction_time;
    RUN;

    /* Calculate velocity features */
    DATA &outds;
        SET &inds;
        BY customer_id;

        /* Retain variables for calculations */
        RETAIN txn_count_&window_days.d 0
               txn_amount_&window_days.d 0
               last_txn_date .;

        /* Reset on new customer */
        if FIRST.customer_id then do;
            txn_count_&window_days.d = 0;
            txn_amount_&window_days.d = 0;
            last_txn_date = .;
        end;

        /* Calculate days since last transaction */
        if NOT missing(last_txn_date) then 
            days_since_last_txn = transaction_date_sas - last_txn_date;
        else 
            days_since_last_txn = .;

        /* Update counters (rolling window) */
        if NOT missing(last_txn_date) then do;
            if days_since_last_txn <= &window_days then do;
                txn_count_&window_days.d + 1;
                txn_amount_&window_days.d + amount;
            end;
            else do;
                txn_count_&window_days.d = 1;
                txn_amount_&window_days.d = amount;
            end;
        end;
        else do;
            txn_count_&window_days.d = 1;
            txn_amount_&window_days.d = amount;
        end;

        /* Update last transaction date */
        last_txn_date = transaction_date_sas;

        /* Calculate average transaction amount in window */
        if txn_count_&window_days.d > 0 then 
            avg_txn_amount_&window_days.d = txn_amount_&window_days.d / txn_count_&window_days.d;
        else 
            avg_txn_amount_&window_days.d = 0;

        DROP last_txn_date;

    RUN;

    %PUT NOTE: Calculated velocity features for &window_days day window;

%mend CALCULATE_VELOCITY;

/* MACRO 2: Calculate amount deviation */
%macro CALCULATE_AMOUNT_DEVIATION(inds=, outds=);

    /* Calculate customer statistics */
    PROC MEANS DATA=&inds NOPRINT;
        BY customer_id;
        VAR amount;
        OUTPUT OUT=customer_stats
            MEAN=customer_avg_amount
            STD=customer_std_amount
            N=customer_txn_count;
    RUN;

    /* Merge statistics back */
    PROC SQL;
        CREATE TABLE &outds AS
        SELECT 
            a.*,
            b.customer_avg_amount,
            b.customer_std_amount,
            b.customer_txn_count,
            /* Calculate z-score */
            CASE 
                WHEN b.customer_std_amount > 0 THEN
                    (a.amount - b.customer_avg_amount) / b.customer_std_amount
                ELSE 0
            END AS amount_zscore,
            /* Calculate percentage deviation */
            CASE
                WHEN b.customer_avg_amount > 0 THEN
                    ((a.amount - b.customer_avg_amount) / b.customer_avg_amount) * 100
                ELSE 0
            END AS amount_pct_deviation
        FROM &inds a
        LEFT JOIN customer_stats b
        ON a.customer_id = b.customer_id;
    QUIT;

    %PUT NOTE: Calculated amount deviation features;

%mend CALCULATE_AMOUNT_DEVIATION;

/* MACRO 3: Create time-based features */
%macro CREATE_TIME_FEATURES(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Extract time components */
        txn_hour = HOUR(transaction_time);
        txn_day_of_week = WEEKDAY(transaction_date_sas);
        txn_day_of_month = DAY(transaction_date_sas);
        txn_month = MONTH(transaction_date_sas);

        /* Create time-of-day categories */
        length time_of_day $20;
        if txn_hour >= 0 AND txn_hour < 6 then time_of_day = 'NIGHT';
        else if txn_hour >= 6 AND txn_hour < 12 then time_of_day = 'MORNING';
        else if txn_hour >= 12 AND txn_hour < 18 then time_of_day = 'AFTERNOON';
        else time_of_day = 'EVENING';

        /* Create weekend flag */
        is_weekend = (txn_day_of_week IN (1, 7));  /* Sunday=1, Saturday=7 */

        /* Create unusual hour flag */
        is_unusual_hour = (txn_hour >= 0 AND txn_hour < 6);

    RUN;

    %PUT NOTE: Created time-based features;

%mend CREATE_TIME_FEATURES;

/* MACRO 4: Create location features */
%macro CREATE_LOCATION_FEATURES(inds=, outds=);

    /* Calculate country transaction counts */
    PROC SQL;
        CREATE TABLE country_counts AS
        SELECT 
            country_code_clean,
            COUNT(*) AS country_txn_count
        FROM &inds
        GROUP BY country_code_clean;
    QUIT;

    /* Merge back and create features */
    PROC SQL;
        CREATE TABLE &outds AS
        SELECT 
            a.*,
            b.country_txn_count,
            /* Flag for rare countries */
            CASE 
                WHEN b.country_txn_count < 10 THEN 1
                ELSE 0
            END AS is_rare_country,
            /* Check if international transaction */
            CASE
                WHEN a.country_code_clean NE 'US' THEN 1
                ELSE 0
            END AS is_international
        FROM &inds a
        LEFT JOIN country_counts b
        ON a.country_code_clean = b.country_code_clean;
    QUIT;

    %PUT NOTE: Created location-based features;

%mend CREATE_LOCATION_FEATURES;

/* Execute feature engineering pipeline */
%CALCULATE_VELOCITY(
    inds=&input_lib..transactions_final,
    outds=&output_lib..txn_with_velocity,
    window_days=7
);

%CALCULATE_AMOUNT_DEVIATION(
    inds=&output_lib..txn_with_velocity,
    outds=&output_lib..txn_with_deviation
);

%CREATE_TIME_FEATURES(
    inds=&output_lib..txn_with_deviation,
    outds=&output_lib..txn_with_time_features
);

%CREATE_LOCATION_FEATURES(
    inds=&output_lib..txn_with_time_features,
    outds=&output_lib..transactions_engineered
);

/* Display sample of engineered features */
PROC PRINT DATA=&output_lib..transactions_engineered(OBS=10);
    VAR transaction_id customer_id amount 
        txn_count_7d avg_txn_amount_7d amount_zscore
        time_of_day is_weekend is_unusual_hour;
    TITLE 'Sample of Engineered Features';
RUN;
```

## Content of 04_rule_based_detection
```sas
/*******************************************************************************
* Program: 04_rule_based_detection.sas
* Purpose: Apply rule-based fraud detection logic
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Define fraud detection rules */
%macro APPLY_FRAUD_RULES(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Initialize rule flags and scores */
        length rule_triggered $200;
        rule_triggered = '';
        rule_score = 0;

        /* RULE 1: High velocity (>10 transactions in 7 days) */
        if txn_count_7d > 10 then do;
            rule_triggered = CATX(', ', rule_triggered, 'HIGH_VELOCITY');
            rule_score = rule_score + 25;
        end;

        /* RULE 2: Large amount deviation (>3 standard deviations) */
        if ABS(amount_zscore) > 3 then do;
            rule_triggered = CATX(', ', rule_triggered, 'AMOUNT_DEVIATION');
            rule_score = rule_score + 30;
        end;

        /* RULE 3: High amount (>$5000) */
        if amount > 5000 then do;
            rule_triggered = CATX(', ', rule_triggered, 'HIGH_AMOUNT');
            rule_score = rule_score + 20;
        end;

        /* RULE 4: Unusual hour transaction */
        if is_unusual_hour = 1 then do;
            rule_triggered = CATX(', ', rule_triggered, 'UNUSUAL_HOUR');
            rule_score = rule_score + 15;
        end;

        /* RULE 5: International transaction */
        if is_international = 1 then do;
            rule_triggered = CATX(', ', rule_triggered, 'INTERNATIONAL');
            rule_score = rule_score + 10;
        end;

        /* RULE 6: Rare country */
        if is_rare_country = 1 then do;
            rule_triggered = CATX(', ', rule_triggered, 'RARE_COUNTRY');
            rule_score = rule_score + 15;
        end;

        /* RULE 7: Multiple transactions in short time */
        if days_since_last_txn < 0.042 then do;  /* Less than 1 hour */
            rule_triggered = CATX(', ', rule_triggered, 'RAPID_SUCCESSION');
            rule_score = rule_score + 25;
        end;

        /* RULE 8: Round amount (potentially suspicious) */
        if MOD(amount, 100) = 0 AND amount >= 1000 then do;
            rule_triggered = CATX(', ', rule_triggered, 'ROUND_AMOUNT');
            rule_score = rule_score + 10;
        end;

        /* Calculate final rule-based risk level */
        length rule_risk_level $10;
        if rule_score >= 75 then rule_risk_level = 'CRITICAL';
        else if rule_score >= 50 then rule_risk_level = 'HIGH';
        else if rule_score >= 25 then rule_risk_level = 'MEDIUM';
        else rule_risk_level = 'LOW';

        /* Flag for investigation */
        is_suspicious = (rule_score >= 50);

    RUN;

    %PUT NOTE: Applied fraud detection rules;

%mend APPLY_FRAUD_RULES;

/* MACRO 2: Generate rule-based alerts */
%macro GENERATE_RULE_ALERTS(inds=, outds=, threshold=50);

    /* Filter suspicious transactions */
    DATA &outds;
        SET &inds;
        WHERE rule_score >= &threshold;
    RUN;

    /* Sort by risk score */
    PROC SORT DATA=&outds;
        BY DESCENDING rule_score transaction_date_sas;
    RUN;

    /* Count alerts by risk level */
    PROC FREQ DATA=&outds;
        TABLES rule_risk_level / NOCUM;
        TITLE "Rule-Based Alerts by Risk Level (Score >= &threshold)";
    RUN;

    /* Log alert counts */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :alert_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %let alert_rate = %SYSEVALF((&alert_count / &total_count) * 100);
    %PUT NOTE: Generated &alert_count alerts (&alert_rate% of transactions);

%mend GENERATE_RULE_ALERTS;

/* MACRO 3: Create rule summary report */
%macro RULE_SUMMARY_REPORT(inds=);

    /* Count by rule */
    PROC SQL;
        CREATE TABLE rule_summary AS
        SELECT 
            'HIGH_VELOCITY' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'HIGH_VELOCITY') > 0 THEN 1 ELSE 0 END) AS trigger_count
        FROM &inds
        UNION ALL
        SELECT 
            'AMOUNT_DEVIATION' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'AMOUNT_DEVIATION') > 0 THEN 1 ELSE 0 END)
        FROM &inds
        UNION ALL
        SELECT 
            'HIGH_AMOUNT' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'HIGH_AMOUNT') > 0 THEN 1 ELSE 0 END)
        FROM &inds
        UNION ALL
        SELECT 
            'UNUSUAL_HOUR' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'UNUSUAL_HOUR') > 0 THEN 1 ELSE 0 END)
        FROM &inds
        UNION ALL
        SELECT 
            'INTERNATIONAL' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'INTERNATIONAL') > 0 THEN 1 ELSE 0 END)
        FROM &inds;
    QUIT;

    /* Display summary */
    PROC PRINT DATA=rule_summary;
        TITLE 'Fraud Rule Trigger Summary';
    RUN;

%mend RULE_SUMMARY_REPORT;

/* Execute rule-based detection */
%APPLY_FRAUD_RULES(
    inds=&input_lib..transactions_engineered,
    outds=&output_lib..transactions_with_rules
);

%GENERATE_RULE_ALERTS(
    inds=&output_lib..transactions_with_rules,
    outds=&output_lib..rule_based_alerts,
    threshold=50
);

%RULE_SUMMARY_REPORT(
    inds=&output_lib..transactions_with_rules
);

/* Display top alerts */
PROC PRINT DATA=&output_lib..rule_based_alerts(OBS=20);
    VAR transaction_id customer_id amount rule_score rule_risk_level rule_triggered;
    TITLE 'Top 20 Rule-Based Fraud Alerts';
RUN;
```

## Content of 05_ml_scoring_model
```sas
/*******************************************************************************
* Program: 05_ml_scoring_model.sas
* Purpose: Apply ML model for fraud probability scoring
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Prepare data for ML scoring */
%macro PREPARE_ML_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create binary flags for categorical variables */
        is_high_amount = (amount > 1000);
        is_very_high_amount = (amount > 5000);

        /* Normalize continuous variables (simple min-max scaling) */
        /* In production, use actual min/max from training data */
        amount_normalized = amount / 10000;  /* Assuming max ~$10k */
        txn_count_normalized = txn_count_7d / 20;  /* Assuming max ~20 */

        /* Handle missing values */
        if missing(amount_zscore) then amount_zscore = 0;
        if missing(days_since_last_txn) then days_since_last_txn = 999;

        /* Create interaction features */
        amount_x_velocity = amount_normalized * txn_count_normalized;
        amount_x_deviation = amount_normalized * ABS(amount_zscore);

    RUN;

    %PUT NOTE: Prepared data for ML scoring;

%mend PREPARE_ML_DATA;

/* MACRO 2: Calculate ML fraud score (simulated logistic regression) */
%macro CALCULATE_ML_SCORE(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Simulated logistic regression coefficients */
        /* In production, these would come from a trained model */

        /* Calculate logit score */
        logit_score = 
            -2.5                                    /* Intercept */
            + 0.8 * amount_normalized               /* Amount effect */
            + 0.6 * txn_count_normalized            /* Velocity effect */
            + 0.4 * ABS(amount_zscore)              /* Deviation effect */
            + 0.5 * is_unusual_hour                 /* Time effect */
            + 0.3 * is_international                /* Location effect */
            + 0.7 * amount_x_velocity               /* Interaction 1 */
            + 0.5 * amount_x_deviation              /* Interaction 2 */
            - 0.2 * customer_txn_count / 100;       /* Customer history */

        /* Convert logit to probability using sigmoid function */
        ml_fraud_probability = 1 / (1 + EXP(-logit_score));

        /* Convert probability to score (0-100) */
        ml_fraud_score = ml_fraud_probability * 100;

        /* Assign ML risk band */
        length ml_risk_band $10;
        if ml_fraud_score >= 80 then ml_risk_band = 'CRITICAL';
        else if ml_fraud_score >= 60 then ml_risk_band = 'HIGH';
        else if ml_fraud_score >= 40 then ml_risk_band = 'MEDIUM';
        else if ml_fraud_score >= 20 then ml_risk_band = 'LOW';
        else ml_risk_band = 'VERY_LOW';

        /* Create ML alert flag */
        ml_alert = (ml_fraud_score >= 60);

        FORMAT ml_fraud_probability PERCENT8.2;

    RUN;

    %PUT NOTE: Calculated ML fraud scores;

%mend CALCULATE_ML_SCORE;

/* MACRO 3: Generate ML performance metrics */
%macro ML_PERFORMANCE_METRICS(inds=);

    /* Distribution of scores */
    PROC MEANS DATA=&inds N MEAN STD MIN P25 MEDIAN P75 MAX;
        VAR ml_fraud_score ml_fraud_probability;
        TITLE 'ML Fraud Score Distribution';
    RUN;

    /* Distribution by risk band */
    PROC FREQ DATA=&inds;
        TABLES ml_risk_band / NOCUM;
        TITLE 'ML Risk Band Distribution';
    RUN;

    /* Alert rate */
    PROC FREQ DATA=&inds;
        TABLES ml_alert / NOCUM;
        TITLE 'ML Alert Rate';
    RUN;

%mend ML_PERFORMANCE_METRICS;

/* MACRO 4: Compare ML vs Rule-based */
%macro COMPARE_MODELS(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Categorize agreement */
        length model_agreement $30;

        if ml_alert = 1 AND is_suspicious = 1 then 
            model_agreement = 'BOTH_ALERT';
        else if ml_alert = 1 AND is_suspicious = 0 then 
            model_agreement = 'ML_ONLY';
        else if ml_alert = 0 AND is_suspicious = 1 then 
            model_agreement = 'RULE_ONLY';
        else 
            model_agreement = 'BOTH_CLEAR';

        /* Calculate combined score */
        combined_score = (ml_fraud_score * 0.6) + (rule_score * 0.4);

        /* Combined risk level */
        length combined_risk_level $10;
        if combined_score >= 75 then combined_risk_level = 'CRITICAL';
        else if combined_score >= 50 then combined_risk_level = 'HIGH';
        else if combined_score >= 25 then combined_risk_level = 'MEDIUM';
        else combined_risk_level = 'LOW';

    RUN;

    /* Model agreement summary */
    PROC FREQ DATA=&outds;
        TABLES model_agreement / NOCUM;
        TITLE 'Model Agreement Analysis';
    RUN;

    /* Correlation between scores */
    PROC CORR DATA=&outds NOSIMPLE;
        VAR ml_fraud_score rule_score;
        TITLE 'Correlation: ML Score vs Rule Score';
    RUN;

    %PUT NOTE: Generated model comparison;

%mend COMPARE_MODELS;

/* Execute ML scoring pipeline */
%PREPARE_ML_DATA(
    inds=&input_lib..transactions_with_rules,
    outds=&output_lib..ml_data_prepared
);

%CALCULATE_ML_SCORE(
    inds=&output_lib..ml_data_prepared,
    outds=&output_lib..transactions_ml_scored
);

%ML_PERFORMANCE_METRICS(
    inds=&output_lib..transactions_ml_scored
);

%COMPARE_MODELS(
    inds=&output_lib..transactions_ml_scored,
    outds=&output_lib..transactions_combined_score
);

/* Display top ML alerts */
PROC PRINT DATA=&output_lib..transactions_ml_scored(OBS=20);
    WHERE ml_alert = 1;
    VAR transaction_id customer_id amount ml_fraud_score ml_fraud_probability 
        ml_risk_band rule_score;
    TITLE 'Top 20 ML-Based Fraud Alerts';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 02_data_quality_cleaning
```sas
/*******************************************************************************
* Program: 02_data_quality_cleaning.sas
* Purpose: Clean and standardize transaction data
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Clean transaction data */
%macro CLEAN_TRANSACTIONS(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Standardize transaction type */
        length transaction_type_clean $20;
        transaction_type_clean = UPCASE(STRIP(transaction_type));

        /* Clean merchant name */
        length merchant_name_clean $100;
        merchant_name_clean = PROPCASE(STRIP(merchant_name));

        /* Standardize country code */
        length country_code_clean $2;
        country_code_clean = UPCASE(SUBSTR(country_code, 1, 2));

        /* Handle missing amounts - replace with 0 */
        if missing(amount) then amount = 0;

        /* Convert transaction date to SAS date */
        if NOT missing(transaction_date) then do;
            transaction_date_sas = INPUT(transaction_date, YYMMDD10.);
            FORMAT transaction_date_sas DATE9.;
        end;

        /* Create transaction timestamp */
        transaction_datetime = DHMS(transaction_date_sas, 
                                   HOUR(transaction_time), 
                                   MINUTE(transaction_time), 
                                   SECOND(transaction_time));
        FORMAT transaction_datetime DATETIME20.;

    RUN;

    %PUT NOTE: Cleaned &inds to &outds;

%mend CLEAN_TRANSACTIONS;

/* MACRO 2: Remove duplicates */
%macro REMOVE_DUPLICATES(inds=, outds=, key=);

    /* Sort by key */
    PROC SORT DATA=&inds OUT=&outds NODUPKEY;
        BY &key;
    RUN;

    /* Log duplicate removal */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :before_count FROM &inds;
        SELECT COUNT(*) INTO :after_count FROM &outds;
    QUIT;

    %let dup_count = %EVAL(&before_count - &after_count);
    %PUT NOTE: Removed &dup_count duplicate records;

%mend REMOVE_DUPLICATES;

/* MACRO 3: Handle outliers */
%macro HANDLE_OUTLIERS(inds=, outds=, var=, method=WINSORIZE);

    /* Calculate percentiles */
    PROC MEANS DATA=&inds NOPRINT;
        VAR &var;
        OUTPUT OUT=percentiles
            P1=p1 P99=p99;
    RUN;

    /* Get percentile values */
    DATA _NULL_;
        SET percentiles;
        CALL SYMPUTX('p1_value', p1);
        CALL SYMPUTX('p99_value', p99);
    RUN;

    /* Apply outlier handling */
    DATA &outds;
        SET &inds;

        %if &method = WINSORIZE %then %do;
            /* Winsorize: Cap at 1st and 99th percentiles */
            if &var < &p1_value then &var = &p1_value;
            else if &var > &p99_value then &var = &p99_value;
        %end;
        %else %if &method = REMOVE %then %do;
            /* Remove outliers */
            if &var >= &p1_value AND &var <= &p99_value;
        %end;

    RUN;

    %PUT NOTE: Handled outliers in &var using &method method;

%mend HANDLE_OUTLIERS;

/* Execute cleaning pipeline */
%CLEAN_TRANSACTIONS(
    inds=&input_lib..transactions_validated,
    outds=&output_lib..transactions_cleaned
);

%REMOVE_DUPLICATES(
    inds=&output_lib..transactions_cleaned,
    outds=&output_lib..transactions_deduped,
    key=transaction_id
);

%HANDLE_OUTLIERS(
    inds=&output_lib..transactions_deduped,
    outds=&output_lib..transactions_final,
    var=amount,
    method=WINSORIZE
);

/* Display results */
PROC MEANS DATA=&output_lib..transactions_final N MEAN STD MIN MAX;
    VAR amount;
    TITLE 'Transaction Amount Statistics After Cleaning';
RUN;
```

## Content of 03_feature_engineering
```sas
/*******************************************************************************
* Program: 03_feature_engineering.sas
* Purpose: Create features for fraud detection
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Calculate velocity features */
%macro CALCULATE_VELOCITY(inds=, outds=, window_days=7);

    /* Sort by customer and date */
    PROC SORT DATA=&inds;
        BY customer_id transaction_date_sas transaction_time;
    RUN;

    /* Calculate velocity features */
    DATA &outds;
        SET &inds;
        BY customer_id;

        /* Retain variables for calculations */
        RETAIN txn_count_&window_days.d 0
               txn_amount_&window_days.d 0
               last_txn_date .;

        /* Reset on new customer */
        if FIRST.customer_id then do;
            txn_count_&window_days.d = 0;
            txn_amount_&window_days.d = 0;
            last_txn_date = .;
        end;

        /* Calculate days since last transaction */
        if NOT missing(last_txn_date) then 
            days_since_last_txn = transaction_date_sas - last_txn_date;
        else 
            days_since_last_txn = .;

        /* Update counters (rolling window) */
        if NOT missing(last_txn_date) then do;
            if days_since_last_txn <= &window_days then do;
                txn_count_&window_days.d + 1;
                txn_amount_&window_days.d + amount;
            end;
            else do;
                txn_count_&window_days.d = 1;
                txn_amount_&window_days.d = amount;
            end;
        end;
        else do;
            txn_count_&window_days.d = 1;
            txn_amount_&window_days.d = amount;
        end;

        /* Update last transaction date */
        last_txn_date = transaction_date_sas;

        /* Calculate average transaction amount in window */
        if txn_count_&window_days.d > 0 then 
            avg_txn_amount_&window_days.d = txn_amount_&window_days.d / txn_count_&window_days.d;
        else 
            avg_txn_amount_&window_days.d = 0;

        DROP last_txn_date;

    RUN;

    %PUT NOTE: Calculated velocity features for &window_days day window;

%mend CALCULATE_VELOCITY;

/* MACRO 2: Calculate amount deviation */
%macro CALCULATE_AMOUNT_DEVIATION(inds=, outds=);

    /* Calculate customer statistics */
    PROC MEANS DATA=&inds NOPRINT;
        BY customer_id;
        VAR amount;
        OUTPUT OUT=customer_stats
            MEAN=customer_avg_amount
            STD=customer_std_amount
            N=customer_txn_count;
    RUN;

    /* Merge statistics back */
    PROC SQL;
        CREATE TABLE &outds AS
        SELECT 
            a.*,
            b.customer_avg_amount,
            b.customer_std_amount,
            b.customer_txn_count,
            /* Calculate z-score */
            CASE 
                WHEN b.customer_std_amount > 0 THEN
                    (a.amount - b.customer_avg_amount) / b.customer_std_amount
                ELSE 0
            END AS amount_zscore,
            /* Calculate percentage deviation */
            CASE
                WHEN b.customer_avg_amount > 0 THEN
                    ((a.amount - b.customer_avg_amount) / b.customer_avg_amount) * 100
                ELSE 0
            END AS amount_pct_deviation
        FROM &inds a
        LEFT JOIN customer_stats b
        ON a.customer_id = b.customer_id;
    QUIT;

    %PUT NOTE: Calculated amount deviation features;

%mend CALCULATE_AMOUNT_DEVIATION;

/* MACRO 3: Create time-based features */
%macro CREATE_TIME_FEATURES(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Extract time components */
        txn_hour = HOUR(transaction_time);
        txn_day_of_week = WEEKDAY(transaction_date_sas);
        txn_day_of_month = DAY(transaction_date_sas);
        txn_month = MONTH(transaction_date_sas);

        /* Create time-of-day categories */
        length time_of_day $20;
        if txn_hour >= 0 AND txn_hour < 6 then time_of_day = 'NIGHT';
        else if txn_hour >= 6 AND txn_hour < 12 then time_of_day = 'MORNING';
        else if txn_hour >= 12 AND txn_hour < 18 then time_of_day = 'AFTERNOON';
        else time_of_day = 'EVENING';

        /* Create weekend flag */
        is_weekend = (txn_day_of_week IN (1, 7));  /* Sunday=1, Saturday=7 */

        /* Create unusual hour flag */
        is_unusual_hour = (txn_hour >= 0 AND txn_hour < 6);

    RUN;

    %PUT NOTE: Created time-based features;

%mend CREATE_TIME_FEATURES;

/* MACRO 4: Create location features */
%macro CREATE_LOCATION_FEATURES(inds=, outds=);

    /* Calculate country transaction counts */
    PROC SQL;
        CREATE TABLE country_counts AS
        SELECT 
            country_code_clean,
            COUNT(*) AS country_txn_count
        FROM &inds
        GROUP BY country_code_clean;
    QUIT;

    /* Merge back and create features */
    PROC SQL;
        CREATE TABLE &outds AS
        SELECT 
            a.*,
            b.country_txn_count,
            /* Flag for rare countries */
            CASE 
                WHEN b.country_txn_count < 10 THEN 1
                ELSE 0
            END AS is_rare_country,
            /* Check if international transaction */
            CASE
                WHEN a.country_code_clean NE 'US' THEN 1
                ELSE 0
            END AS is_international
        FROM &inds a
        LEFT JOIN country_counts b
        ON a.country_code_clean = b.country_code_clean;
    QUIT;

    %PUT NOTE: Created location-based features;

%mend CREATE_LOCATION_FEATURES;

/* Execute feature engineering pipeline */
%CALCULATE_VELOCITY(
    inds=&input_lib..transactions_final,
    outds=&output_lib..txn_with_velocity,
    window_days=7
);

%CALCULATE_AMOUNT_DEVIATION(
    inds=&output_lib..txn_with_velocity,
    outds=&output_lib..txn_with_deviation
);

%CREATE_TIME_FEATURES(
    inds=&output_lib..txn_with_deviation,
    outds=&output_lib..txn_with_time_features
);

%CREATE_LOCATION_FEATURES(
    inds=&output_lib..txn_with_time_features,
    outds=&output_lib..transactions_engineered
);

/* Display sample of engineered features */
PROC PRINT DATA=&output_lib..transactions_engineered(OBS=10);
    VAR transaction_id customer_id amount 
        txn_count_7d avg_txn_amount_7d amount_zscore
        time_of_day is_weekend is_unusual_hour;
    TITLE 'Sample of Engineered Features';
RUN;
```

## Content of 04_rule_based_detection
```sas
/*******************************************************************************
* Program: 04_rule_based_detection.sas
* Purpose: Apply rule-based fraud detection logic
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Define fraud detection rules */
%macro APPLY_FRAUD_RULES(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Initialize rule flags and scores */
        length rule_triggered $200;
        rule_triggered = '';
        rule_score = 0;

        /* RULE 1: High velocity (>10 transactions in 7 days) */
        if txn_count_7d > 10 then do;
            rule_triggered = CATX(', ', rule_triggered, 'HIGH_VELOCITY');
            rule_score = rule_score + 25;
        end;

        /* RULE 2: Large amount deviation (>3 standard deviations) */
        if ABS(amount_zscore) > 3 then do;
            rule_triggered = CATX(', ', rule_triggered, 'AMOUNT_DEVIATION');
            rule_score = rule_score + 30;
        end;

        /* RULE 3: High amount (>$5000) */
        if amount > 5000 then do;
            rule_triggered = CATX(', ', rule_triggered, 'HIGH_AMOUNT');
            rule_score = rule_score + 20;
        end;

        /* RULE 4: Unusual hour transaction */
        if is_unusual_hour = 1 then do;
            rule_triggered = CATX(', ', rule_triggered, 'UNUSUAL_HOUR');
            rule_score = rule_score + 15;
        end;

        /* RULE 5: International transaction */
        if is_international = 1 then do;
            rule_triggered = CATX(', ', rule_triggered, 'INTERNATIONAL');
            rule_score = rule_score + 10;
        end;

        /* RULE 6: Rare country */
        if is_rare_country = 1 then do;
            rule_triggered = CATX(', ', rule_triggered, 'RARE_COUNTRY');
            rule_score = rule_score + 15;
        end;

        /* RULE 7: Multiple transactions in short time */
        if days_since_last_txn < 0.042 then do;  /* Less than 1 hour */
            rule_triggered = CATX(', ', rule_triggered, 'RAPID_SUCCESSION');
            rule_score = rule_score + 25;
        end;

        /* RULE 8: Round amount (potentially suspicious) */
        if MOD(amount, 100) = 0 AND amount >= 1000 then do;
            rule_triggered = CATX(', ', rule_triggered, 'ROUND_AMOUNT');
            rule_score = rule_score + 10;
        end;

        /* Calculate final rule-based risk level */
        length rule_risk_level $10;
        if rule_score >= 75 then rule_risk_level = 'CRITICAL';
        else if rule_score >= 50 then rule_risk_level = 'HIGH';
        else if rule_score >= 25 then rule_risk_level = 'MEDIUM';
        else rule_risk_level = 'LOW';

        /* Flag for investigation */
        is_suspicious = (rule_score >= 50);

    RUN;

    %PUT NOTE: Applied fraud detection rules;

%mend APPLY_FRAUD_RULES;

/* MACRO 2: Generate rule-based alerts */
%macro GENERATE_RULE_ALERTS(inds=, outds=, threshold=50);

    /* Filter suspicious transactions */
    DATA &outds;
        SET &inds;
        WHERE rule_score >= &threshold;
    RUN;

    /* Sort by risk score */
    PROC SORT DATA=&outds;
        BY DESCENDING rule_score transaction_date_sas;
    RUN;

    /* Count alerts by risk level */
    PROC FREQ DATA=&outds;
        TABLES rule_risk_level / NOCUM;
        TITLE "Rule-Based Alerts by Risk Level (Score >= &threshold)";
    RUN;

    /* Log alert counts */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :alert_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %let alert_rate = %SYSEVALF((&alert_count / &total_count) * 100);
    %PUT NOTE: Generated &alert_count alerts (&alert_rate% of transactions);

%mend GENERATE_RULE_ALERTS;

/* MACRO 3: Create rule summary report */
%macro RULE_SUMMARY_REPORT(inds=);

    /* Count by rule */
    PROC SQL;
        CREATE TABLE rule_summary AS
        SELECT 
            'HIGH_VELOCITY' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'HIGH_VELOCITY') > 0 THEN 1 ELSE 0 END) AS trigger_count
        FROM &inds
        UNION ALL
        SELECT 
            'AMOUNT_DEVIATION' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'AMOUNT_DEVIATION') > 0 THEN 1 ELSE 0 END)
        FROM &inds
        UNION ALL
        SELECT 
            'HIGH_AMOUNT' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'HIGH_AMOUNT') > 0 THEN 1 ELSE 0 END)
        FROM &inds
        UNION ALL
        SELECT 
            'UNUSUAL_HOUR' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'UNUSUAL_HOUR') > 0 THEN 1 ELSE 0 END)
        FROM &inds
        UNION ALL
        SELECT 
            'INTERNATIONAL' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'INTERNATIONAL') > 0 THEN 1 ELSE 0 END)
        FROM &inds;
    QUIT;

    /* Display summary */
    PROC PRINT DATA=rule_summary;
        TITLE 'Fraud Rule Trigger Summary';
    RUN;

%mend RULE_SUMMARY_REPORT;

/* Execute rule-based detection */
%APPLY_FRAUD_RULES(
    inds=&input_lib..transactions_engineered,
    outds=&output_lib..transactions_with_rules
);

%GENERATE_RULE_ALERTS(
    inds=&output_lib..transactions_with_rules,
    outds=&output_lib..rule_based_alerts,
    threshold=50
);

%RULE_SUMMARY_REPORT(
    inds=&output_lib..transactions_with_rules
);

/* Display top alerts */
PROC PRINT DATA=&output_lib..rule_based_alerts(OBS=20);
    VAR transaction_id customer_id amount rule_score rule_risk_level rule_triggered;
    TITLE 'Top 20 Rule-Based Fraud Alerts';
RUN;
```

## Content of 05_ml_scoring_model
```sas
/*******************************************************************************
* Program: 05_ml_scoring_model.sas
* Purpose: Apply ML model for fraud probability scoring
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Prepare data for ML scoring */
%macro PREPARE_ML_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create binary flags for categorical variables */
        is_high_amount = (amount > 1000);
        is_very_high_amount = (amount > 5000);

        /* Normalize continuous variables (simple min-max scaling) */
        /* In production, use actual min/max from training data */
        amount_normalized = amount / 10000;  /* Assuming max ~$10k */
        txn_count_normalized = txn_count_7d / 20;  /* Assuming max ~20 */

        /* Handle missing values */
        if missing(amount_zscore) then amount_zscore = 0;
        if missing(days_since_last_txn) then days_since_last_txn = 999;

        /* Create interaction features */
        amount_x_velocity = amount_normalized * txn_count_normalized;
        amount_x_deviation = amount_normalized * ABS(amount_zscore);

    RUN;

    %PUT NOTE: Prepared data for ML scoring;

%mend PREPARE_ML_DATA;

/* MACRO 2: Calculate ML fraud score (simulated logistic regression) */
%macro CALCULATE_ML_SCORE(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Simulated logistic regression coefficients */
        /* In production, these would come from a trained model */

        /* Calculate logit score */
        logit_score = 
            -2.5                                    /* Intercept */
            + 0.8 * amount_normalized               /* Amount effect */
            + 0.6 * txn_count_normalized            /* Velocity effect */
            + 0.4 * ABS(amount_zscore)              /* Deviation effect */
            + 0.5 * is_unusual_hour                 /* Time effect */
            + 0.3 * is_international                /* Location effect */
            + 0.7 * amount_x_velocity               /* Interaction 1 */
            + 0.5 * amount_x_deviation              /* Interaction 2 */
            - 0.2 * customer_txn_count / 100;       /* Customer history */

        /* Convert logit to probability using sigmoid function */
        ml_fraud_probability = 1 / (1 + EXP(-logit_score));

        /* Convert probability to score (0-100) */
        ml_fraud_score = ml_fraud_probability * 100;

        /* Assign ML risk band */
        length ml_risk_band $10;
        if ml_fraud_score >= 80 then ml_risk_band = 'CRITICAL';
        else if ml_fraud_score >= 60 then ml_risk_band = 'HIGH';
        else if ml_fraud_score >= 40 then ml_risk_band = 'MEDIUM';
        else if ml_fraud_score >= 20 then ml_risk_band = 'LOW';
        else ml_risk_band = 'VERY_LOW';

        /* Create ML alert flag */
        ml_alert = (ml_fraud_score >= 60);

        FORMAT ml_fraud_probability PERCENT8.2;

    RUN;

    %PUT NOTE: Calculated ML fraud scores;

%mend CALCULATE_ML_SCORE;

/* MACRO 3: Generate ML performance metrics */
%macro ML_PERFORMANCE_METRICS(inds=);

    /* Distribution of scores */
    PROC MEANS DATA=&inds N MEAN STD MIN P25 MEDIAN P75 MAX;
        VAR ml_fraud_score ml_fraud_probability;
        TITLE 'ML Fraud Score Distribution';
    RUN;

    /* Distribution by risk band */
    PROC FREQ DATA=&inds;
        TABLES ml_risk_band / NOCUM;
        TITLE 'ML Risk Band Distribution';
    RUN;

    /* Alert rate */
    PROC FREQ DATA=&inds;
        TABLES ml_alert / NOCUM;
        TITLE 'ML Alert Rate';
    RUN;

%mend ML_PERFORMANCE_METRICS;

/* MACRO 4: Compare ML vs Rule-based */
%macro COMPARE_MODELS(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Categorize agreement */
        length model_agreement $30;

        if ml_alert = 1 AND is_suspicious = 1 then 
            model_agreement = 'BOTH_ALERT';
        else if ml_alert = 1 AND is_suspicious = 0 then 
            model_agreement = 'ML_ONLY';
        else if ml_alert = 0 AND is_suspicious = 1 then 
            model_agreement = 'RULE_ONLY';
        else 
            model_agreement = 'BOTH_CLEAR';

        /* Calculate combined score */
        combined_score = (ml_fraud_score * 0.6) + (rule_score * 0.4);

        /* Combined risk level */
        length combined_risk_level $10;
        if combined_score >= 75 then combined_risk_level = 'CRITICAL';
        else if combined_score >= 50 then combined_risk_level = 'HIGH';
        else if combined_score >= 25 then combined_risk_level = 'MEDIUM';
        else combined_risk_level = 'LOW';

    RUN;

    /* Model agreement summary */
    PROC FREQ DATA=&outds;
        TABLES model_agreement / NOCUM;
        TITLE 'Model Agreement Analysis';
    RUN;

    /* Correlation between scores */
    PROC CORR DATA=&outds NOSIMPLE;
        VAR ml_fraud_score rule_score;
        TITLE 'Correlation: ML Score vs Rule Score';
    RUN;

    %PUT NOTE: Generated model comparison;

%mend COMPARE_MODELS;

/* Execute ML scoring pipeline */
%PREPARE_ML_DATA(
    inds=&input_lib..transactions_with_rules,
    outds=&output_lib..ml_data_prepared
);

%CALCULATE_ML_SCORE(
    inds=&output_lib..ml_data_prepared,
    outds=&output_lib..transactions_ml_scored
);

%ML_PERFORMANCE_METRICS(
    inds=&output_lib..transactions_ml_scored
);

%COMPARE_MODELS(
    inds=&output_lib..transactions_ml_scored,
    outds=&output_lib..transactions_combined_score
);

/* Display top ML alerts */
PROC PRINT DATA=&output_lib..transactions_ml_scored(OBS=20);
    WHERE ml_alert = 1;
    VAR transaction_id customer_id amount ml_fraud_score ml_fraud_probability 
        ml_risk_band rule_score;
    TITLE 'Top 20 ML-Based Fraud Alerts';
RUN;
```

## Content of 06_case_management_output
```sas
/*******************************************************************************
* Program: 06_case_management_output.sas
* Purpose: Generate prioritized case management queue and reports
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;
%let report_path = /output/reports;

/* MACRO 1: Create investigation queue */
%macro CREATE_INVESTIGATION_QUEUE(inds=, outds=, priority_threshold=50);

    DATA &outds;
        SET &inds;

        /* Calculate final priority score */
        priority_score = combined_score;

        /* Add urgency factors */
        if amount > 10000 then priority_score = priority_score + 10;
        if is_international = 1 AND amount > 5000 then priority_score = priority_score + 5;
        if txn_count_7d > 15 then priority_score = priority_score + 5;

        /* Cap at 100 */
        if priority_score > 100 then priority_score = 100;

        /* Assign case priority */
        length case_priority $10;
        if priority_score >= 80 then case_priority = 'URGENT';
        else if priority_score >= 60 then case_priority = 'HIGH';
        else if priority_score >= 40 then case_priority = 'MEDIUM';
        else case_priority = 'LOW';

        /* Filter for investigation queue */
        if priority_score >= &priority_threshold;

        /* Generate case ID */
        length case_id $20;
        case_id = CATS('CASE_', PUT(_N_, Z8.));

        /* Create investigation reason */
        length investigation_reason $500;
        investigation_reason = CATX(' | ',
            'ML Score: ' || PUT(ml_fraud_score, 5.1),
            'Rule Score: ' || PUT(rule_score, 3.),
            'Rules: ' || rule_triggered
        );

        /* Assign to investigator (round-robin simulation) */
        investigator_id = MOD(_N_, 10) + 1;  /* 10 investigators */

        /* Set case status */
        case_status = 'PENDING_REVIEW';

        /* Add timestamp */
        case_created_datetime = DATETIME();
        FORMAT case_created_datetime DATETIME20.;

    RUN;

    /* Sort by priority */
    PROC SORT DATA=&outds;
        BY DESCENDING priority_score case_priority transaction_date_sas;
    RUN;

    /* Log queue statistics */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :queue_count FROM &outds;
        SELECT COUNT(DISTINCT customer_id) INTO :unique_customers FROM &outds;
    QUIT;

    %PUT NOTE: Created investigation queue with &queue_count cases;
    %PUT NOTE: Affecting &unique_customers unique customers;

%mend CREATE_INVESTIGATION_QUEUE;

/* MACRO 2: Generate daily summary report */
%macro GENERATE_DAILY_SUMMARY(inds=);

    /* Overall statistics */
    TITLE 'Daily Fraud Detection Summary';
    TITLE2 "Report Date: &SYSDATE9";

    PROC SQL;
        CREATE TABLE daily_summary AS
        SELECT 
            COUNT(*) AS total_transactions,
            SUM(ml_alert) AS ml_alerts,
            SUM(is_suspicious) AS rule_alerts,
            SUM(CASE WHEN ml_alert=1 OR is_suspicious=1 THEN 1 ELSE 0 END) AS total_alerts,
            SUM(amount) AS total_amount FORMAT=DOLLAR20.2,
            SUM(CASE WHEN ml_alert=1 OR is_suspicious=1 THEN amount ELSE 0 END) 
                AS flagged_amount FORMAT=DOLLAR20.2,
            CALCULATED total_alerts / CALCULATED total_transactions * 100 
                AS alert_rate FORMAT=5.2
        FROM &inds;
    QUIT;

    PROC PRINT DATA=daily_summary NOOBS;
        TITLE 'Overall Statistics';
    RUN;

    /* Alerts by priority */
    PROC FREQ DATA=&inds;
        TABLES case_priority / NOCUM;
        TITLE 'Cases by Priority Level';
    RUN;

    /* Top customers by alert count */
    PROC SQL OUTOBS=20;
        CREATE TABLE top_customers AS
        SELECT 
            customer_id,
            COUNT(*) AS alert_count,
            SUM(amount) AS total_flagged_amount FORMAT=DOLLAR15.2,
            AVG(combined_score) AS avg_score FORMAT=5.1,
            MAX(case_priority) AS highest_priority
        FROM &inds
        WHERE ml_alert = 1 OR is_suspicious = 1
        GROUP BY customer_id
        ORDER BY alert_count DESC, total_flagged_amount DESC;
    QUIT;

    PROC PRINT DATA=top_customers NOOBS;
        TITLE 'Top 20 Customers by Alert Count';
    RUN;

    /* Trend by hour */
    PROC SQL;
        CREATE TABLE hourly_trend AS
        SELECT 
            txn_hour,
            COUNT(*) AS transaction_count,
            SUM(CASE WHEN ml_alert=1 OR is_suspicious=1 THEN 1 ELSE 0 END) AS alert_count,
            CALCULATED alert_count / CALCULATED transaction_count * 100 
                AS alert_rate FORMAT=5.2
        FROM &inds
        GROUP BY txn_hour
        ORDER BY txn_hour;
    QUIT;

    PROC PRINT DATA=hourly_trend NOOBS;
        TITLE 'Hourly Alert Trend';
    RUN;

%mend GENERATE_DAILY_SUMMARY;

/* MACRO 3: Export investigation queue */
%macro EXPORT_INVESTIGATION_QUEUE(inds=, filepath=);

    /* Select key fields for investigators */
    DATA export_data;
        SET &inds;
        KEEP case_id transaction_id customer_id transaction_date_sas transaction_time
             amount merchant_name_clean country_code_clean
             priority_score case_priority ml_fraud_score rule_score
             investigation_reason case_status investigator_id
             case_created_datetime;
    RUN;

    /* Export to CSV */
    PROC EXPORT 
        DATA=export_data
        OUTFILE="&filepath/investigation_queue_&SYSDATE9..csv"
        DBMS=CSV
        REPLACE;
    RUN;

    %PUT NOTE: Exported investigation queue to &filepath;

%mend EXPORT_INVESTIGATION_QUEUE;

/* MACRO 4: Generate SAR report data */
%macro GENERATE_SAR_DATA(inds=, outds=, sar_threshold=80);

    /* Filter high-priority cases for SAR filing */
    DATA &outds;
        SET &inds;
        WHERE priority_score >= &sar_threshold;

        /* Add SAR-specific fields */
        length sar_type $50;
        sar_type = 'Suspicious Transaction - Fraud Indicators';

        /* Create narrative */
        length sar_narrative $1000;
        sar_narrative = CATX('. ',
            'Transaction flagged by automated fraud detection system',
            'ML Model Score: ' || PUT(ml_fraud_score, 5.1) || '/100',
            'Rule-Based Score: ' || PUT(rule_score, 3.) || '/100',
            'Triggered Rules: ' || rule_triggered,
            'Transaction Amount: $' || PUT(amount, COMMA12.2),
            'Customer Transaction Count (7d): ' || PUT(txn_count_7d, 3.)
        );

        /* SAR filing requirement */
        requires_sar = 1;
        sar_deadline_date = INTNX('DAY', case_created_datetime, 30);
        FORMAT sar_deadline_date DATE9.;

    RUN;

    /* Sort by deadline */
    PROC SORT DATA=&outds;
        BY sar_deadline_date DESCENDING priority_score;
    RUN;

    /* Count SAR cases */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :sar_count FROM &outds;
    QUIT;

    %PUT NOTE: Generated &sar_count SAR report cases;

%mend GENERATE_SAR_DATA;

/* Execute case management workflow */
%CREATE_INVESTIGATION_QUEUE(
    inds=&input_lib..transactions_combined_score,
    outds=&output_lib..investigation_queue,
    priority_threshold=50
);

%GENERATE_DAILY_SUMMARY(
    inds=&output_lib..investigation_queue
);

%EXPORT_INVESTIGATION_QUEUE(
    inds=&output_lib..investigation_queue,
    filepath=&report_path
);

%GENERATE_SAR_DATA(
    inds=&output_lib..investigation_queue,
    outds=&output_lib..sar_cases,
    sar_threshold=80
);

/* Final output - Investigation Queue */
PROC PRINT DATA=&output_lib..investigation_queue(OBS=50);
    VAR case_id transaction_id customer_id amount priority_score case_priority
        ml_fraud_score rule_score case_status investigator_id;
    TITLE 'Investigation Queue - Top 50 Cases';
    TITLE2 'Ready for Investigator Assignment';
RUN;

/* SAR Cases requiring filing */
PROC PRINT DATA=&output_lib..sar_cases(OBS=20);
    VAR case_id customer_id amount priority_score sar_deadline_date;
    TITLE 'SAR Cases Requiring Filing';
RUN;
```

## Content of SASPOC
```sas
/*******************************************************************************
** PROGRAM:       Program_Name.sas
** AUTHOR:        [Your Name]
** CREATED:       [Date created]
**
** DESCRIPTION:   
** This program performs [brief, high-level function of the program]. 
**
** FUNCTION:
** [Detailed description of the program's logic and goal. 
** e.g., "Reads raw data from the 'sasuser.raw_data' table, cleans missing 
** values, calculates BMI, and saves the final output to 'work.final_output'."]
**
** INPUT:
** - Library: sasuser 
** - Table:   raw_data (contains patient_id, height_cm, weight_kg, date_visit)
** - Parameters: &start_date, &end_date (macro variables for filtering)
**
** OUTPUT:
** - Library: work
** - Table:   final_output (contains patient_id, bmi, date_visit, status)
** - Log messages: Includes data quality checks for out-of-range values.
**
** HISTORY:
** DATE         AUTHOR        DESCRIPTION OF CHANGE
** -------------------------------------------------------------------------
** 2025-11-26   [Your Name]   Initial version created with basic data cleaning.
** 2025-12-01   [Collaborator] Added BMI calculation and 'status' variable logic.
** 2025-12-15   [Your Name]   Optimized for large datasets using specific data step techniques.
*******************************************************************************/

 %let SYSPARM1 = %UPCASE(%SCAN(&SYSPARM,1,"_"))
 %let SYSPARM2 = %UPCASE(%SCAN(&SYSPARM,2,"_"))
 %let gdate = &sysdate9.;
 % let PROGRAM = SASPOC;
 %let PROJECT = POC;
 %let FREQ = D;
 
 %include "MYLIB.&SYSPARM1..META(&FREQ.INI)"

 %INITIALIZE;

 %let PREVYEAR = %eval(%substr(&DATE,7,4)-1);
 %let YEAR =%substr(&DATE,7,4);

 options mprint mlogic symbolgen;

 %macro call;

   %ALLOCALIB(inputlib);
  
   %DREAD(OUT_DAT = POCOUT);
 
   %DUPDATE(prev_ds=OUTPUTP.customer_data, new_ds=OUTPUT.customer_data, out_ds=FINAL.customer_data);
  
   %DALLOCLIB(inputlib);
%mend;

%call;```

## Content of SASPOC
```sas
/*******************************************************************************
** PROGRAM:       Program_Name.sas
** AUTHOR:        [Your Name]
** CREATED:       [Date created]
**
** DESCRIPTION:   
** This program performs [brief, high-level function of the program]. 
**
** FUNCTION:
** [Detailed description of the program's logic and goal. 
** e.g., "Reads raw data from the 'sasuser.raw_data' table, cleans missing 
** values, calculates BMI, and saves the final output to 'work.final_output'."]
**
** INPUT:
** - Library: sasuser 
** - Table:   raw_data (contains patient_id, height_cm, weight_kg, date_visit)
** - Parameters: &start_date, &end_date (macro variables for filtering)
**
** OUTPUT:
** - Library: work
** - Table:   final_output (contains patient_id, bmi, date_visit, status)
** - Log messages: Includes data quality checks for out-of-range values.
**
** HISTORY:
** DATE         AUTHOR        DESCRIPTION OF CHANGE
** -------------------------------------------------------------------------
** 2025-11-26   [Your Name]   Initial version created with basic data cleaning.
** 2025-12-01   [Collaborator] Added BMI calculation and 'status' variable logic.
** 2025-12-15   [Your Name]   Optimized for large datasets using specific data step techniques.
*******************************************************************************/

 %let SYSPARM1 = %UPCASE(%SCAN(&SYSPARM,1,"_"))
 %let SYSPARM2 = %UPCASE(%SCAN(&SYSPARM,2,"_"))
 %let gdate = &sysdate9.;
 % let PROGRAM = SASPOC;
 %let PROJECT = POC;
 %let FREQ = D;
 
 %include "MYLIB.&SYSPARM1..META(&FREQ.INI)"

 %INITIALIZE;

 %let PREVYEAR = %eval(%substr(&DATE,7,4)-1);
 %let YEAR =%substr(&DATE,7,4);

 options mprint mlogic symbolgen;

 %macro call;

   %ALLOCALIB(inputlib);
  
   %DREAD(OUT_DAT = POCOUT);
 
   %DUPDATE(prev_ds=OUTPUTP.customer_data, new_ds=OUTPUT.customer_data, out_ds=FINAL.customer_data);
  
   %DALLOCLIB(inputlib);
%mend;

%call;```

## Content of SASPOC
```sas
/*******************************************************************************
** PROGRAM:       Program_Name.sas
** AUTHOR:        [Your Name]
** CREATED:       [Date created]
**
** DESCRIPTION:   
** This program performs [brief, high-level function of the program]. 
**
** FUNCTION:
** [Detailed description of the program's logic and goal. 
** e.g., "Reads raw data from the 'sasuser.raw_data' table, cleans missing 
** values, calculates BMI, and saves the final output to 'work.final_output'."]
**
** INPUT:
** - Library: sasuser 
** - Table:   raw_data (contains patient_id, height_cm, weight_kg, date_visit)
** - Parameters: &start_date, &end_date (macro variables for filtering)
**
** OUTPUT:
** - Library: work
** - Table:   final_output (contains patient_id, bmi, date_visit, status)
** - Log messages: Includes data quality checks for out-of-range values.
**
** HISTORY:
** DATE         AUTHOR        DESCRIPTION OF CHANGE
** -------------------------------------------------------------------------
** 2025-11-26   [Your Name]   Initial version created with basic data cleaning.
** 2025-12-01   [Collaborator] Added BMI calculation and 'status' variable logic.
** 2025-12-15   [Your Name]   Optimized for large datasets using specific data step techniques.
*******************************************************************************/

 %let SYSPARM1 = %UPCASE(%SCAN(&SYSPARM,1,"_"))
 %let SYSPARM2 = %UPCASE(%SCAN(&SYSPARM,2,"_"))
 %let gdate = &sysdate9.;
 % let PROGRAM = SASPOC;
 %let PROJECT = POC;
 %let FREQ = D;
 
 %include "MYLIB.&SYSPARM1..META(&FREQ.INI)"

 %INITIALIZE;

 %let PREVYEAR = %eval(%substr(&DATE,7,4)-1);
 %let YEAR =%substr(&DATE,7,4);

 options mprint mlogic symbolgen;

 %macro call;

   %ALLOCALIB(inputlib);
  
   %DREAD(OUT_DAT = POCOUT);
 
   %DUPDATE(prev_ds=OUTPUTP.customer_data, new_ds=OUTPUT.customer_data, out_ds=FINAL.customer_data);
  
   %DALLOCLIB(inputlib);
%mend;

%call;```

## Content of SASPOC
```sas
/*******************************************************************************
** PROGRAM:       Program_Name.sas
** AUTHOR:        [Your Name]
** CREATED:       [Date created]
**
** DESCRIPTION:   
** This program performs [brief, high-level function of the program]. 
**
** FUNCTION:
** [Detailed description of the program's logic and goal. 
** e.g., "Reads raw data from the 'sasuser.raw_data' table, cleans missing 
** values, calculates BMI, and saves the final output to 'work.final_output'."]
**
** INPUT:
** - Library: sasuser 
** - Table:   raw_data (contains patient_id, height_cm, weight_kg, date_visit)
** - Parameters: &start_date, &end_date (macro variables for filtering)
**
** OUTPUT:
** - Library: work
** - Table:   final_output (contains patient_id, bmi, date_visit, status)
** - Log messages: Includes data quality checks for out-of-range values.
**
** HISTORY:
** DATE         AUTHOR        DESCRIPTION OF CHANGE
** -------------------------------------------------------------------------
** 2025-11-26   [Your Name]   Initial version created with basic data cleaning.
** 2025-12-01   [Collaborator] Added BMI calculation and 'status' variable logic.
** 2025-12-15   [Your Name]   Optimized for large datasets using specific data step techniques.
*******************************************************************************/

 %let SYSPARM1 = %UPCASE(%SCAN(&SYSPARM,1,"_"))
 %let SYSPARM2 = %UPCASE(%SCAN(&SYSPARM,2,"_"))
 %let gdate = &sysdate9.;
 % let PROGRAM = SASPOC;
 %let PROJECT = POC;
 %let FREQ = D;
 
 %include "MYLIB.&SYSPARM1..META(&FREQ.INI)"

 %INITIALIZE;

 %let PREVYEAR = %eval(%substr(&DATE,7,4)-1);
 %let YEAR =%substr(&DATE,7,4);

 options mprint mlogic symbolgen;

 %macro call;

   %ALLOCALIB(inputlib);
  
   %DREAD(OUT_DAT = POCOUT);
 
   %DUPDATE(prev_ds=OUTPUTP.customer_data, new_ds=OUTPUT.customer_data, out_ds=FINAL.customer_data);
  
   %DALLOCLIB(inputlib);
%mend;

%call;```

## Content of SASPOC
```sas
/*******************************************************************************
** PROGRAM:       Program_Name.sas
** AUTHOR:        [Your Name]
** CREATED:       [Date created]
**
** DESCRIPTION:   
** This program performs [brief, high-level function of the program]. 
**
** FUNCTION:
** [Detailed description of the program's logic and goal. 
** e.g., "Reads raw data from the 'sasuser.raw_data' table, cleans missing 
** values, calculates BMI, and saves the final output to 'work.final_output'."]
**
** INPUT:
** - Library: sasuser 
** - Table:   raw_data (contains patient_id, height_cm, weight_kg, date_visit)
** - Parameters: &start_date, &end_date (macro variables for filtering)
**
** OUTPUT:
** - Library: work
** - Table:   final_output (contains patient_id, bmi, date_visit, status)
** - Log messages: Includes data quality checks for out-of-range values.
**
** HISTORY:
** DATE         AUTHOR        DESCRIPTION OF CHANGE
** -------------------------------------------------------------------------
** 2025-11-26   [Your Name]   Initial version created with basic data cleaning.
** 2025-12-01   [Collaborator] Added BMI calculation and 'status' variable logic.
** 2025-12-15   [Your Name]   Optimized for large datasets using specific data step techniques.
*******************************************************************************/

 %let SYSPARM1 = %UPCASE(%SCAN(&SYSPARM,1,"_"))
 %let SYSPARM2 = %UPCASE(%SCAN(&SYSPARM,2,"_"))
 %let gdate = &sysdate9.;
 % let PROGRAM = SASPOC;
 %let PROJECT = POC;
 %let FREQ = D;
 
 %include "MYLIB.&SYSPARM1..META(&FREQ.INI)"

 %INITIALIZE;

 %let PREVYEAR = %eval(%substr(&DATE,7,4)-1);
 %let YEAR =%substr(&DATE,7,4);

 options mprint mlogic symbolgen;

 %macro call;

   %ALLOCALIB(inputlib);
  
   %DREAD(OUT_DAT = POCOUT);
 
   %DUPDATE(prev_ds=OUTPUTP.customer_data, new_ds=OUTPUT.customer_data, out_ds=FINAL.customer_data);
  
   %DALLOCLIB(inputlib);
%mend;

%call;```

## Content of SASPOC
```sas
/*******************************************************************************
** PROGRAM:       Program_Name.sas
** AUTHOR:        [Your Name]
** CREATED:       [Date created]
**
** DESCRIPTION:   
** This program performs [brief, high-level function of the program]. 
**
** FUNCTION:
** [Detailed description of the program's logic and goal. 
** e.g., "Reads raw data from the 'sasuser.raw_data' table, cleans missing 
** values, calculates BMI, and saves the final output to 'work.final_output'."]
**
** INPUT:
** - Library: sasuser 
** - Table:   raw_data (contains patient_id, height_cm, weight_kg, date_visit)
** - Parameters: &start_date, &end_date (macro variables for filtering)
**
** OUTPUT:
** - Library: work
** - Table:   final_output (contains patient_id, bmi, date_visit, status)
** - Log messages: Includes data quality checks for out-of-range values.
**
** HISTORY:
** DATE         AUTHOR        DESCRIPTION OF CHANGE
** -------------------------------------------------------------------------
** 2025-11-26   [Your Name]   Initial version created with basic data cleaning.
** 2025-12-01   [Collaborator] Added BMI calculation and 'status' variable logic.
** 2025-12-15   [Your Name]   Optimized for large datasets using specific data step techniques.
*******************************************************************************/

 %let SYSPARM1 = %UPCASE(%SCAN(&SYSPARM,1,"_"))
 %let SYSPARM2 = %UPCASE(%SCAN(&SYSPARM,2,"_"))
 %let gdate = &sysdate9.;
 % let PROGRAM = SASPOC;
 %let PROJECT = POC;
 %let FREQ = D;
 
 %include "MYLIB.&SYSPARM1..META(&FREQ.INI)"

 %INITIALIZE;

 %let PREVYEAR = %eval(%substr(&DATE,7,4)-1);
 %let YEAR =%substr(&DATE,7,4);

 options mprint mlogic symbolgen;

 %macro call;

   %ALLOCALIB(inputlib);
  
   %DREAD(OUT_DAT = POCOUT);
 
   %DUPDATE(prev_ds=OUTPUTP.customer_data, new_ds=OUTPUT.customer_data, out_ds=FINAL.customer_data);
  
   %DALLOCLIB(inputlib);
%mend;

%call;```

## Content of SASPOC
```sas
/*******************************************************************************
** PROGRAM:       Program_Name.sas
** AUTHOR:        [Your Name]
** CREATED:       [Date created]
**
** DESCRIPTION:   
** This program performs [brief, high-level function of the program]. 
**
** FUNCTION:
** [Detailed description of the program's logic and goal. 
** e.g., "Reads raw data from the 'sasuser.raw_data' table, cleans missing 
** values, calculates BMI, and saves the final output to 'work.final_output'."]
**
** INPUT:
** - Library: sasuser 
** - Table:   raw_data (contains patient_id, height_cm, weight_kg, date_visit)
** - Parameters: &start_date, &end_date (macro variables for filtering)
**
** OUTPUT:
** - Library: work
** - Table:   final_output (contains patient_id, bmi, date_visit, status)
** - Log messages: Includes data quality checks for out-of-range values.
**
** HISTORY:
** DATE         AUTHOR        DESCRIPTION OF CHANGE
** -------------------------------------------------------------------------
** 2025-11-26   [Your Name]   Initial version created with basic data cleaning.
** 2025-12-01   [Collaborator] Added BMI calculation and 'status' variable logic.
** 2025-12-15   [Your Name]   Optimized for large datasets using specific data step techniques.
*******************************************************************************/

 %let SYSPARM1 = %UPCASE(%SCAN(&SYSPARM,1,"_"))
 %let SYSPARM2 = %UPCASE(%SCAN(&SYSPARM,2,"_"))
 %let gdate = &sysdate9.;
 % let PROGRAM = SASPOC;
 %let PROJECT = POC;
 %let FREQ = D;
 
 %include "MYLIB.&SYSPARM1..META(&FREQ.INI)"

 %INITIALIZE;

 %let PREVYEAR = %eval(%substr(&DATE,7,4)-1);
 %let YEAR =%substr(&DATE,7,4);

 options mprint mlogic symbolgen;

 %macro call;

   %ALLOCALIB(inputlib);
  
   %DREAD(OUT_DAT = POCOUT);
 
   %DUPDATE(prev_ds=OUTPUTP.customer_data, new_ds=OUTPUT.customer_data, out_ds=FINAL.customer_data);
  
   %DALLOCLIB(inputlib);
%mend;

%call;```

## Content of SASPOC
```sas
/*******************************************************************************
** PROGRAM:       Program_Name.sas
** AUTHOR:        [Your Name]
** CREATED:       [Date created]
**
** DESCRIPTION:   
** This program performs [brief, high-level function of the program]. 
**
** FUNCTION:
** [Detailed description of the program's logic and goal. 
** e.g., "Reads raw data from the 'sasuser.raw_data' table, cleans missing 
** values, calculates BMI, and saves the final output to 'work.final_output'."]
**
** INPUT:
** - Library: sasuser 
** - Table:   raw_data (contains patient_id, height_cm, weight_kg, date_visit)
** - Parameters: &start_date, &end_date (macro variables for filtering)
**
** OUTPUT:
** - Library: work
** - Table:   final_output (contains patient_id, bmi, date_visit, status)
** - Log messages: Includes data quality checks for out-of-range values.
**
** HISTORY:
** DATE         AUTHOR        DESCRIPTION OF CHANGE
** -------------------------------------------------------------------------
** 2025-11-26   [Your Name]   Initial version created with basic data cleaning.
** 2025-12-01   [Collaborator] Added BMI calculation and 'status' variable logic.
** 2025-12-15   [Your Name]   Optimized for large datasets using specific data step techniques.
*******************************************************************************/

 %let SYSPARM1 = %UPCASE(%SCAN(&SYSPARM,1,"_"))
 %let SYSPARM2 = %UPCASE(%SCAN(&SYSPARM,2,"_"))
 %let gdate = &sysdate9.;
 % let PROGRAM = SASPOC;
 %let PROJECT = POC;
 %let FREQ = D;
 
 %include "MYLIB.&SYSPARM1..META(&FREQ.INI)"

 %INITIALIZE;

 %let PREVYEAR = %eval(%substr(&DATE,7,4)-1);
 %let YEAR =%substr(&DATE,7,4);

 options mprint mlogic symbolgen;

 %macro call;

   %ALLOCALIB(inputlib);
  
   %DREAD(OUT_DAT = POCOUT);
 
   %DUPDATE(prev_ds=OUTPUTP.customer_data, new_ds=OUTPUT.customer_data, out_ds=FINAL.customer_data);
  
   %DALLOCLIB(inputlib);
%mend;

%call;```

## Content of SASPOC
```sas
/*******************************************************************************
** PROGRAM:       Program_Name.sas
** AUTHOR:        [Your Name]
** CREATED:       [Date created]
**
** DESCRIPTION:   
** This program performs [brief, high-level function of the program]. 
**
** FUNCTION:
** [Detailed description of the program's logic and goal. 
** e.g., "Reads raw data from the 'sasuser.raw_data' table, cleans missing 
** values, calculates BMI, and saves the final output to 'work.final_output'."]
**
** INPUT:
** - Library: sasuser 
** - Table:   raw_data (contains patient_id, height_cm, weight_kg, date_visit)
** - Parameters: &start_date, &end_date (macro variables for filtering)
**
** OUTPUT:
** - Library: work
** - Table:   final_output (contains patient_id, bmi, date_visit, status)
** - Log messages: Includes data quality checks for out-of-range values.
**
** HISTORY:
** DATE         AUTHOR        DESCRIPTION OF CHANGE
** -------------------------------------------------------------------------
** 2025-11-26   [Your Name]   Initial version created with basic data cleaning.
** 2025-12-01   [Collaborator] Added BMI calculation and 'status' variable logic.
** 2025-12-15   [Your Name]   Optimized for large datasets using specific data step techniques.
*******************************************************************************/

 %let SYSPARM1 = %UPCASE(%SCAN(&SYSPARM,1,"_"))
 %let SYSPARM2 = %UPCASE(%SCAN(&SYSPARM,2,"_"))
 %let gdate = &sysdate9.;
 % let PROGRAM = SASPOC;
 %let PROJECT = POC;
 %let FREQ = D;
 
 %include "MYLIB.&SYSPARM1..META(&FREQ.INI)"

 %INITIALIZE;

 %let PREVYEAR = %eval(%substr(&DATE,7,4)-1);
 %let YEAR =%substr(&DATE,7,4);

 options mprint mlogic symbolgen;

 %macro call;

   %ALLOCALIB(inputlib);
  
   %DREAD(OUT_DAT = POCOUT);
 
   %DUPDATE(prev_ds=OUTPUTP.customer_data, new_ds=OUTPUT.customer_data, out_ds=FINAL.customer_data);
  
   %DALLOCLIB(inputlib);
%mend;

%call;```

## Content of SASPOC
```sas
/*******************************************************************************
** PROGRAM:       Program_Name.sas
** AUTHOR:        [Your Name]
** CREATED:       [Date created]
**
** DESCRIPTION:   
** This program performs [brief, high-level function of the program]. 
**
** FUNCTION:
** [Detailed description of the program's logic and goal. 
** e.g., "Reads raw data from the 'sasuser.raw_data' table, cleans missing 
** values, calculates BMI, and saves the final output to 'work.final_output'."]
**
** INPUT:
** - Library: sasuser 
** - Table:   raw_data (contains patient_id, height_cm, weight_kg, date_visit)
** - Parameters: &start_date, &end_date (macro variables for filtering)
**
** OUTPUT:
** - Library: work
** - Table:   final_output (contains patient_id, bmi, date_visit, status)
** - Log messages: Includes data quality checks for out-of-range values.
**
** HISTORY:
** DATE         AUTHOR        DESCRIPTION OF CHANGE
** -------------------------------------------------------------------------
** 2025-11-26   [Your Name]   Initial version created with basic data cleaning.
** 2025-12-01   [Collaborator] Added BMI calculation and 'status' variable logic.
** 2025-12-15   [Your Name]   Optimized for large datasets using specific data step techniques.
*******************************************************************************/

 %let SYSPARM1 = %UPCASE(%SCAN(&SYSPARM,1,"_"))
 %let SYSPARM2 = %UPCASE(%SCAN(&SYSPARM,2,"_"))
 %let gdate = &sysdate9.;
 % let PROGRAM = SASPOC;
 %let PROJECT = POC;
 %let FREQ = D;
 
 %include "MYLIB.&SYSPARM1..META(&FREQ.INI)"

 %INITIALIZE;

 %let PREVYEAR = %eval(%substr(&DATE,7,4)-1);
 %let YEAR =%substr(&DATE,7,4);

 options mprint mlogic symbolgen;

 %macro call;

   %ALLOCALIB(inputlib);
  
   %DREAD(OUT_DAT = POCOUT);
 
   %DUPDATE(prev_ds=OUTPUTP.customer_data, new_ds=OUTPUT.customer_data, out_ds=FINAL.customer_data);
  
   %DALLOCLIB(inputlib);
%mend;

%call;```

## Content of SASPOC
```sas
/*******************************************************************************
** PROGRAM:       Program_Name.sas
** AUTHOR:        [Your Name]
** CREATED:       [Date created]
**
** DESCRIPTION:   
** This program performs [brief, high-level function of the program]. 
**
** FUNCTION:
** [Detailed description of the program's logic and goal. 
** e.g., "Reads raw data from the 'sasuser.raw_data' table, cleans missing 
** values, calculates BMI, and saves the final output to 'work.final_output'."]
**
** INPUT:
** - Library: sasuser 
** - Table:   raw_data (contains patient_id, height_cm, weight_kg, date_visit)
** - Parameters: &start_date, &end_date (macro variables for filtering)
**
** OUTPUT:
** - Library: work
** - Table:   final_output (contains patient_id, bmi, date_visit, status)
** - Log messages: Includes data quality checks for out-of-range values.
**
** HISTORY:
** DATE         AUTHOR        DESCRIPTION OF CHANGE
** -------------------------------------------------------------------------
** 2025-11-26   [Your Name]   Initial version created with basic data cleaning.
** 2025-12-01   [Collaborator] Added BMI calculation and 'status' variable logic.
** 2025-12-15   [Your Name]   Optimized for large datasets using specific data step techniques.
*******************************************************************************/

 %let SYSPARM1 = %UPCASE(%SCAN(&SYSPARM,1,"_"))
 %let SYSPARM2 = %UPCASE(%SCAN(&SYSPARM,2,"_"))
 %let gdate = &sysdate9.;
 % let PROGRAM = SASPOC;
 %let PROJECT = POC;
 %let FREQ = D;
 
 %include "MYLIB.&SYSPARM1..META(&FREQ.INI)"

 %INITIALIZE;

 %let PREVYEAR = %eval(%substr(&DATE,7,4)-1);
 %let YEAR =%substr(&DATE,7,4);

 options mprint mlogic symbolgen;

 %macro call;

   %ALLOCALIB(inputlib);
  
   %DREAD(OUT_DAT = POCOUT);
 
   %DUPDATE(prev_ds=OUTPUTP.customer_data, new_ds=OUTPUT.customer_data, out_ds=FINAL.customer_data);
  
   %DALLOCLIB(inputlib);
%mend;

%call;```

## Content of SASPOC
```sas
/*******************************************************************************
** PROGRAM:       Program_Name.sas
** AUTHOR:        [Your Name]
** CREATED:       [Date created]
**
** DESCRIPTION:   
** This program performs [brief, high-level function of the program]. 
**
** FUNCTION:
** [Detailed description of the program's logic and goal. 
** e.g., "Reads raw data from the 'sasuser.raw_data' table, cleans missing 
** values, calculates BMI, and saves the final output to 'work.final_output'."]
**
** INPUT:
** - Library: sasuser 
** - Table:   raw_data (contains patient_id, height_cm, weight_kg, date_visit)
** - Parameters: &start_date, &end_date (macro variables for filtering)
**
** OUTPUT:
** - Library: work
** - Table:   final_output (contains patient_id, bmi, date_visit, status)
** - Log messages: Includes data quality checks for out-of-range values.
**
** HISTORY:
** DATE         AUTHOR        DESCRIPTION OF CHANGE
** -------------------------------------------------------------------------
** 2025-11-26   [Your Name]   Initial version created with basic data cleaning.
** 2025-12-01   [Collaborator] Added BMI calculation and 'status' variable logic.
** 2025-12-15   [Your Name]   Optimized for large datasets using specific data step techniques.
*******************************************************************************/

 %let SYSPARM1 = %UPCASE(%SCAN(&SYSPARM,1,"_"))
 %let SYSPARM2 = %UPCASE(%SCAN(&SYSPARM,2,"_"))
 %let gdate = &sysdate9.;
 % let PROGRAM = SASPOC;
 %let PROJECT = POC;
 %let FREQ = D;
 
 %include "MYLIB.&SYSPARM1..META(&FREQ.INI)"

 %INITIALIZE;

 %let PREVYEAR = %eval(%substr(&DATE,7,4)-1);
 %let YEAR =%substr(&DATE,7,4);

 options mprint mlogic symbolgen;

 %macro call;

   %ALLOCALIB(inputlib);
  
   %DREAD(OUT_DAT = POCOUT);
 
   %DUPDATE(prev_ds=OUTPUTP.customer_data, new_ds=OUTPUT.customer_data, out_ds=FINAL.customer_data);
  
   %DALLOCLIB(inputlib);
%mend;

%call;```

## Content of SASPOC
```sas
/*******************************************************************************
** PROGRAM:       Program_Name.sas
** AUTHOR:        [Your Name]
** CREATED:       [Date created]
**
** DESCRIPTION:   
** This program performs [brief, high-level function of the program]. 
**
** FUNCTION:
** [Detailed description of the program's logic and goal. 
** e.g., "Reads raw data from the 'sasuser.raw_data' table, cleans missing 
** values, calculates BMI, and saves the final output to 'work.final_output'."]
**
** INPUT:
** - Library: sasuser 
** - Table:   raw_data (contains patient_id, height_cm, weight_kg, date_visit)
** - Parameters: &start_date, &end_date (macro variables for filtering)
**
** OUTPUT:
** - Library: work
** - Table:   final_output (contains patient_id, bmi, date_visit, status)
** - Log messages: Includes data quality checks for out-of-range values.
**
** HISTORY:
** DATE         AUTHOR        DESCRIPTION OF CHANGE
** -------------------------------------------------------------------------
** 2025-11-26   [Your Name]   Initial version created with basic data cleaning.
** 2025-12-01   [Collaborator] Added BMI calculation and 'status' variable logic.
** 2025-12-15   [Your Name]   Optimized for large datasets using specific data step techniques.
*******************************************************************************/

 %let SYSPARM1 = %UPCASE(%SCAN(&SYSPARM,1,"_"))
 %let SYSPARM2 = %UPCASE(%SCAN(&SYSPARM,2,"_"))
 %let gdate = &sysdate9.;
 % let PROGRAM = SASPOC;
 %let PROJECT = POC;
 %let FREQ = D;
 
 %include "MYLIB.&SYSPARM1..META(&FREQ.INI)"

 %INITIALIZE;

 %let PREVYEAR = %eval(%substr(&DATE,7,4)-1);
 %let YEAR =%substr(&DATE,7,4);

 options mprint mlogic symbolgen;

 %macro call;

   %ALLOCALIB(inputlib);
  
   %DREAD(OUT_DAT = POCOUT);
 
   %DUPDATE(prev_ds=OUTPUTP.customer_data, new_ds=OUTPUT.customer_data, out_ds=FINAL.customer_data);
  
   %DALLOCLIB(inputlib);
%mend;

%call;```

## Content of SASPOC
```sas
/*******************************************************************************
** PROGRAM:       Program_Name.sas
** AUTHOR:        [Your Name]
** CREATED:       [Date created]
**
** DESCRIPTION:   
** This program performs [brief, high-level function of the program]. 
**
** FUNCTION:
** [Detailed description of the program's logic and goal. 
** e.g., "Reads raw data from the 'sasuser.raw_data' table, cleans missing 
** values, calculates BMI, and saves the final output to 'work.final_output'."]
**
** INPUT:
** - Library: sasuser 
** - Table:   raw_data (contains patient_id, height_cm, weight_kg, date_visit)
** - Parameters: &start_date, &end_date (macro variables for filtering)
**
** OUTPUT:
** - Library: work
** - Table:   final_output (contains patient_id, bmi, date_visit, status)
** - Log messages: Includes data quality checks for out-of-range values.
**
** HISTORY:
** DATE         AUTHOR        DESCRIPTION OF CHANGE
** -------------------------------------------------------------------------
** 2025-11-26   [Your Name]   Initial version created with basic data cleaning.
** 2025-12-01   [Collaborator] Added BMI calculation and 'status' variable logic.
** 2025-12-15   [Your Name]   Optimized for large datasets using specific data step techniques.
*******************************************************************************/

 %let SYSPARM1 = %UPCASE(%SCAN(&SYSPARM,1,"_"))
 %let SYSPARM2 = %UPCASE(%SCAN(&SYSPARM,2,"_"))
 %let gdate = &sysdate9.;
 % let PROGRAM = SASPOC;
 %let PROJECT = POC;
 %let FREQ = D;
 
 %include "MYLIB.&SYSPARM1..META(&FREQ.INI)"

 %INITIALIZE;

 %let PREVYEAR = %eval(%substr(&DATE,7,4)-1);
 %let YEAR =%substr(&DATE,7,4);

 options mprint mlogic symbolgen;

 %macro call;

   %ALLOCALIB(inputlib);
  
   %DREAD(OUT_DAT = POCOUT);
 
   %DUPDATE(prev_ds=OUTPUTP.customer_data, new_ds=OUTPUT.customer_data, out_ds=FINAL.customer_data);
  
   %DALLOCLIB(inputlib);
%mend;

%call;```

## Content of PYSK
```sas
import logging
import sys
from datetime import datetime

from pyspark.sql import SparkSession
from pyspark.sql import functions as F
from pyspark.sql import types as T
from pyspark.sql.window import Window

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def create_spark_session(app_name="FraudDetectionPipeline"):
    """
    Initializes and returns a SparkSession.
    """
    logger.info(f"Initializing SparkSession for {app_name}...")
    spark = SparkSession.builder \
        .appName(app_name) \
        .config("spark.sql.legacy.timeParserPolicy", "LEGACY") \
        .config("spark.sql.shuffle.partitions", "200") \
        .config("spark.driver.memory", "4g") \
        .config("spark.executor.memory", "8g") \
        .getOrCreate()
    logger.info("SparkSession initialized successfully.")
    return spark

# --- Configuration Variables ---
# Paths for input and output data
INPUT_PATH = "/data/raw"
OUTPUT_PATH = "/data/processed"
REPORT_PATH = "/output/reports"
TRANSACTION_FILE = "transactions.csv"

# Schemas for input CSV (to avoid inference issues and ensure types)
# SAS: transaction_id, customer_id, amount, transaction_date, transaction_time, transaction_type, merchant_name, country_code
TRANSACTION_SCHEMA = T.StructType([
    T.StructField("transaction_id", T.StringType(), True),
    T.StructField("customer_id", T.StringType(), True),
    T.StructField("amount", T.DoubleType(), True),
    T.StructField("transaction_date", T.StringType(), True), # Read as string, convert later
    T.StructField("transaction_time", T.StringType(), True), # Read as string, convert later
    T.StructField("transaction_type", T.StringType(), True),
    T.StructField("merchant_name", T.StringType(), True),
    T.StructField("country_code", T.StringType(), True),
])

# --- Program 01: 01_transaction_data_import.sas ---

def import_transactions(spark: SparkSession, filepath: str, schema: T.StructType) -> T.DataFrame:
    """
    Imports transaction data from a CSV file.
    Maps to SAS macro IMPORT_TRANSACTIONS.
    """
    logger.info(f"Attempting to import data from {filepath}...")
    try:
        df = spark.read \
            .option("header", "true") \
            .schema(schema) \
            .csv(filepath)
        logger.info(f"Successfully imported {filepath}.")
        return df
    except Exception as e:
        logger.error(f"ERROR: Failed to import {filepath}. Error: {e}")
        sys.exit(1) # Abort program as in SAS %ABORT

def validate_transactions(df: T.DataFrame) -> T.DataFrame:
    """
    Validates the imported transaction data by checking for missing values and invalid amounts.
    Filters out invalid records.
    Maps to SAS macro VALIDATE_DATA.
    """
    logger.info("Starting data validation...")

    total_count = df.count()
    logger.info(f"Total records before validation: {total_count}")

    # SAS: Create validation flags based on missing values and amount <= 0
    # PySpark: Use F.when().otherwise() for conditional logic
    validated_df = df.withColumn(
        "validation_status",
        F.when(F.col("transaction_id").isNull(), F.lit("MISSING_ID"))
        .when(F.col("customer_id").isNull(), F.lit("MISSING_CUSTOMER"))
        .when(F.col("amount").isNull(), F.lit("MISSING_AMOUNT"))
        .when(F.col("transaction_date").isNull(), F.lit("MISSING_DATE"))
        .when(F.col("amount") <= 0, F.lit("INVALID_AMOUNT"))
        .otherwise(F.lit("VALID"))
    )

    # SAS: Keep only valid records
    # PySpark: Use .filter()
    validated_df = validated_df.filter(F.col("validation_status") == "VALID")

    valid_count = validated_df.count()
    logger.info(f"Validated {valid_count} of {total_count} records.")

    return validated_df

# --- Program 02: 02_data_quality_cleaning.sas ---

def clean_transactions(df: T.DataFrame) -> T.DataFrame:
    """
    Cleans and standardizes transaction data.
    Maps to SAS macro CLEAN_TRANSACTIONS.
    """
    logger.info("Starting transaction data cleaning and standardization...")

    # SAS: Standardize transaction type (UPCASE, STRIP)
    # PySpark: F.upper(), F.trim()
    df = df.withColumn("transaction_type_clean", F.upper(F.trim(F.col("transaction_type"))))

    # SAS: Clean merchant name (PROPCASE, STRIP)
    # PySpark: F.initcap(), F.trim()
    df = df.withColumn("merchant_name_clean", F.initcap(F.trim(F.col("merchant_name"))))

    # SAS: Standardize country code (UPCASE, SUBSTR(country_code, 1, 2))
    # PySpark: F.upper(), F.substring()
    df = df.withColumn("country_code_clean", F.upper(F.substring(F.col("country_code"), 1, 2)))

    # SAS: Handle missing amounts - replace with 0
    # PySpark: F.coalesce()
    df = df.withColumn("amount", F.coalesce(F.col("amount"), F.lit(0)))

    # SAS: Convert transaction date to SAS date format (INPUT(transaction_date, YYMMDD10.))
    # PySpark: F.to_date()
    df = df.withColumn("transaction_date_sas", F.to_date(F.col("transaction_date"), "yyyy-MM-dd"))

    # SAS: Create transaction timestamp (DHMS(transaction_date_sas, HOUR(transaction_time), ...))
    # PySpark: F.to_timestamp() by concatenating date and time strings
    df = df.withColumn(
        "transaction_datetime",
        F.to_timestamp(F.concat_ws(" ", F.col("transaction_date"), F.col("transaction_time")), "yyyy-MM-dd HH:mm:ss")
    )

    logger.info("Transaction data cleaned and standardized.")
    return df

def remove_duplicates(df: T.DataFrame, key_cols: list) -> T.DataFrame:
    """
    Removes duplicate records based on specified key columns.
    Maps to SAS macro REMOVE_DUPLICATES.
    """
    logger.info(f"Starting duplicate removal based on key: {key_cols}...")

    before_count = df.count()
    # SAS: PROC SORT DATA=&inds OUT=&outds NODUPKEY BY &key;
    # PySpark: .dropDuplicates()
    deduped_df = df.dropDuplicates(key_cols)
    after_count = deduped_df.count()

    dup_count = before_count - after_count
    logger.info(f"Removed {dup_count} duplicate records.")

    return deduped_df

def handle_outliers(df: T.DataFrame, var_col: str, method: str = "WINSORIZE") -> T.DataFrame:
    """
    Handles outliers in a specified variable using Winsorization or removal.
    Maps to SAS macro HANDLE_OUTLIERS.
    """
    logger.info(f"Handling outliers in '{var_col}' using '{method}' method...")

    # SAS: PROC MEANS ... OUTPUT OUT=percentiles P1=p1 P99=p99;
    # PySpark: .approxQuantile()
    # Note: approxQuantile returns a list of values for the specified probabilities
    percentiles = df.approxQuantile(var_col, [0.01, 0.99], 0.01)
    p1_value = percentiles[0]
    p99_value = percentiles[1]

    logger.info(f"1st percentile for '{var_col}': {p1_value}")
    logger.info(f"99th percentile for '{var_col}': {p99_value}")

    if method.upper() == "WINSORIZE":
        # SAS: if &var < &p1_value then &var = &p1_value; else if &var > &p99_value then &var = &p99_value;
        # PySpark: F.when().otherwise()
        df = df.withColumn(
            var_col,
            F.when(F.col(var_col) < p1_value, p1_value)
            .when(F.col(var_col) > p99_value, p99_value)
            .otherwise(F.col(var_col))
        )
    elif method.upper() == "REMOVE":
        # SAS: if &var >= &p1_value AND &var <= &p99_value;
        # PySpark: .filter()
        df = df.filter((F.col(var_col) >= p1_value) & (F.col(var_col) <= p99_value))
    else:
        logger.warning(f"Unknown outlier handling method: {method}. No action taken.")

    logger.info(f"Outliers in '{var_col}' handled using '{method}' method.")
    return df

# --- Program 03: 03_feature_engineering.sas ---

def calculate_velocity_features(df: T.DataFrame, window_days: int = 7) -> T.DataFrame:
    """
    Calculates velocity features (transaction counts and amounts within a rolling window)
    and days since last transaction for each customer.
    Maps to SAS macro CALCULATE_VELOCITY.
    """
    logger.info(f"Calculating velocity features for a {window_days}-day window...")

    # SAS: PROC SORT DATA=&inds; BY customer_id transaction_date_sas transaction_time;
    # PySpark: Define window specification for customer-level ordering
    window_spec_customer = Window.partitionBy("customer_id").orderBy("transaction_datetime")

    # SAS: days_since_last_txn = transaction_date_sas - last_txn_date;
    # PySpark: F.lag() to get previous date, F.datediff()
    df = df.withColumn(
        "prev_transaction_date_sas",
        F.lag("transaction_date_sas", 1).over(window_spec_customer)
    ).withColumn(
        "days_since_last_txn",
        F.when(
            F.col("prev_transaction_date_sas").isNotNull(),
            F.datediff(F.col("transaction_date_sas"), F.col("prev_transaction_date_sas"))
        ).otherwise(None) # SAS uses '.' for missing, PySpark uses None
    ).drop("prev_transaction_date_sas")

    # SAS: Rolling window calculations (txn_count_&window_days.d, txn_amount_&window_days.d, avg_txn_amount_&window_days.d)
    # The SAS RETAIN logic with conditional reset is complex to map directly to standard Spark window functions.
    # We'll use a fixed-interval rolling window, which is a common and performant interpretation of "velocity" in Spark.
    # This window includes transactions from 'window_days' ago up to the current transaction.
    window_spec_rolling = Window.partitionBy("customer_id").orderBy("transaction_datetime").rangeBetween(
        -F.expr(f"INTERVAL {window_days} DAYS"), 0
    )

    df = df.withColumn(f"txn_count_{window_days}d", F.count("transaction_id").over(window_spec_rolling)) \
           .withColumn(f"txn_amount_{window_days}d", F.sum("amount").over(window_spec_rolling)) \
           .withColumn(f"avg_txn_amount_{window_days}d", F.avg("amount").over(window_spec_rolling))

    # Handle potential nulls from window functions for first records
    df = df.withColumn(f"txn_count_{window_days}d", F.coalesce(F.col(f"txn_count_{window_days}d"), F.lit(0)))
    df = df.withColumn(f"txn_amount_{window_days}d", F.coalesce(F.col(f"txn_amount_{window_days}d"), F.lit(0.0)))
    df = df.withColumn(f"avg_txn_amount_{window_days}d", F.coalesce(F.col(f"avg_txn_amount_{window_days}d"), F.lit(0.0)))

    logger.info("Velocity features calculated.")
    return df

def calculate_amount_deviation(df: T.DataFrame) -> T.DataFrame:
    """
    Calculates amount deviation features (average amount, standard deviation, Z-score,
    and percentage deviation) for each customer.
    Maps to SAS macro CALCULATE_AMOUNT_DEVIATION.
    """
    logger.info("Calculating amount deviation features...")

    # SAS: PROC MEANS ... BY customer_id ... OUTPUT OUT=customer_stats ...
    # PySpark: .groupBy().agg()
    customer_stats_df = df.groupBy("customer_id").agg(
        F.avg("amount").alias("customer_avg_amount"),
        F.stddev("amount").alias("customer_std_amount"),
        F.count("transaction_id").alias("customer_txn_count")
    )

    # SAS: PROC SQL ... LEFT JOIN customer_stats ...
    # PySpark: .join() with broadcast hint for efficiency if customer_stats_df is small
    df = df.join(F.broadcast(customer_stats_df), on="customer_id", how="left")

    # SAS: CASE WHEN b.customer_std_amount > 0 THEN ... ELSE 0 END AS amount_zscore
    # PySpark: F.when().otherwise()
    df = df.withColumn(
        "amount_zscore",
        F.when(F.col("customer_std_amount") > 0,
               (F.col("amount") - F.col("customer_avg_amount")) / F.col("customer_std_amount"))
        .otherwise(0.0)
    )

    # SAS: CASE WHEN b.customer_avg_amount > 0 THEN ... ELSE 0 END AS amount_pct_deviation
    # PySpark: F.when().otherwise()
    df = df.withColumn(
        "amount_pct_deviation",
        F.when(F.col("customer_avg_amount") > 0,
               ((F.col("amount") - F.col("customer_avg_amount")) / F.col("customer_avg_amount")) * 100)
        .otherwise(0.0)
    )

    # Fill potential nulls from join for new customers or if no stats
    df = df.withColumn("customer_avg_amount", F.coalesce(F.col("customer_avg_amount"), F.lit(0.0)))
    df = df.withColumn("customer_std_amount", F.coalesce(F.col("customer_std_amount"), F.lit(0.0)))
    df = df.withColumn("customer_txn_count", F.coalesce(F.col("customer_txn_count"), F.lit(0)))

    logger.info("Amount deviation features calculated.")
    return df

def create_time_features(df: T.DataFrame) -> T.DataFrame:
    """
    Creates time-based features from the transaction date and time.
    Maps to SAS macro CREATE_TIME_FEATURES.
    """
    logger.info("Creating time-based features...")

    # SAS: HOUR(transaction_time), WEEKDAY(transaction_date_sas), DAY(transaction_date_sas), MONTH(transaction_date_sas)
    # PySpark: F.hour(), F.dayofweek(), F.dayofmonth(), F.month()
    df = df.withColumn("txn_hour", F.hour(F.col("transaction_datetime"))) \
           .withColumn("txn_day_of_week", F.dayofweek(F.col("transaction_date_sas"))) \
           .withColumn("txn_day_of_month", F.dayofmonth(F.col("transaction_date_sas"))) \
           .withColumn("txn_month", F.month(F.col("transaction_date_sas")))

    # SAS: Create time-of-day categories (IF/ELSE IF)
    # PySpark: F.when().otherwise()
    df = df.withColumn(
        "time_of_day",
        F.when((F.col("txn_hour") >= 0) & (F.col("txn_hour") < 6), F.lit("NIGHT"))
        .when((F.col("txn_hour") >= 6) & (F.col("txn_hour") < 12), F.lit("MORNING"))
        .when((F.col("txn_hour") >= 12) & (F.col("txn_hour") < 18), F.lit("AFTERNOON"))
        .otherwise(F.lit("EVENING"))
    )

    # SAS: Create weekend flag (txn_day_of_week IN (1, 7))
    # PySpark: F.isin()
    df = df.withColumn("is_weekend", F.col("txn_day_of_week").isin([1, 7]).cast(T.IntegerType()))

    # SAS: Create unusual hour flag (txn_hour >= 0 AND txn_hour < 6)
    # PySpark: Boolean expression cast to IntegerType
    df = df.withColumn("is_unusual_hour", ((F.col("txn_hour") >= 0) & (F.col("txn_hour") < 6)).cast(T.IntegerType()))

    logger.info("Time-based features created.")
    return df

def create_location_features(df: T.DataFrame) -> T.DataFrame:
    """
    Creates location-based features.
    Maps to SAS macro CREATE_LOCATION_FEATURES.
    """
    logger.info("Creating location-based features...")

    # SAS: PROC SQL ... GROUP BY country_code_clean ...
    # PySpark: .groupBy().agg()
    country_counts_df = df.groupBy("country_code_clean").agg(
        F.count("transaction_id").alias("country_txn_count")
    )

    # SAS: PROC SQL ... LEFT JOIN country_counts ...
    # PySpark: .join() with broadcast hint
    df = df.join(F.broadcast(country_counts_df), on="country_code_clean", how="left")

    # SAS: CASE WHEN b.country_txn_count < 10 THEN 1 ELSE 0 END AS is_rare_country
    # PySpark: F.when().otherwise()
    df = df.withColumn(
        "is_rare_country",
        F.when(F.col("country_txn_count") < 10, 1).otherwise(0)
    )

    # SAS: CASE WHEN a.country_code_clean NE 'US' THEN 1 ELSE 0 END AS is_international
    # PySpark: Boolean expression cast to IntegerType
    df = df.withColumn(
        "is_international",
        (F.col("country_code_clean") != "US").cast(T.IntegerType())
    )

    # Fill potential nulls from join
    df = df.withColumn("country_txn_count", F.coalesce(F.col("country_txn_count"), F.lit(0)))

    logger.info("Location-based features created.")
    return df

# --- Program 04: 04_rule_based_detection.sas ---

def apply_fraud_rules(df: T.DataFrame) -> T.DataFrame:
    """
    Applies rule-based fraud detection logic and calculates a rule score.
    Maps to SAS macro APPLY_FRAUD_RULES.
    """
    logger.info("Applying fraud detection rules...")

    # Initialize rule flags and scores
    # In PySpark, we build up the score and triggered rules iteratively or in one go.
    # Let's create individual rule flags first, then sum scores and concatenate names.

    # Rule 1: High velocity (>10 transactions in 7 days)
    df = df.withColumn("rule_high_velocity", (F.col("txn_count_7d") > 10).cast(T.IntegerType()))
    # Rule 2: Large amount deviation (>3 standard deviations)
    df = df.withColumn("rule_amount_deviation", (F.abs(F.col("amount_zscore")) > 3).cast(T.IntegerType()))
    # Rule 3: High amount (>$5000)
    df = df.withColumn("rule_high_amount", (F.col("amount") > 5000).cast(T.IntegerType()))
    # Rule 4: Unusual hour transaction
    df = df.withColumn("rule_unusual_hour", (F.col("is_unusual_hour") == 1).cast(T.IntegerType()))
    # Rule 5: International transaction
    df = df.withColumn("rule_international", (F.col("is_international") == 1).cast(T.IntegerType()))
    # Rule 6: Rare country
    df = df.withColumn("rule_rare_country", (F.col("is_rare_country") == 1).cast(T.IntegerType()))
    # Rule 7: Multiple transactions in short time (less than 1 hour = 0.042 days)
    # Handle potential nulls in days_since_last_txn by treating them as not rapid succession
    df = df.withColumn("rule_rapid_succession",
                       (F.col("days_since_last_txn").isNotNull() & (F.col("days_since_last_txn") < 0.042)).cast(T.IntegerType()))
    # Rule 8: Round amount (multiple of 100 and >= 1000)
    df = df.withColumn("rule_round_amount",
                       ((F.col("amount") % 100 == 0) & (F.col("amount") >= 1000)).cast(T.IntegerType()))

    # Calculate rule_score by summing points for triggered rules
    df = df.withColumn("rule_score",
        (F.col("rule_high_velocity") * 25) +
        (F.col("rule_amount_deviation") * 30) +
        (F.col("rule_high_amount") * 20) +
        (F.col("rule_unusual_hour") * 15) +
        (F.col("rule_international") * 10) +
        (F.col("rule_rare_country") * 15) +
        (F.col("rule_rapid_succession") * 25) +
        (F.col("rule_round_amount") * 10)
    )

    # Concatenate triggered rule names
    rule_names = [
        F.when(F.col("rule_high_velocity") == 1, F.lit("HIGH_VELOCITY")),
        F.when(F.col("rule_amount_deviation") == 1, F.lit("AMOUNT_DEVIATION")),
        F.when(F.col("rule_high_amount") == 1, F.lit("HIGH_AMOUNT")),
        F.when(F.col("rule_unusual_hour") == 1, F.lit("UNUSUAL_HOUR")),
        F.when(F.col("rule_international") == 1, F.lit("INTERNATIONAL")),
        F.when(F.col("rule_rare_country") == 1, F.lit("RARE_COUNTRY")),
        F.when(F.col("rule_rapid_succession") == 1, F.lit("RAPID_SUCCESSION")),
        F.when(F.col("rule_round_amount") == 1, F.lit("ROUND_AMOUNT"))
    ]
    # Filter out None values from the array before concatenating
    df = df.withColumn("rule_triggered_array", F.array_remove(F.array(*rule_names), F.lit(None)))
    df = df.withColumn("rule_triggered", F.concat_ws(", ", F.col("rule_triggered_array")))
    df = df.drop("rule_triggered_array") # Clean up intermediate column

    # Calculate final rule-based risk level
    df = df.withColumn(
        "rule_risk_level",
        F.when(F.col("rule_score") >= 75, F.lit("CRITICAL"))
        .when(F.col("rule_score") >= 50, F.lit("HIGH"))
        .when(F.col("rule_score") >= 25, F.lit("MEDIUM"))
        .otherwise(F.lit("LOW"))
    )

    # Flag for investigation
    df = df.withColumn("is_suspicious", (F.col("rule_score") >= 50).cast(T.IntegerType()))

    logger.info("Fraud detection rules applied.")
    return df

def generate_rule_alerts(df: T.DataFrame, threshold: int = 50) -> T.DataFrame:
    """
    Generates alerts based on the rule score and provides a summary.
    Maps to SAS macro GENERATE_RULE_ALERTS.
    """
    logger.info(f"Generating rule-based alerts with threshold >= {threshold}...")

    total_transactions = df.count()

    # SAS: Filter suspicious transactions (WHERE rule_score >= &threshold;)
    # PySpark: .filter()
    alerts_df = df.filter(F.col("rule_score") >= threshold)

    # SAS: Sort by risk score (PROC SORT BY DESCENDING rule_score transaction_date_sas;)
    # PySpark: .orderBy()
    alerts_df = alerts_df.orderBy(F.col("rule_score").desc(), F.col("transaction_date_sas").desc())

    # SAS: Count alerts by risk level (PROC FREQ TABLES rule_risk_level / NOCUM;)
    # PySpark: .groupBy().count()
    risk_level_counts = alerts_df.groupBy("rule_risk_level").count().orderBy("rule_risk_level")
    logger.info("Rule-Based Alerts by Risk Level:")
    risk_level_counts.show(truncate=False)

    alert_count = alerts_df.count()
    alert_rate = (alert_count / total_transactions * 100) if total_transactions > 0 else 0.0
    logger.info(f"Generated {alert_count} alerts ({alert_rate:.2f}% of transactions).")

    return alerts_df

def rule_summary_report(df: T.DataFrame) -> T.DataFrame:
    """
    Creates a summary report of rule triggers.
    Maps to SAS macro RULE_SUMMARY_REPORT.
    """
    logger.info("Generating rule summary report...")

    # SAS: PROC SQL ... UNION ALL for each rule
    # PySpark: Aggregate individual rule flags and then union
    rule_summary_df = df.groupBy().agg(
        F.sum(F.col("rule_high_velocity")).alias("HIGH_VELOCITY"),
        F.sum(F.col("rule_amount_deviation")).alias("AMOUNT_DEVIATION"),
        F.sum(F.col("rule_high_amount")).alias("HIGH_AMOUNT"),
        F.sum(F.col("rule_unusual_hour")).alias("UNUSUAL_HOUR"),
        F.sum(F.col("rule_international")).alias("INTERNATIONAL"),
        F.sum(F.col("rule_rare_country")).alias("RARE_COUNTRY"),
        F.sum(F.col("rule_rapid_succession")).alias("RAPID_SUCCESSION"),
        F.sum(F.col("rule_round_amount")).alias("ROUND_AMOUNT")
    ).collect()[0].asDict() # Get the single row as a dictionary

    # Convert dictionary to a DataFrame for display
    summary_data = []
    for rule_name, trigger_count in rule_summary_df.items():
        summary_data.append((rule_name, trigger_count))

    summary_schema = T.StructType([
        T.StructField("rule_name", T.StringType(), True),
        T.StructField("trigger_count", T.LongType(), True)
    ])
    rule_summary_df = df.sparkSession.createDataFrame(summary_data, schema=summary_schema) \
        .orderBy(F.col("trigger_count").desc())

    logger.info("Fraud Rule Trigger Summary:")
    rule_summary_df.show(truncate=False)

    return rule_summary_df

# --- Program 05: 05_ml_scoring_model.sas ---

def prepare_ml_data(df: T.DataFrame) -> T.DataFrame:
    """
    Prepares the data for ML scoring by creating binary flags, normalizing continuous variables,
    and creating interaction features.
    Maps to SAS macro PREPARE_ML_DATA.
    """
    logger.info("Preparing data for ML scoring...")

    # SAS: Create binary flags for categorical variables
    df = df.withColumn("is_high_amount", (F.col("amount") > 1000).cast(T.IntegerType())) \
           .withColumn("is_very_high_amount", (F.col("amount") > 5000).cast(T.IntegerType()))

    # SAS: Normalize continuous variables (simple min-max scaling)
    # PySpark: Direct division
    df = df.withColumn("amount_normalized", F.col("amount") / 10000) # Assuming max ~$10k
    df = df.withColumn("txn_count_normalized", F.col("txn_count_7d") / 20) # Assuming max ~20

    # SAS: Handle missing values
    # PySpark: F.coalesce()
    df = df.withColumn("amount_zscore", F.coalesce(F.col("amount_zscore"), F.lit(0.0)))
    df = df.withColumn("days_since_last_txn", F.coalesce(F.col("days_since_last_txn"), F.lit(999.0)))

    # SAS: Create interaction features
    df = df.withColumn("amount_x_velocity", F.col("amount_normalized") * F.col("txn_count_normalized")) \
           .withColumn("amount_x_deviation", F.col("amount_normalized") * F.abs(F.col("amount_zscore")))

    logger.info("Data prepared for ML scoring.")
    return df

def calculate_ml_score(df: T.DataFrame) -> T.DataFrame:
    """
    Calculates an ML-based fraud score using a simulated logistic regression model.
    Maps to SAS macro CALCULATE_ML_SCORE.
    """
    logger.info("Calculating ML fraud scores (simulated logistic regression)...")

    # Simulated logistic regression coefficients
    # SAS: logit_score = ...
    # PySpark: Direct arithmetic calculation
    df = df.withColumn(
        "logit_score",
        F.lit(-2.5) +                                   # Intercept
        F.lit(0.8) * F.col("amount_normalized") +       # Amount effect
        F.lit(0.6) * F.col("txn_count_normalized") +    # Velocity effect
        F.lit(0.4) * F.abs(F.col("amount_zscore")) +    # Deviation effect
        F.lit(0.5) * F.col("is_unusual_hour") +         # Time effect
        F.lit(0.3) * F.col("is_international") +        # Location effect
        F.lit(0.7) * F.col("amount_x_velocity") +       # Interaction 1
        F.lit(0.5) * F.col("amount_x_deviation") +      # Interaction 2
        F.lit(-0.2) * (F.col("customer_txn_count") /
100) # Assuming normalization for customer_txn_count
    )

    # Convert logit score to probability (sigmoid function: 1 / (1 + exp(-x)))
    df = df.withColumn("ml_score_probability", F.lit(1) / (F.lit(1) + F.exp(-F.col("logit_score"))))

    # Scale probability to a score, e.g., 0-100
    df = df.withColumn("ml_score", (F.col("ml_score_probability") * 100).cast(T.IntegerType()))

    # Assign ML-based risk level
    df = df.withColumn(
        "ml_risk_level",
        F.when(F.col("ml_score") >= 80, F.lit("CRITICAL"))
        .when(F.col("ml_score") >= 60, F.lit("HIGH"))
        .when(F.col("ml_score") >= 40, F.lit("MEDIUM"))
        .otherwise(F.lit("LOW"))
    )

    logger.info("ML fraud scores calculated.")
    return df

# --- Program 06: 06_combine_scores_reporting.sas ---

def combine_scores(df: T.DataFrame) -> T.DataFrame:
    """
    Combines rule-based and ML-based scores to derive a final fraud assessment.
    Maps to SAS macro COMBINE_SCORES.
    """
    logger.info("Combining rule-based and ML-based scores...")

    # SAS: final_score = (rule_score * 0.4) + (ml_score * 0.6);
    # PySpark: Weighted average
    df = df.withColumn(
        "final_fraud_score",
        (F.col("rule_score") * 0.4) + (F.col("ml_score") * 0.6)
    )

    # SAS: final_risk_level based on final_fraud_score
    df = df.withColumn(
        "final_risk_level",
        F.when(F.col("final_fraud_score") >= 70, F.lit("CRITICAL"))
        .when(F.col("final_fraud_score") >= 50, F.lit("HIGH"))
        .when(F.col("final_fraud_score") >= 30, F.lit("MEDIUM"))
        .otherwise(F.lit("LOW"))
    )

    # SAS: final_recommendation (e.g., INVESTIGATE, MONITOR, APPROVE)
    df = df.withColumn(
        "final_recommendation",
        F.when(F.col("final_fraud_score") >= 50, F.lit("INVESTIGATE"))
        .when(F.col("final_fraud_score") >= 30, F.lit("MONITOR"))
        .otherwise(F.lit("APPROVE"))
    )

    logger.info("Scores combined and final assessment derived.")
    return df

def generate_final_report(df: T.DataFrame, output_path: str) -> None:
    """
    Generates a final fraud detection report, including summary statistics and
    saving high-risk transactions.
    Maps to SAS macro GENERATE_FINAL_REPORT.
    """
    logger.info("Generating final fraud detection report...")

    total_transactions = df.count()
    high_risk_transactions = df.filter(F.col("final_risk_level").isin(["CRITICAL", "HIGH"]))
    high_risk_count = high_risk_transactions.count()
    high_risk_rate = (high_risk_count / total_transactions * 100) if total_transactions > 0 else 0.0

    logger.info(f"Total transactions processed: {total_transactions}")
    logger.info(f"High-risk transactions identified (CRITICAL/HIGH): {high_risk_count} ({high_risk_rate:.2f}%)")

    # Summary by final risk level
    risk_level_summary = df.groupBy("final_risk_level").count().orderBy("final_risk_level")
    logger.info("Final Risk Level Distribution:")
    risk_level_summary.show(truncate=False)

    # Summary by final recommendation
    recommendation_summary = df.groupBy("final_recommendation").count().orderBy("final_recommendation")
    logger.info("Final Recommendation Distribution:")
    recommendation_summary.show(truncate=False)

    # Save high-risk transactions for further investigation
    output_file_path = f"{output_path}/high_risk_transactions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
    logger.info(f"Saving high-risk transactions to {output_file_path}...")
    try:
        # Select relevant columns for the report
        high_risk_transactions.select(
            "transaction_id", "customer_id", "amount", "transaction_datetime",
            "merchant_name_clean", "country_code_clean",
            "rule_score", "rule_risk_level", "rule_triggered",
            "ml_score", "ml_risk_level",
            "final_fraud_score", "final_risk_level", "final_recommendation"
        ).write \
            .mode("overwrite") \
            .option("header", "true") \
            .csv(output_file_path)
        logger.info(f"High-risk transactions saved successfully to {output_file_path}.")
    except Exception as e:
        logger.error(f"ERROR: Failed to save high-risk transactions. Error: {e}")

    logger.info("Final fraud detection report generated.")

# --- Main Pipeline Execution ---

def main():
    """
    Main function to orchestrate the fraud detection pipeline.
    """
    spark = None
    try:
        spark = create_spark_session()

        # 01_transaction_data_import.sas
        transactions_df = import_transactions(spark, f"{INPUT_PATH}/{TRANSACTION_FILE}", TRANSACTION_SCHEMA)
        transactions_df = validate_transactions(transactions_df)

        # 02_data_quality_cleaning.sas
        transactions_df = clean_transactions(transactions_df)
        transactions_df = remove_duplicates(transactions_df, ["transaction_id", "customer_id", "transaction_datetime"])
        transactions_df = handle_outliers(transactions_df, "amount", method="WINSORIZE")

        # 03_feature_engineering.sas
        transactions_df = calculate_velocity_features(transactions_df, window_days=7)
        transactions_df = calculate_amount_deviation(transactions_df)
        transactions_df = create_time_features(transactions_df)
        transactions_df = create_location_features(transactions_df)

        # Cache the DataFrame before applying rules and ML scoring if it's used multiple times
        # or if subsequent operations are expensive.
        transactions_df.cache()
        transactions_df.count() # Trigger caching

        # 04_rule_based_detection.sas
        transactions_df = apply_fraud_rules(transactions_df)
        rule_alerts_df = generate_rule_alerts(transactions_df, threshold=50)
        rule_summary_report(transactions_df)

        # 05_ml_scoring_model.sas
        transactions_df = prepare_ml_data(transactions_df)
        transactions_df = calculate_ml_score(transactions_df)

        # 06_combine_scores_reporting.sas
        transactions_df = combine_scores(transactions_df)
        generate_final_report(transactions_df, REPORT_PATH)

        # Optionally save the fully processed data
        processed_output_path = f"{OUTPUT_PATH}/processed_transactions_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        logger.info(f"Saving all processed transactions to {processed_output_path}...")
        transactions_df.write \
            .mode("overwrite") \
            .parquet(processed_output_path)
        logger.info("All processed transactions saved.")

    except Exception as e:
        logger.error(f"An unhandled error occurred in the main pipeline: {e}", exc_info=True)
        sys.exit(1)
    finally:
        if spark:
            logger.info("Stopping SparkSession.")
            spark.stop()

if __name__ == "__main__":
    main()```

## Content of SASPOC
```sas
/*******************************************************************************
** PROGRAM:       Program_Name.sas
** AUTHOR:        [Your Name]
** CREATED:       [Date created]
**
** DESCRIPTION:   
** This program performs [brief, high-level function of the program]. 
**
** FUNCTION:
** [Detailed description of the program's logic and goal. 
** e.g., "Reads raw data from the 'sasuser.raw_data' table, cleans missing 
** values, calculates BMI, and saves the final output to 'work.final_output'."]
**
** INPUT:
** - Library: sasuser 
** - Table:   raw_data (contains patient_id, height_cm, weight_kg, date_visit)
** - Parameters: &start_date, &end_date (macro variables for filtering)
**
** OUTPUT:
** - Library: work
** - Table:   final_output (contains patient_id, bmi, date_visit, status)
** - Log messages: Includes data quality checks for out-of-range values.
**
** HISTORY:
** DATE         AUTHOR        DESCRIPTION OF CHANGE
** -------------------------------------------------------------------------
** 2025-11-26   [Your Name]   Initial version created with basic data cleaning.
** 2025-12-01   [Collaborator] Added BMI calculation and 'status' variable logic.
** 2025-12-15   [Your Name]   Optimized for large datasets using specific data step techniques.
*******************************************************************************/

 %let SYSPARM1 = %UPCASE(%SCAN(&SYSPARM,1,"_"))
 %let SYSPARM2 = %UPCASE(%SCAN(&SYSPARM,2,"_"))
 %let gdate = &sysdate9.;
 % let PROGRAM = SASPOC;
 %let PROJECT = POC;
 %let FREQ = D;
 
 %include "MYLIB.&SYSPARM1..META(&FREQ.INI)"

 %INITIALIZE;

 %let PREVYEAR = %eval(%substr(&DATE,7,4)-1);
 %let YEAR =%substr(&DATE,7,4);

 options mprint mlogic symbolgen;

 %macro call;

   %ALLOCALIB(inputlib);
  
   %DREAD(OUT_DAT = POCOUT);
 
   %DUPDATE(prev_ds=OUTPUTP.customer_data, new_ds=OUTPUT.customer_data, out_ds=FINAL.customer_data);
  
   %DALLOCLIB(inputlib);
%mend;

%call;```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 02_data_quality_cleaning
```sas
/*******************************************************************************
* Program: 02_data_quality_cleaning.sas
* Purpose: Clean and standardize transaction data
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Clean transaction data */
%macro CLEAN_TRANSACTIONS(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Standardize transaction type */
        length transaction_type_clean $20;
        transaction_type_clean = UPCASE(STRIP(transaction_type));

        /* Clean merchant name */
        length merchant_name_clean $100;
        merchant_name_clean = PROPCASE(STRIP(merchant_name));

        /* Standardize country code */
        length country_code_clean $2;
        country_code_clean = UPCASE(SUBSTR(country_code, 1, 2));

        /* Handle missing amounts - replace with 0 */
        if missing(amount) then amount = 0;

        /* Convert transaction date to SAS date */
        if NOT missing(transaction_date) then do;
            transaction_date_sas = INPUT(transaction_date, YYMMDD10.);
            FORMAT transaction_date_sas DATE9.;
        end;

        /* Create transaction timestamp */
        transaction_datetime = DHMS(transaction_date_sas, 
                                   HOUR(transaction_time), 
                                   MINUTE(transaction_time), 
                                   SECOND(transaction_time));
        FORMAT transaction_datetime DATETIME20.;

    RUN;

    %PUT NOTE: Cleaned &inds to &outds;

%mend CLEAN_TRANSACTIONS;

/* MACRO 2: Remove duplicates */
%macro REMOVE_DUPLICATES(inds=, outds=, key=);

    /* Sort by key */
    PROC SORT DATA=&inds OUT=&outds NODUPKEY;
        BY &key;
    RUN;

    /* Log duplicate removal */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :before_count FROM &inds;
        SELECT COUNT(*) INTO :after_count FROM &outds;
    QUIT;

    %let dup_count = %EVAL(&before_count - &after_count);
    %PUT NOTE: Removed &dup_count duplicate records;

%mend REMOVE_DUPLICATES;

/* MACRO 3: Handle outliers */
%macro HANDLE_OUTLIERS(inds=, outds=, var=, method=WINSORIZE);

    /* Calculate percentiles */
    PROC MEANS DATA=&inds NOPRINT;
        VAR &var;
        OUTPUT OUT=percentiles
            P1=p1 P99=p99;
    RUN;

    /* Get percentile values */
    DATA _NULL_;
        SET percentiles;
        CALL SYMPUTX('p1_value', p1);
        CALL SYMPUTX('p99_value', p99);
    RUN;

    /* Apply outlier handling */
    DATA &outds;
        SET &inds;

        %if &method = WINSORIZE %then %do;
            /* Winsorize: Cap at 1st and 99th percentiles */
            if &var < &p1_value then &var = &p1_value;
            else if &var > &p99_value then &var = &p99_value;
        %end;
        %else %if &method = REMOVE %then %do;
            /* Remove outliers */
            if &var >= &p1_value AND &var <= &p99_value;
        %end;

    RUN;

    %PUT NOTE: Handled outliers in &var using &method method;

%mend HANDLE_OUTLIERS;

/* Execute cleaning pipeline */
%CLEAN_TRANSACTIONS(
    inds=&input_lib..transactions_validated,
    outds=&output_lib..transactions_cleaned
);

%REMOVE_DUPLICATES(
    inds=&output_lib..transactions_cleaned,
    outds=&output_lib..transactions_deduped,
    key=transaction_id
);

%HANDLE_OUTLIERS(
    inds=&output_lib..transactions_deduped,
    outds=&output_lib..transactions_final,
    var=amount,
    method=WINSORIZE
);

/* Display results */
PROC MEANS DATA=&output_lib..transactions_final N MEAN STD MIN MAX;
    VAR amount;
    TITLE 'Transaction Amount Statistics After Cleaning';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 02_data_quality_cleaning
```sas
/*******************************************************************************
* Program: 02_data_quality_cleaning.sas
* Purpose: Clean and standardize transaction data
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Clean transaction data */
%macro CLEAN_TRANSACTIONS(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Standardize transaction type */
        length transaction_type_clean $20;
        transaction_type_clean = UPCASE(STRIP(transaction_type));

        /* Clean merchant name */
        length merchant_name_clean $100;
        merchant_name_clean = PROPCASE(STRIP(merchant_name));

        /* Standardize country code */
        length country_code_clean $2;
        country_code_clean = UPCASE(SUBSTR(country_code, 1, 2));

        /* Handle missing amounts - replace with 0 */
        if missing(amount) then amount = 0;

        /* Convert transaction date to SAS date */
        if NOT missing(transaction_date) then do;
            transaction_date_sas = INPUT(transaction_date, YYMMDD10.);
            FORMAT transaction_date_sas DATE9.;
        end;

        /* Create transaction timestamp */
        transaction_datetime = DHMS(transaction_date_sas, 
                                   HOUR(transaction_time), 
                                   MINUTE(transaction_time), 
                                   SECOND(transaction_time));
        FORMAT transaction_datetime DATETIME20.;

    RUN;

    %PUT NOTE: Cleaned &inds to &outds;

%mend CLEAN_TRANSACTIONS;

/* MACRO 2: Remove duplicates */
%macro REMOVE_DUPLICATES(inds=, outds=, key=);

    /* Sort by key */
    PROC SORT DATA=&inds OUT=&outds NODUPKEY;
        BY &key;
    RUN;

    /* Log duplicate removal */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :before_count FROM &inds;
        SELECT COUNT(*) INTO :after_count FROM &outds;
    QUIT;

    %let dup_count = %EVAL(&before_count - &after_count);
    %PUT NOTE: Removed &dup_count duplicate records;

%mend REMOVE_DUPLICATES;

/* MACRO 3: Handle outliers */
%macro HANDLE_OUTLIERS(inds=, outds=, var=, method=WINSORIZE);

    /* Calculate percentiles */
    PROC MEANS DATA=&inds NOPRINT;
        VAR &var;
        OUTPUT OUT=percentiles
            P1=p1 P99=p99;
    RUN;

    /* Get percentile values */
    DATA _NULL_;
        SET percentiles;
        CALL SYMPUTX('p1_value', p1);
        CALL SYMPUTX('p99_value', p99);
    RUN;

    /* Apply outlier handling */
    DATA &outds;
        SET &inds;

        %if &method = WINSORIZE %then %do;
            /* Winsorize: Cap at 1st and 99th percentiles */
            if &var < &p1_value then &var = &p1_value;
            else if &var > &p99_value then &var = &p99_value;
        %end;
        %else %if &method = REMOVE %then %do;
            /* Remove outliers */
            if &var >= &p1_value AND &var <= &p99_value;
        %end;

    RUN;

    %PUT NOTE: Handled outliers in &var using &method method;

%mend HANDLE_OUTLIERS;

/* Execute cleaning pipeline */
%CLEAN_TRANSACTIONS(
    inds=&input_lib..transactions_validated,
    outds=&output_lib..transactions_cleaned
);

%REMOVE_DUPLICATES(
    inds=&output_lib..transactions_cleaned,
    outds=&output_lib..transactions_deduped,
    key=transaction_id
);

%HANDLE_OUTLIERS(
    inds=&output_lib..transactions_deduped,
    outds=&output_lib..transactions_final,
    var=amount,
    method=WINSORIZE
);

/* Display results */
PROC MEANS DATA=&output_lib..transactions_final N MEAN STD MIN MAX;
    VAR amount;
    TITLE 'Transaction Amount Statistics After Cleaning';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 02_data_quality_cleaning
```sas
/*******************************************************************************
* Program: 02_data_quality_cleaning.sas
* Purpose: Clean and standardize transaction data
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Clean transaction data */
%macro CLEAN_TRANSACTIONS(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Standardize transaction type */
        length transaction_type_clean $20;
        transaction_type_clean = UPCASE(STRIP(transaction_type));

        /* Clean merchant name */
        length merchant_name_clean $100;
        merchant_name_clean = PROPCASE(STRIP(merchant_name));

        /* Standardize country code */
        length country_code_clean $2;
        country_code_clean = UPCASE(SUBSTR(country_code, 1, 2));

        /* Handle missing amounts - replace with 0 */
        if missing(amount) then amount = 0;

        /* Convert transaction date to SAS date */
        if NOT missing(transaction_date) then do;
            transaction_date_sas = INPUT(transaction_date, YYMMDD10.);
            FORMAT transaction_date_sas DATE9.;
        end;

        /* Create transaction timestamp */
        transaction_datetime = DHMS(transaction_date_sas, 
                                   HOUR(transaction_time), 
                                   MINUTE(transaction_time), 
                                   SECOND(transaction_time));
        FORMAT transaction_datetime DATETIME20.;

    RUN;

    %PUT NOTE: Cleaned &inds to &outds;

%mend CLEAN_TRANSACTIONS;

/* MACRO 2: Remove duplicates */
%macro REMOVE_DUPLICATES(inds=, outds=, key=);

    /* Sort by key */
    PROC SORT DATA=&inds OUT=&outds NODUPKEY;
        BY &key;
    RUN;

    /* Log duplicate removal */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :before_count FROM &inds;
        SELECT COUNT(*) INTO :after_count FROM &outds;
    QUIT;

    %let dup_count = %EVAL(&before_count - &after_count);
    %PUT NOTE: Removed &dup_count duplicate records;

%mend REMOVE_DUPLICATES;

/* MACRO 3: Handle outliers */
%macro HANDLE_OUTLIERS(inds=, outds=, var=, method=WINSORIZE);

    /* Calculate percentiles */
    PROC MEANS DATA=&inds NOPRINT;
        VAR &var;
        OUTPUT OUT=percentiles
            P1=p1 P99=p99;
    RUN;

    /* Get percentile values */
    DATA _NULL_;
        SET percentiles;
        CALL SYMPUTX('p1_value', p1);
        CALL SYMPUTX('p99_value', p99);
    RUN;

    /* Apply outlier handling */
    DATA &outds;
        SET &inds;

        %if &method = WINSORIZE %then %do;
            /* Winsorize: Cap at 1st and 99th percentiles */
            if &var < &p1_value then &var = &p1_value;
            else if &var > &p99_value then &var = &p99_value;
        %end;
        %else %if &method = REMOVE %then %do;
            /* Remove outliers */
            if &var >= &p1_value AND &var <= &p99_value;
        %end;

    RUN;

    %PUT NOTE: Handled outliers in &var using &method method;

%mend HANDLE_OUTLIERS;

/* Execute cleaning pipeline */
%CLEAN_TRANSACTIONS(
    inds=&input_lib..transactions_validated,
    outds=&output_lib..transactions_cleaned
);

%REMOVE_DUPLICATES(
    inds=&output_lib..transactions_cleaned,
    outds=&output_lib..transactions_deduped,
    key=transaction_id
);

%HANDLE_OUTLIERS(
    inds=&output_lib..transactions_deduped,
    outds=&output_lib..transactions_final,
    var=amount,
    method=WINSORIZE
);

/* Display results */
PROC MEANS DATA=&output_lib..transactions_final N MEAN STD MIN MAX;
    VAR amount;
    TITLE 'Transaction Amount Statistics After Cleaning';
RUN;
```

## Content of 03_feature_engineering
```sas
/*******************************************************************************
* Program: 03_feature_engineering.sas
* Purpose: Create features for fraud detection
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Calculate velocity features */
%macro CALCULATE_VELOCITY(inds=, outds=, window_days=7);

    /* Sort by customer and date */
    PROC SORT DATA=&inds;
        BY customer_id transaction_date_sas transaction_time;
    RUN;

    /* Calculate velocity features */
    DATA &outds;
        SET &inds;
        BY customer_id;

        /* Retain variables for calculations */
        RETAIN txn_count_&window_days.d 0
               txn_amount_&window_days.d 0
               last_txn_date .;

        /* Reset on new customer */
        if FIRST.customer_id then do;
            txn_count_&window_days.d = 0;
            txn_amount_&window_days.d = 0;
            last_txn_date = .;
        end;

        /* Calculate days since last transaction */
        if NOT missing(last_txn_date) then 
            days_since_last_txn = transaction_date_sas - last_txn_date;
        else 
            days_since_last_txn = .;

        /* Update counters (rolling window) */
        if NOT missing(last_txn_date) then do;
            if days_since_last_txn <= &window_days then do;
                txn_count_&window_days.d + 1;
                txn_amount_&window_days.d + amount;
            end;
            else do;
                txn_count_&window_days.d = 1;
                txn_amount_&window_days.d = amount;
            end;
        end;
        else do;
            txn_count_&window_days.d = 1;
            txn_amount_&window_days.d = amount;
        end;

        /* Update last transaction date */
        last_txn_date = transaction_date_sas;

        /* Calculate average transaction amount in window */
        if txn_count_&window_days.d > 0 then 
            avg_txn_amount_&window_days.d = txn_amount_&window_days.d / txn_count_&window_days.d;
        else 
            avg_txn_amount_&window_days.d = 0;

        DROP last_txn_date;

    RUN;

    %PUT NOTE: Calculated velocity features for &window_days day window;

%mend CALCULATE_VELOCITY;

/* MACRO 2: Calculate amount deviation */
%macro CALCULATE_AMOUNT_DEVIATION(inds=, outds=);

    /* Calculate customer statistics */
    PROC MEANS DATA=&inds NOPRINT;
        BY customer_id;
        VAR amount;
        OUTPUT OUT=customer_stats
            MEAN=customer_avg_amount
            STD=customer_std_amount
            N=customer_txn_count;
    RUN;

    /* Merge statistics back */
    PROC SQL;
        CREATE TABLE &outds AS
        SELECT 
            a.*,
            b.customer_avg_amount,
            b.customer_std_amount,
            b.customer_txn_count,
            /* Calculate z-score */
            CASE 
                WHEN b.customer_std_amount > 0 THEN
                    (a.amount - b.customer_avg_amount) / b.customer_std_amount
                ELSE 0
            END AS amount_zscore,
            /* Calculate percentage deviation */
            CASE
                WHEN b.customer_avg_amount > 0 THEN
                    ((a.amount - b.customer_avg_amount) / b.customer_avg_amount) * 100
                ELSE 0
            END AS amount_pct_deviation
        FROM &inds a
        LEFT JOIN customer_stats b
        ON a.customer_id = b.customer_id;
    QUIT;

    %PUT NOTE: Calculated amount deviation features;

%mend CALCULATE_AMOUNT_DEVIATION;

/* MACRO 3: Create time-based features */
%macro CREATE_TIME_FEATURES(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Extract time components */
        txn_hour = HOUR(transaction_time);
        txn_day_of_week = WEEKDAY(transaction_date_sas);
        txn_day_of_month = DAY(transaction_date_sas);
        txn_month = MONTH(transaction_date_sas);

        /* Create time-of-day categories */
        length time_of_day $20;
        if txn_hour >= 0 AND txn_hour < 6 then time_of_day = 'NIGHT';
        else if txn_hour >= 6 AND txn_hour < 12 then time_of_day = 'MORNING';
        else if txn_hour >= 12 AND txn_hour < 18 then time_of_day = 'AFTERNOON';
        else time_of_day = 'EVENING';

        /* Create weekend flag */
        is_weekend = (txn_day_of_week IN (1, 7));  /* Sunday=1, Saturday=7 */

        /* Create unusual hour flag */
        is_unusual_hour = (txn_hour >= 0 AND txn_hour < 6);

    RUN;

    %PUT NOTE: Created time-based features;

%mend CREATE_TIME_FEATURES;

/* MACRO 4: Create location features */
%macro CREATE_LOCATION_FEATURES(inds=, outds=);

    /* Calculate country transaction counts */
    PROC SQL;
        CREATE TABLE country_counts AS
        SELECT 
            country_code_clean,
            COUNT(*) AS country_txn_count
        FROM &inds
        GROUP BY country_code_clean;
    QUIT;

    /* Merge back and create features */
    PROC SQL;
        CREATE TABLE &outds AS
        SELECT 
            a.*,
            b.country_txn_count,
            /* Flag for rare countries */
            CASE 
                WHEN b.country_txn_count < 10 THEN 1
                ELSE 0
            END AS is_rare_country,
            /* Check if international transaction */
            CASE
                WHEN a.country_code_clean NE 'US' THEN 1
                ELSE 0
            END AS is_international
        FROM &inds a
        LEFT JOIN country_counts b
        ON a.country_code_clean = b.country_code_clean;
    QUIT;

    %PUT NOTE: Created location-based features;

%mend CREATE_LOCATION_FEATURES;

/* Execute feature engineering pipeline */
%CALCULATE_VELOCITY(
    inds=&input_lib..transactions_final,
    outds=&output_lib..txn_with_velocity,
    window_days=7
);

%CALCULATE_AMOUNT_DEVIATION(
    inds=&output_lib..txn_with_velocity,
    outds=&output_lib..txn_with_deviation
);

%CREATE_TIME_FEATURES(
    inds=&output_lib..txn_with_deviation,
    outds=&output_lib..txn_with_time_features
);

%CREATE_LOCATION_FEATURES(
    inds=&output_lib..txn_with_time_features,
    outds=&output_lib..transactions_engineered
);

/* Display sample of engineered features */
PROC PRINT DATA=&output_lib..transactions_engineered(OBS=10);
    VAR transaction_id customer_id amount 
        txn_count_7d avg_txn_amount_7d amount_zscore
        time_of_day is_weekend is_unusual_hour;
    TITLE 'Sample of Engineered Features';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 02_data_quality_cleaning
```sas
/*******************************************************************************
* Program: 02_data_quality_cleaning.sas
* Purpose: Clean and standardize transaction data
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Clean transaction data */
%macro CLEAN_TRANSACTIONS(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Standardize transaction type */
        length transaction_type_clean $20;
        transaction_type_clean = UPCASE(STRIP(transaction_type));

        /* Clean merchant name */
        length merchant_name_clean $100;
        merchant_name_clean = PROPCASE(STRIP(merchant_name));

        /* Standardize country code */
        length country_code_clean $2;
        country_code_clean = UPCASE(SUBSTR(country_code, 1, 2));

        /* Handle missing amounts - replace with 0 */
        if missing(amount) then amount = 0;

        /* Convert transaction date to SAS date */
        if NOT missing(transaction_date) then do;
            transaction_date_sas = INPUT(transaction_date, YYMMDD10.);
            FORMAT transaction_date_sas DATE9.;
        end;

        /* Create transaction timestamp */
        transaction_datetime = DHMS(transaction_date_sas, 
                                   HOUR(transaction_time), 
                                   MINUTE(transaction_time), 
                                   SECOND(transaction_time));
        FORMAT transaction_datetime DATETIME20.;

    RUN;

    %PUT NOTE: Cleaned &inds to &outds;

%mend CLEAN_TRANSACTIONS;

/* MACRO 2: Remove duplicates */
%macro REMOVE_DUPLICATES(inds=, outds=, key=);

    /* Sort by key */
    PROC SORT DATA=&inds OUT=&outds NODUPKEY;
        BY &key;
    RUN;

    /* Log duplicate removal */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :before_count FROM &inds;
        SELECT COUNT(*) INTO :after_count FROM &outds;
    QUIT;

    %let dup_count = %EVAL(&before_count - &after_count);
    %PUT NOTE: Removed &dup_count duplicate records;

%mend REMOVE_DUPLICATES;

/* MACRO 3: Handle outliers */
%macro HANDLE_OUTLIERS(inds=, outds=, var=, method=WINSORIZE);

    /* Calculate percentiles */
    PROC MEANS DATA=&inds NOPRINT;
        VAR &var;
        OUTPUT OUT=percentiles
            P1=p1 P99=p99;
    RUN;

    /* Get percentile values */
    DATA _NULL_;
        SET percentiles;
        CALL SYMPUTX('p1_value', p1);
        CALL SYMPUTX('p99_value', p99);
    RUN;

    /* Apply outlier handling */
    DATA &outds;
        SET &inds;

        %if &method = WINSORIZE %then %do;
            /* Winsorize: Cap at 1st and 99th percentiles */
            if &var < &p1_value then &var = &p1_value;
            else if &var > &p99_value then &var = &p99_value;
        %end;
        %else %if &method = REMOVE %then %do;
            /* Remove outliers */
            if &var >= &p1_value AND &var <= &p99_value;
        %end;

    RUN;

    %PUT NOTE: Handled outliers in &var using &method method;

%mend HANDLE_OUTLIERS;

/* Execute cleaning pipeline */
%CLEAN_TRANSACTIONS(
    inds=&input_lib..transactions_validated,
    outds=&output_lib..transactions_cleaned
);

%REMOVE_DUPLICATES(
    inds=&output_lib..transactions_cleaned,
    outds=&output_lib..transactions_deduped,
    key=transaction_id
);

%HANDLE_OUTLIERS(
    inds=&output_lib..transactions_deduped,
    outds=&output_lib..transactions_final,
    var=amount,
    method=WINSORIZE
);

/* Display results */
PROC MEANS DATA=&output_lib..transactions_final N MEAN STD MIN MAX;
    VAR amount;
    TITLE 'Transaction Amount Statistics After Cleaning';
RUN;
```

## Content of 03_feature_engineering
```sas
/*******************************************************************************
* Program: 03_feature_engineering.sas
* Purpose: Create features for fraud detection
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Calculate velocity features */
%macro CALCULATE_VELOCITY(inds=, outds=, window_days=7);

    /* Sort by customer and date */
    PROC SORT DATA=&inds;
        BY customer_id transaction_date_sas transaction_time;
    RUN;

    /* Calculate velocity features */
    DATA &outds;
        SET &inds;
        BY customer_id;

        /* Retain variables for calculations */
        RETAIN txn_count_&window_days.d 0
               txn_amount_&window_days.d 0
               last_txn_date .;

        /* Reset on new customer */
        if FIRST.customer_id then do;
            txn_count_&window_days.d = 0;
            txn_amount_&window_days.d = 0;
            last_txn_date = .;
        end;

        /* Calculate days since last transaction */
        if NOT missing(last_txn_date) then 
            days_since_last_txn = transaction_date_sas - last_txn_date;
        else 
            days_since_last_txn = .;

        /* Update counters (rolling window) */
        if NOT missing(last_txn_date) then do;
            if days_since_last_txn <= &window_days then do;
                txn_count_&window_days.d + 1;
                txn_amount_&window_days.d + amount;
            end;
            else do;
                txn_count_&window_days.d = 1;
                txn_amount_&window_days.d = amount;
            end;
        end;
        else do;
            txn_count_&window_days.d = 1;
            txn_amount_&window_days.d = amount;
        end;

        /* Update last transaction date */
        last_txn_date = transaction_date_sas;

        /* Calculate average transaction amount in window */
        if txn_count_&window_days.d > 0 then 
            avg_txn_amount_&window_days.d = txn_amount_&window_days.d / txn_count_&window_days.d;
        else 
            avg_txn_amount_&window_days.d = 0;

        DROP last_txn_date;

    RUN;

    %PUT NOTE: Calculated velocity features for &window_days day window;

%mend CALCULATE_VELOCITY;

/* MACRO 2: Calculate amount deviation */
%macro CALCULATE_AMOUNT_DEVIATION(inds=, outds=);

    /* Calculate customer statistics */
    PROC MEANS DATA=&inds NOPRINT;
        BY customer_id;
        VAR amount;
        OUTPUT OUT=customer_stats
            MEAN=customer_avg_amount
            STD=customer_std_amount
            N=customer_txn_count;
    RUN;

    /* Merge statistics back */
    PROC SQL;
        CREATE TABLE &outds AS
        SELECT 
            a.*,
            b.customer_avg_amount,
            b.customer_std_amount,
            b.customer_txn_count,
            /* Calculate z-score */
            CASE 
                WHEN b.customer_std_amount > 0 THEN
                    (a.amount - b.customer_avg_amount) / b.customer_std_amount
                ELSE 0
            END AS amount_zscore,
            /* Calculate percentage deviation */
            CASE
                WHEN b.customer_avg_amount > 0 THEN
                    ((a.amount - b.customer_avg_amount) / b.customer_avg_amount) * 100
                ELSE 0
            END AS amount_pct_deviation
        FROM &inds a
        LEFT JOIN customer_stats b
        ON a.customer_id = b.customer_id;
    QUIT;

    %PUT NOTE: Calculated amount deviation features;

%mend CALCULATE_AMOUNT_DEVIATION;

/* MACRO 3: Create time-based features */
%macro CREATE_TIME_FEATURES(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Extract time components */
        txn_hour = HOUR(transaction_time);
        txn_day_of_week = WEEKDAY(transaction_date_sas);
        txn_day_of_month = DAY(transaction_date_sas);
        txn_month = MONTH(transaction_date_sas);

        /* Create time-of-day categories */
        length time_of_day $20;
        if txn_hour >= 0 AND txn_hour < 6 then time_of_day = 'NIGHT';
        else if txn_hour >= 6 AND txn_hour < 12 then time_of_day = 'MORNING';
        else if txn_hour >= 12 AND txn_hour < 18 then time_of_day = 'AFTERNOON';
        else time_of_day = 'EVENING';

        /* Create weekend flag */
        is_weekend = (txn_day_of_week IN (1, 7));  /* Sunday=1, Saturday=7 */

        /* Create unusual hour flag */
        is_unusual_hour = (txn_hour >= 0 AND txn_hour < 6);

    RUN;

    %PUT NOTE: Created time-based features;

%mend CREATE_TIME_FEATURES;

/* MACRO 4: Create location features */
%macro CREATE_LOCATION_FEATURES(inds=, outds=);

    /* Calculate country transaction counts */
    PROC SQL;
        CREATE TABLE country_counts AS
        SELECT 
            country_code_clean,
            COUNT(*) AS country_txn_count
        FROM &inds
        GROUP BY country_code_clean;
    QUIT;

    /* Merge back and create features */
    PROC SQL;
        CREATE TABLE &outds AS
        SELECT 
            a.*,
            b.country_txn_count,
            /* Flag for rare countries */
            CASE 
                WHEN b.country_txn_count < 10 THEN 1
                ELSE 0
            END AS is_rare_country,
            /* Check if international transaction */
            CASE
                WHEN a.country_code_clean NE 'US' THEN 1
                ELSE 0
            END AS is_international
        FROM &inds a
        LEFT JOIN country_counts b
        ON a.country_code_clean = b.country_code_clean;
    QUIT;

    %PUT NOTE: Created location-based features;

%mend CREATE_LOCATION_FEATURES;

/* Execute feature engineering pipeline */
%CALCULATE_VELOCITY(
    inds=&input_lib..transactions_final,
    outds=&output_lib..txn_with_velocity,
    window_days=7
);

%CALCULATE_AMOUNT_DEVIATION(
    inds=&output_lib..txn_with_velocity,
    outds=&output_lib..txn_with_deviation
);

%CREATE_TIME_FEATURES(
    inds=&output_lib..txn_with_deviation,
    outds=&output_lib..txn_with_time_features
);

%CREATE_LOCATION_FEATURES(
    inds=&output_lib..txn_with_time_features,
    outds=&output_lib..transactions_engineered
);

/* Display sample of engineered features */
PROC PRINT DATA=&output_lib..transactions_engineered(OBS=10);
    VAR transaction_id customer_id amount 
        txn_count_7d avg_txn_amount_7d amount_zscore
        time_of_day is_weekend is_unusual_hour;
    TITLE 'Sample of Engineered Features';
RUN;
```

## Content of 04_rule_based_detection
```sas
/*******************************************************************************
* Program: 04_rule_based_detection.sas
* Purpose: Apply rule-based fraud detection logic
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Define fraud detection rules */
%macro APPLY_FRAUD_RULES(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Initialize rule flags and scores */
        length rule_triggered $200;
        rule_triggered = '';
        rule_score = 0;

        /* RULE 1: High velocity (>10 transactions in 7 days) */
        if txn_count_7d > 10 then do;
            rule_triggered = CATX(', ', rule_triggered, 'HIGH_VELOCITY');
            rule_score = rule_score + 25;
        end;

        /* RULE 2: Large amount deviation (>3 standard deviations) */
        if ABS(amount_zscore) > 3 then do;
            rule_triggered = CATX(', ', rule_triggered, 'AMOUNT_DEVIATION');
            rule_score = rule_score + 30;
        end;

        /* RULE 3: High amount (>$5000) */
        if amount > 5000 then do;
            rule_triggered = CATX(', ', rule_triggered, 'HIGH_AMOUNT');
            rule_score = rule_score + 20;
        end;

        /* RULE 4: Unusual hour transaction */
        if is_unusual_hour = 1 then do;
            rule_triggered = CATX(', ', rule_triggered, 'UNUSUAL_HOUR');
            rule_score = rule_score + 15;
        end;

        /* RULE 5: International transaction */
        if is_international = 1 then do;
            rule_triggered = CATX(', ', rule_triggered, 'INTERNATIONAL');
            rule_score = rule_score + 10;
        end;

        /* RULE 6: Rare country */
        if is_rare_country = 1 then do;
            rule_triggered = CATX(', ', rule_triggered, 'RARE_COUNTRY');
            rule_score = rule_score + 15;
        end;

        /* RULE 7: Multiple transactions in short time */
        if days_since_last_txn < 0.042 then do;  /* Less than 1 hour */
            rule_triggered = CATX(', ', rule_triggered, 'RAPID_SUCCESSION');
            rule_score = rule_score + 25;
        end;

        /* RULE 8: Round amount (potentially suspicious) */
        if MOD(amount, 100) = 0 AND amount >= 1000 then do;
            rule_triggered = CATX(', ', rule_triggered, 'ROUND_AMOUNT');
            rule_score = rule_score + 10;
        end;

        /* Calculate final rule-based risk level */
        length rule_risk_level $10;
        if rule_score >= 75 then rule_risk_level = 'CRITICAL';
        else if rule_score >= 50 then rule_risk_level = 'HIGH';
        else if rule_score >= 25 then rule_risk_level = 'MEDIUM';
        else rule_risk_level = 'LOW';

        /* Flag for investigation */
        is_suspicious = (rule_score >= 50);

    RUN;

    %PUT NOTE: Applied fraud detection rules;

%mend APPLY_FRAUD_RULES;

/* MACRO 2: Generate rule-based alerts */
%macro GENERATE_RULE_ALERTS(inds=, outds=, threshold=50);

    /* Filter suspicious transactions */
    DATA &outds;
        SET &inds;
        WHERE rule_score >= &threshold;
    RUN;

    /* Sort by risk score */
    PROC SORT DATA=&outds;
        BY DESCENDING rule_score transaction_date_sas;
    RUN;

    /* Count alerts by risk level */
    PROC FREQ DATA=&outds;
        TABLES rule_risk_level / NOCUM;
        TITLE "Rule-Based Alerts by Risk Level (Score >= &threshold)";
    RUN;

    /* Log alert counts */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :alert_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %let alert_rate = %SYSEVALF((&alert_count / &total_count) * 100);
    %PUT NOTE: Generated &alert_count alerts (&alert_rate% of transactions);

%mend GENERATE_RULE_ALERTS;

/* MACRO 3: Create rule summary report */
%macro RULE_SUMMARY_REPORT(inds=);

    /* Count by rule */
    PROC SQL;
        CREATE TABLE rule_summary AS
        SELECT 
            'HIGH_VELOCITY' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'HIGH_VELOCITY') > 0 THEN 1 ELSE 0 END) AS trigger_count
        FROM &inds
        UNION ALL
        SELECT 
            'AMOUNT_DEVIATION' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'AMOUNT_DEVIATION') > 0 THEN 1 ELSE 0 END)
        FROM &inds
        UNION ALL
        SELECT 
            'HIGH_AMOUNT' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'HIGH_AMOUNT') > 0 THEN 1 ELSE 0 END)
        FROM &inds
        UNION ALL
        SELECT 
            'UNUSUAL_HOUR' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'UNUSUAL_HOUR') > 0 THEN 1 ELSE 0 END)
        FROM &inds
        UNION ALL
        SELECT 
            'INTERNATIONAL' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'INTERNATIONAL') > 0 THEN 1 ELSE 0 END)
        FROM &inds;
    QUIT;

    /* Display summary */
    PROC PRINT DATA=rule_summary;
        TITLE 'Fraud Rule Trigger Summary';
    RUN;

%mend RULE_SUMMARY_REPORT;

/* Execute rule-based detection */
%APPLY_FRAUD_RULES(
    inds=&input_lib..transactions_engineered,
    outds=&output_lib..transactions_with_rules
);

%GENERATE_RULE_ALERTS(
    inds=&output_lib..transactions_with_rules,
    outds=&output_lib..rule_based_alerts,
    threshold=50
);

%RULE_SUMMARY_REPORT(
    inds=&output_lib..transactions_with_rules
);

/* Display top alerts */
PROC PRINT DATA=&output_lib..rule_based_alerts(OBS=20);
    VAR transaction_id customer_id amount rule_score rule_risk_level rule_triggered;
    TITLE 'Top 20 Rule-Based Fraud Alerts';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 02_data_quality_cleaning
```sas
/*******************************************************************************
* Program: 02_data_quality_cleaning.sas
* Purpose: Clean and standardize transaction data
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Clean transaction data */
%macro CLEAN_TRANSACTIONS(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Standardize transaction type */
        length transaction_type_clean $20;
        transaction_type_clean = UPCASE(STRIP(transaction_type));

        /* Clean merchant name */
        length merchant_name_clean $100;
        merchant_name_clean = PROPCASE(STRIP(merchant_name));

        /* Standardize country code */
        length country_code_clean $2;
        country_code_clean = UPCASE(SUBSTR(country_code, 1, 2));

        /* Handle missing amounts - replace with 0 */
        if missing(amount) then amount = 0;

        /* Convert transaction date to SAS date */
        if NOT missing(transaction_date) then do;
            transaction_date_sas = INPUT(transaction_date, YYMMDD10.);
            FORMAT transaction_date_sas DATE9.;
        end;

        /* Create transaction timestamp */
        transaction_datetime = DHMS(transaction_date_sas, 
                                   HOUR(transaction_time), 
                                   MINUTE(transaction_time), 
                                   SECOND(transaction_time));
        FORMAT transaction_datetime DATETIME20.;

    RUN;

    %PUT NOTE: Cleaned &inds to &outds;

%mend CLEAN_TRANSACTIONS;

/* MACRO 2: Remove duplicates */
%macro REMOVE_DUPLICATES(inds=, outds=, key=);

    /* Sort by key */
    PROC SORT DATA=&inds OUT=&outds NODUPKEY;
        BY &key;
    RUN;

    /* Log duplicate removal */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :before_count FROM &inds;
        SELECT COUNT(*) INTO :after_count FROM &outds;
    QUIT;

    %let dup_count = %EVAL(&before_count - &after_count);
    %PUT NOTE: Removed &dup_count duplicate records;

%mend REMOVE_DUPLICATES;

/* MACRO 3: Handle outliers */
%macro HANDLE_OUTLIERS(inds=, outds=, var=, method=WINSORIZE);

    /* Calculate percentiles */
    PROC MEANS DATA=&inds NOPRINT;
        VAR &var;
        OUTPUT OUT=percentiles
            P1=p1 P99=p99;
    RUN;

    /* Get percentile values */
    DATA _NULL_;
        SET percentiles;
        CALL SYMPUTX('p1_value', p1);
        CALL SYMPUTX('p99_value', p99);
    RUN;

    /* Apply outlier handling */
    DATA &outds;
        SET &inds;

        %if &method = WINSORIZE %then %do;
            /* Winsorize: Cap at 1st and 99th percentiles */
            if &var < &p1_value then &var = &p1_value;
            else if &var > &p99_value then &var = &p99_value;
        %end;
        %else %if &method = REMOVE %then %do;
            /* Remove outliers */
            if &var >= &p1_value AND &var <= &p99_value;
        %end;

    RUN;

    %PUT NOTE: Handled outliers in &var using &method method;

%mend HANDLE_OUTLIERS;

/* Execute cleaning pipeline */
%CLEAN_TRANSACTIONS(
    inds=&input_lib..transactions_validated,
    outds=&output_lib..transactions_cleaned
);

%REMOVE_DUPLICATES(
    inds=&output_lib..transactions_cleaned,
    outds=&output_lib..transactions_deduped,
    key=transaction_id
);

%HANDLE_OUTLIERS(
    inds=&output_lib..transactions_deduped,
    outds=&output_lib..transactions_final,
    var=amount,
    method=WINSORIZE
);

/* Display results */
PROC MEANS DATA=&output_lib..transactions_final N MEAN STD MIN MAX;
    VAR amount;
    TITLE 'Transaction Amount Statistics After Cleaning';
RUN;
```

## Content of 03_feature_engineering
```sas
/*******************************************************************************
* Program: 03_feature_engineering.sas
* Purpose: Create features for fraud detection
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Calculate velocity features */
%macro CALCULATE_VELOCITY(inds=, outds=, window_days=7);

    /* Sort by customer and date */
    PROC SORT DATA=&inds;
        BY customer_id transaction_date_sas transaction_time;
    RUN;

    /* Calculate velocity features */
    DATA &outds;
        SET &inds;
        BY customer_id;

        /* Retain variables for calculations */
        RETAIN txn_count_&window_days.d 0
               txn_amount_&window_days.d 0
               last_txn_date .;

        /* Reset on new customer */
        if FIRST.customer_id then do;
            txn_count_&window_days.d = 0;
            txn_amount_&window_days.d = 0;
            last_txn_date = .;
        end;

        /* Calculate days since last transaction */
        if NOT missing(last_txn_date) then 
            days_since_last_txn = transaction_date_sas - last_txn_date;
        else 
            days_since_last_txn = .;

        /* Update counters (rolling window) */
        if NOT missing(last_txn_date) then do;
            if days_since_last_txn <= &window_days then do;
                txn_count_&window_days.d + 1;
                txn_amount_&window_days.d + amount;
            end;
            else do;
                txn_count_&window_days.d = 1;
                txn_amount_&window_days.d = amount;
            end;
        end;
        else do;
            txn_count_&window_days.d = 1;
            txn_amount_&window_days.d = amount;
        end;

        /* Update last transaction date */
        last_txn_date = transaction_date_sas;

        /* Calculate average transaction amount in window */
        if txn_count_&window_days.d > 0 then 
            avg_txn_amount_&window_days.d = txn_amount_&window_days.d / txn_count_&window_days.d;
        else 
            avg_txn_amount_&window_days.d = 0;

        DROP last_txn_date;

    RUN;

    %PUT NOTE: Calculated velocity features for &window_days day window;

%mend CALCULATE_VELOCITY;

/* MACRO 2: Calculate amount deviation */
%macro CALCULATE_AMOUNT_DEVIATION(inds=, outds=);

    /* Calculate customer statistics */
    PROC MEANS DATA=&inds NOPRINT;
        BY customer_id;
        VAR amount;
        OUTPUT OUT=customer_stats
            MEAN=customer_avg_amount
            STD=customer_std_amount
            N=customer_txn_count;
    RUN;

    /* Merge statistics back */
    PROC SQL;
        CREATE TABLE &outds AS
        SELECT 
            a.*,
            b.customer_avg_amount,
            b.customer_std_amount,
            b.customer_txn_count,
            /* Calculate z-score */
            CASE 
                WHEN b.customer_std_amount > 0 THEN
                    (a.amount - b.customer_avg_amount) / b.customer_std_amount
                ELSE 0
            END AS amount_zscore,
            /* Calculate percentage deviation */
            CASE
                WHEN b.customer_avg_amount > 0 THEN
                    ((a.amount - b.customer_avg_amount) / b.customer_avg_amount) * 100
                ELSE 0
            END AS amount_pct_deviation
        FROM &inds a
        LEFT JOIN customer_stats b
        ON a.customer_id = b.customer_id;
    QUIT;

    %PUT NOTE: Calculated amount deviation features;

%mend CALCULATE_AMOUNT_DEVIATION;

/* MACRO 3: Create time-based features */
%macro CREATE_TIME_FEATURES(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Extract time components */
        txn_hour = HOUR(transaction_time);
        txn_day_of_week = WEEKDAY(transaction_date_sas);
        txn_day_of_month = DAY(transaction_date_sas);
        txn_month = MONTH(transaction_date_sas);

        /* Create time-of-day categories */
        length time_of_day $20;
        if txn_hour >= 0 AND txn_hour < 6 then time_of_day = 'NIGHT';
        else if txn_hour >= 6 AND txn_hour < 12 then time_of_day = 'MORNING';
        else if txn_hour >= 12 AND txn_hour < 18 then time_of_day = 'AFTERNOON';
        else time_of_day = 'EVENING';

        /* Create weekend flag */
        is_weekend = (txn_day_of_week IN (1, 7));  /* Sunday=1, Saturday=7 */

        /* Create unusual hour flag */
        is_unusual_hour = (txn_hour >= 0 AND txn_hour < 6);

    RUN;

    %PUT NOTE: Created time-based features;

%mend CREATE_TIME_FEATURES;

/* MACRO 4: Create location features */
%macro CREATE_LOCATION_FEATURES(inds=, outds=);

    /* Calculate country transaction counts */
    PROC SQL;
        CREATE TABLE country_counts AS
        SELECT 
            country_code_clean,
            COUNT(*) AS country_txn_count
        FROM &inds
        GROUP BY country_code_clean;
    QUIT;

    /* Merge back and create features */
    PROC SQL;
        CREATE TABLE &outds AS
        SELECT 
            a.*,
            b.country_txn_count,
            /* Flag for rare countries */
            CASE 
                WHEN b.country_txn_count < 10 THEN 1
                ELSE 0
            END AS is_rare_country,
            /* Check if international transaction */
            CASE
                WHEN a.country_code_clean NE 'US' THEN 1
                ELSE 0
            END AS is_international
        FROM &inds a
        LEFT JOIN country_counts b
        ON a.country_code_clean = b.country_code_clean;
    QUIT;

    %PUT NOTE: Created location-based features;

%mend CREATE_LOCATION_FEATURES;

/* Execute feature engineering pipeline */
%CALCULATE_VELOCITY(
    inds=&input_lib..transactions_final,
    outds=&output_lib..txn_with_velocity,
    window_days=7
);

%CALCULATE_AMOUNT_DEVIATION(
    inds=&output_lib..txn_with_velocity,
    outds=&output_lib..txn_with_deviation
);

%CREATE_TIME_FEATURES(
    inds=&output_lib..txn_with_deviation,
    outds=&output_lib..txn_with_time_features
);

%CREATE_LOCATION_FEATURES(
    inds=&output_lib..txn_with_time_features,
    outds=&output_lib..transactions_engineered
);

/* Display sample of engineered features */
PROC PRINT DATA=&output_lib..transactions_engineered(OBS=10);
    VAR transaction_id customer_id amount 
        txn_count_7d avg_txn_amount_7d amount_zscore
        time_of_day is_weekend is_unusual_hour;
    TITLE 'Sample of Engineered Features';
RUN;
```

## Content of 04_rule_based_detection
```sas
/*******************************************************************************
* Program: 04_rule_based_detection.sas
* Purpose: Apply rule-based fraud detection logic
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Define fraud detection rules */
%macro APPLY_FRAUD_RULES(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Initialize rule flags and scores */
        length rule_triggered $200;
        rule_triggered = '';
        rule_score = 0;

        /* RULE 1: High velocity (>10 transactions in 7 days) */
        if txn_count_7d > 10 then do;
            rule_triggered = CATX(', ', rule_triggered, 'HIGH_VELOCITY');
            rule_score = rule_score + 25;
        end;

        /* RULE 2: Large amount deviation (>3 standard deviations) */
        if ABS(amount_zscore) > 3 then do;
            rule_triggered = CATX(', ', rule_triggered, 'AMOUNT_DEVIATION');
            rule_score = rule_score + 30;
        end;

        /* RULE 3: High amount (>$5000) */
        if amount > 5000 then do;
            rule_triggered = CATX(', ', rule_triggered, 'HIGH_AMOUNT');
            rule_score = rule_score + 20;
        end;

        /* RULE 4: Unusual hour transaction */
        if is_unusual_hour = 1 then do;
            rule_triggered = CATX(', ', rule_triggered, 'UNUSUAL_HOUR');
            rule_score = rule_score + 15;
        end;

        /* RULE 5: International transaction */
        if is_international = 1 then do;
            rule_triggered = CATX(', ', rule_triggered, 'INTERNATIONAL');
            rule_score = rule_score + 10;
        end;

        /* RULE 6: Rare country */
        if is_rare_country = 1 then do;
            rule_triggered = CATX(', ', rule_triggered, 'RARE_COUNTRY');
            rule_score = rule_score + 15;
        end;

        /* RULE 7: Multiple transactions in short time */
        if days_since_last_txn < 0.042 then do;  /* Less than 1 hour */
            rule_triggered = CATX(', ', rule_triggered, 'RAPID_SUCCESSION');
            rule_score = rule_score + 25;
        end;

        /* RULE 8: Round amount (potentially suspicious) */
        if MOD(amount, 100) = 0 AND amount >= 1000 then do;
            rule_triggered = CATX(', ', rule_triggered, 'ROUND_AMOUNT');
            rule_score = rule_score + 10;
        end;

        /* Calculate final rule-based risk level */
        length rule_risk_level $10;
        if rule_score >= 75 then rule_risk_level = 'CRITICAL';
        else if rule_score >= 50 then rule_risk_level = 'HIGH';
        else if rule_score >= 25 then rule_risk_level = 'MEDIUM';
        else rule_risk_level = 'LOW';

        /* Flag for investigation */
        is_suspicious = (rule_score >= 50);

    RUN;

    %PUT NOTE: Applied fraud detection rules;

%mend APPLY_FRAUD_RULES;

/* MACRO 2: Generate rule-based alerts */
%macro GENERATE_RULE_ALERTS(inds=, outds=, threshold=50);

    /* Filter suspicious transactions */
    DATA &outds;
        SET &inds;
        WHERE rule_score >= &threshold;
    RUN;

    /* Sort by risk score */
    PROC SORT DATA=&outds;
        BY DESCENDING rule_score transaction_date_sas;
    RUN;

    /* Count alerts by risk level */
    PROC FREQ DATA=&outds;
        TABLES rule_risk_level / NOCUM;
        TITLE "Rule-Based Alerts by Risk Level (Score >= &threshold)";
    RUN;

    /* Log alert counts */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :alert_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %let alert_rate = %SYSEVALF((&alert_count / &total_count) * 100);
    %PUT NOTE: Generated &alert_count alerts (&alert_rate% of transactions);

%mend GENERATE_RULE_ALERTS;

/* MACRO 3: Create rule summary report */
%macro RULE_SUMMARY_REPORT(inds=);

    /* Count by rule */
    PROC SQL;
        CREATE TABLE rule_summary AS
        SELECT 
            'HIGH_VELOCITY' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'HIGH_VELOCITY') > 0 THEN 1 ELSE 0 END) AS trigger_count
        FROM &inds
        UNION ALL
        SELECT 
            'AMOUNT_DEVIATION' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'AMOUNT_DEVIATION') > 0 THEN 1 ELSE 0 END)
        FROM &inds
        UNION ALL
        SELECT 
            'HIGH_AMOUNT' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'HIGH_AMOUNT') > 0 THEN 1 ELSE 0 END)
        FROM &inds
        UNION ALL
        SELECT 
            'UNUSUAL_HOUR' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'UNUSUAL_HOUR') > 0 THEN 1 ELSE 0 END)
        FROM &inds
        UNION ALL
        SELECT 
            'INTERNATIONAL' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'INTERNATIONAL') > 0 THEN 1 ELSE 0 END)
        FROM &inds;
    QUIT;

    /* Display summary */
    PROC PRINT DATA=rule_summary;
        TITLE 'Fraud Rule Trigger Summary';
    RUN;

%mend RULE_SUMMARY_REPORT;

/* Execute rule-based detection */
%APPLY_FRAUD_RULES(
    inds=&input_lib..transactions_engineered,
    outds=&output_lib..transactions_with_rules
);

%GENERATE_RULE_ALERTS(
    inds=&output_lib..transactions_with_rules,
    outds=&output_lib..rule_based_alerts,
    threshold=50
);

%RULE_SUMMARY_REPORT(
    inds=&output_lib..transactions_with_rules
);

/* Display top alerts */
PROC PRINT DATA=&output_lib..rule_based_alerts(OBS=20);
    VAR transaction_id customer_id amount rule_score rule_risk_level rule_triggered;
    TITLE 'Top 20 Rule-Based Fraud Alerts';
RUN;
```

## Content of 05_ml_scoring_model
```sas
/*******************************************************************************
* Program: 05_ml_scoring_model.sas
* Purpose: Apply ML model for fraud probability scoring
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Prepare data for ML scoring */
%macro PREPARE_ML_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create binary flags for categorical variables */
        is_high_amount = (amount > 1000);
        is_very_high_amount = (amount > 5000);

        /* Normalize continuous variables (simple min-max scaling) */
        /* In production, use actual min/max from training data */
        amount_normalized = amount / 10000;  /* Assuming max ~$10k */
        txn_count_normalized = txn_count_7d / 20;  /* Assuming max ~20 */

        /* Handle missing values */
        if missing(amount_zscore) then amount_zscore = 0;
        if missing(days_since_last_txn) then days_since_last_txn = 999;

        /* Create interaction features */
        amount_x_velocity = amount_normalized * txn_count_normalized;
        amount_x_deviation = amount_normalized * ABS(amount_zscore);

    RUN;

    %PUT NOTE: Prepared data for ML scoring;

%mend PREPARE_ML_DATA;

/* MACRO 2: Calculate ML fraud score (simulated logistic regression) */
%macro CALCULATE_ML_SCORE(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Simulated logistic regression coefficients */
        /* In production, these would come from a trained model */

        /* Calculate logit score */
        logit_score = 
            -2.5                                    /* Intercept */
            + 0.8 * amount_normalized               /* Amount effect */
            + 0.6 * txn_count_normalized            /* Velocity effect */
            + 0.4 * ABS(amount_zscore)              /* Deviation effect */
            + 0.5 * is_unusual_hour                 /* Time effect */
            + 0.3 * is_international                /* Location effect */
            + 0.7 * amount_x_velocity               /* Interaction 1 */
            + 0.5 * amount_x_deviation              /* Interaction 2 */
            - 0.2 * customer_txn_count / 100;       /* Customer history */

        /* Convert logit to probability using sigmoid function */
        ml_fraud_probability = 1 / (1 + EXP(-logit_score));

        /* Convert probability to score (0-100) */
        ml_fraud_score = ml_fraud_probability * 100;

        /* Assign ML risk band */
        length ml_risk_band $10;
        if ml_fraud_score >= 80 then ml_risk_band = 'CRITICAL';
        else if ml_fraud_score >= 60 then ml_risk_band = 'HIGH';
        else if ml_fraud_score >= 40 then ml_risk_band = 'MEDIUM';
        else if ml_fraud_score >= 20 then ml_risk_band = 'LOW';
        else ml_risk_band = 'VERY_LOW';

        /* Create ML alert flag */
        ml_alert = (ml_fraud_score >= 60);

        FORMAT ml_fraud_probability PERCENT8.2;

    RUN;

    %PUT NOTE: Calculated ML fraud scores;

%mend CALCULATE_ML_SCORE;

/* MACRO 3: Generate ML performance metrics */
%macro ML_PERFORMANCE_METRICS(inds=);

    /* Distribution of scores */
    PROC MEANS DATA=&inds N MEAN STD MIN P25 MEDIAN P75 MAX;
        VAR ml_fraud_score ml_fraud_probability;
        TITLE 'ML Fraud Score Distribution';
    RUN;

    /* Distribution by risk band */
    PROC FREQ DATA=&inds;
        TABLES ml_risk_band / NOCUM;
        TITLE 'ML Risk Band Distribution';
    RUN;

    /* Alert rate */
    PROC FREQ DATA=&inds;
        TABLES ml_alert / NOCUM;
        TITLE 'ML Alert Rate';
    RUN;

%mend ML_PERFORMANCE_METRICS;

/* MACRO 4: Compare ML vs Rule-based */
%macro COMPARE_MODELS(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Categorize agreement */
        length model_agreement $30;

        if ml_alert = 1 AND is_suspicious = 1 then 
            model_agreement = 'BOTH_ALERT';
        else if ml_alert = 1 AND is_suspicious = 0 then 
            model_agreement = 'ML_ONLY';
        else if ml_alert = 0 AND is_suspicious = 1 then 
            model_agreement = 'RULE_ONLY';
        else 
            model_agreement = 'BOTH_CLEAR';

        /* Calculate combined score */
        combined_score = (ml_fraud_score * 0.6) + (rule_score * 0.4);

        /* Combined risk level */
        length combined_risk_level $10;
        if combined_score >= 75 then combined_risk_level = 'CRITICAL';
        else if combined_score >= 50 then combined_risk_level = 'HIGH';
        else if combined_score >= 25 then combined_risk_level = 'MEDIUM';
        else combined_risk_level = 'LOW';

    RUN;

    /* Model agreement summary */
    PROC FREQ DATA=&outds;
        TABLES model_agreement / NOCUM;
        TITLE 'Model Agreement Analysis';
    RUN;

    /* Correlation between scores */
    PROC CORR DATA=&outds NOSIMPLE;
        VAR ml_fraud_score rule_score;
        TITLE 'Correlation: ML Score vs Rule Score';
    RUN;

    %PUT NOTE: Generated model comparison;

%mend COMPARE_MODELS;

/* Execute ML scoring pipeline */
%PREPARE_ML_DATA(
    inds=&input_lib..transactions_with_rules,
    outds=&output_lib..ml_data_prepared
);

%CALCULATE_ML_SCORE(
    inds=&output_lib..ml_data_prepared,
    outds=&output_lib..transactions_ml_scored
);

%ML_PERFORMANCE_METRICS(
    inds=&output_lib..transactions_ml_scored
);

%COMPARE_MODELS(
    inds=&output_lib..transactions_ml_scored,
    outds=&output_lib..transactions_combined_score
);

/* Display top ML alerts */
PROC PRINT DATA=&output_lib..transactions_ml_scored(OBS=20);
    WHERE ml_alert = 1;
    VAR transaction_id customer_id amount ml_fraud_score ml_fraud_probability 
        ml_risk_band rule_score;
    TITLE 'Top 20 ML-Based Fraud Alerts';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 02_data_quality_cleaning
```sas
/*******************************************************************************
* Program: 02_data_quality_cleaning.sas
* Purpose: Clean and standardize transaction data
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Clean transaction data */
%macro CLEAN_TRANSACTIONS(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Standardize transaction type */
        length transaction_type_clean $20;
        transaction_type_clean = UPCASE(STRIP(transaction_type));

        /* Clean merchant name */
        length merchant_name_clean $100;
        merchant_name_clean = PROPCASE(STRIP(merchant_name));

        /* Standardize country code */
        length country_code_clean $2;
        country_code_clean = UPCASE(SUBSTR(country_code, 1, 2));

        /* Handle missing amounts - replace with 0 */
        if missing(amount) then amount = 0;

        /* Convert transaction date to SAS date */
        if NOT missing(transaction_date) then do;
            transaction_date_sas = INPUT(transaction_date, YYMMDD10.);
            FORMAT transaction_date_sas DATE9.;
        end;

        /* Create transaction timestamp */
        transaction_datetime = DHMS(transaction_date_sas, 
                                   HOUR(transaction_time), 
                                   MINUTE(transaction_time), 
                                   SECOND(transaction_time));
        FORMAT transaction_datetime DATETIME20.;

    RUN;

    %PUT NOTE: Cleaned &inds to &outds;

%mend CLEAN_TRANSACTIONS;

/* MACRO 2: Remove duplicates */
%macro REMOVE_DUPLICATES(inds=, outds=, key=);

    /* Sort by key */
    PROC SORT DATA=&inds OUT=&outds NODUPKEY;
        BY &key;
    RUN;

    /* Log duplicate removal */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :before_count FROM &inds;
        SELECT COUNT(*) INTO :after_count FROM &outds;
    QUIT;

    %let dup_count = %EVAL(&before_count - &after_count);
    %PUT NOTE: Removed &dup_count duplicate records;

%mend REMOVE_DUPLICATES;

/* MACRO 3: Handle outliers */
%macro HANDLE_OUTLIERS(inds=, outds=, var=, method=WINSORIZE);

    /* Calculate percentiles */
    PROC MEANS DATA=&inds NOPRINT;
        VAR &var;
        OUTPUT OUT=percentiles
            P1=p1 P99=p99;
    RUN;

    /* Get percentile values */
    DATA _NULL_;
        SET percentiles;
        CALL SYMPUTX('p1_value', p1);
        CALL SYMPUTX('p99_value', p99);
    RUN;

    /* Apply outlier handling */
    DATA &outds;
        SET &inds;

        %if &method = WINSORIZE %then %do;
            /* Winsorize: Cap at 1st and 99th percentiles */
            if &var < &p1_value then &var = &p1_value;
            else if &var > &p99_value then &var = &p99_value;
        %end;
        %else %if &method = REMOVE %then %do;
            /* Remove outliers */
            if &var >= &p1_value AND &var <= &p99_value;
        %end;

    RUN;

    %PUT NOTE: Handled outliers in &var using &method method;

%mend HANDLE_OUTLIERS;

/* Execute cleaning pipeline */
%CLEAN_TRANSACTIONS(
    inds=&input_lib..transactions_validated,
    outds=&output_lib..transactions_cleaned
);

%REMOVE_DUPLICATES(
    inds=&output_lib..transactions_cleaned,
    outds=&output_lib..transactions_deduped,
    key=transaction_id
);

%HANDLE_OUTLIERS(
    inds=&output_lib..transactions_deduped,
    outds=&output_lib..transactions_final,
    var=amount,
    method=WINSORIZE
);

/* Display results */
PROC MEANS DATA=&output_lib..transactions_final N MEAN STD MIN MAX;
    VAR amount;
    TITLE 'Transaction Amount Statistics After Cleaning';
RUN;
```

## Content of 03_feature_engineering
```sas
/*******************************************************************************
* Program: 03_feature_engineering.sas
* Purpose: Create features for fraud detection
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Calculate velocity features */
%macro CALCULATE_VELOCITY(inds=, outds=, window_days=7);

    /* Sort by customer and date */
    PROC SORT DATA=&inds;
        BY customer_id transaction_date_sas transaction_time;
    RUN;

    /* Calculate velocity features */
    DATA &outds;
        SET &inds;
        BY customer_id;

        /* Retain variables for calculations */
        RETAIN txn_count_&window_days.d 0
               txn_amount_&window_days.d 0
               last_txn_date .;

        /* Reset on new customer */
        if FIRST.customer_id then do;
            txn_count_&window_days.d = 0;
            txn_amount_&window_days.d = 0;
            last_txn_date = .;
        end;

        /* Calculate days since last transaction */
        if NOT missing(last_txn_date) then 
            days_since_last_txn = transaction_date_sas - last_txn_date;
        else 
            days_since_last_txn = .;

        /* Update counters (rolling window) */
        if NOT missing(last_txn_date) then do;
            if days_since_last_txn <= &window_days then do;
                txn_count_&window_days.d + 1;
                txn_amount_&window_days.d + amount;
            end;
            else do;
                txn_count_&window_days.d = 1;
                txn_amount_&window_days.d = amount;
            end;
        end;
        else do;
            txn_count_&window_days.d = 1;
            txn_amount_&window_days.d = amount;
        end;

        /* Update last transaction date */
        last_txn_date = transaction_date_sas;

        /* Calculate average transaction amount in window */
        if txn_count_&window_days.d > 0 then 
            avg_txn_amount_&window_days.d = txn_amount_&window_days.d / txn_count_&window_days.d;
        else 
            avg_txn_amount_&window_days.d = 0;

        DROP last_txn_date;

    RUN;

    %PUT NOTE: Calculated velocity features for &window_days day window;

%mend CALCULATE_VELOCITY;

/* MACRO 2: Calculate amount deviation */
%macro CALCULATE_AMOUNT_DEVIATION(inds=, outds=);

    /* Calculate customer statistics */
    PROC MEANS DATA=&inds NOPRINT;
        BY customer_id;
        VAR amount;
        OUTPUT OUT=customer_stats
            MEAN=customer_avg_amount
            STD=customer_std_amount
            N=customer_txn_count;
    RUN;

    /* Merge statistics back */
    PROC SQL;
        CREATE TABLE &outds AS
        SELECT 
            a.*,
            b.customer_avg_amount,
            b.customer_std_amount,
            b.customer_txn_count,
            /* Calculate z-score */
            CASE 
                WHEN b.customer_std_amount > 0 THEN
                    (a.amount - b.customer_avg_amount) / b.customer_std_amount
                ELSE 0
            END AS amount_zscore,
            /* Calculate percentage deviation */
            CASE
                WHEN b.customer_avg_amount > 0 THEN
                    ((a.amount - b.customer_avg_amount) / b.customer_avg_amount) * 100
                ELSE 0
            END AS amount_pct_deviation
        FROM &inds a
        LEFT JOIN customer_stats b
        ON a.customer_id = b.customer_id;
    QUIT;

    %PUT NOTE: Calculated amount deviation features;

%mend CALCULATE_AMOUNT_DEVIATION;

/* MACRO 3: Create time-based features */
%macro CREATE_TIME_FEATURES(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Extract time components */
        txn_hour = HOUR(transaction_time);
        txn_day_of_week = WEEKDAY(transaction_date_sas);
        txn_day_of_month = DAY(transaction_date_sas);
        txn_month = MONTH(transaction_date_sas);

        /* Create time-of-day categories */
        length time_of_day $20;
        if txn_hour >= 0 AND txn_hour < 6 then time_of_day = 'NIGHT';
        else if txn_hour >= 6 AND txn_hour < 12 then time_of_day = 'MORNING';
        else if txn_hour >= 12 AND txn_hour < 18 then time_of_day = 'AFTERNOON';
        else time_of_day = 'EVENING';

        /* Create weekend flag */
        is_weekend = (txn_day_of_week IN (1, 7));  /* Sunday=1, Saturday=7 */

        /* Create unusual hour flag */
        is_unusual_hour = (txn_hour >= 0 AND txn_hour < 6);

    RUN;

    %PUT NOTE: Created time-based features;

%mend CREATE_TIME_FEATURES;

/* MACRO 4: Create location features */
%macro CREATE_LOCATION_FEATURES(inds=, outds=);

    /* Calculate country transaction counts */
    PROC SQL;
        CREATE TABLE country_counts AS
        SELECT 
            country_code_clean,
            COUNT(*) AS country_txn_count
        FROM &inds
        GROUP BY country_code_clean;
    QUIT;

    /* Merge back and create features */
    PROC SQL;
        CREATE TABLE &outds AS
        SELECT 
            a.*,
            b.country_txn_count,
            /* Flag for rare countries */
            CASE 
                WHEN b.country_txn_count < 10 THEN 1
                ELSE 0
            END AS is_rare_country,
            /* Check if international transaction */
            CASE
                WHEN a.country_code_clean NE 'US' THEN 1
                ELSE 0
            END AS is_international
        FROM &inds a
        LEFT JOIN country_counts b
        ON a.country_code_clean = b.country_code_clean;
    QUIT;

    %PUT NOTE: Created location-based features;

%mend CREATE_LOCATION_FEATURES;

/* Execute feature engineering pipeline */
%CALCULATE_VELOCITY(
    inds=&input_lib..transactions_final,
    outds=&output_lib..txn_with_velocity,
    window_days=7
);

%CALCULATE_AMOUNT_DEVIATION(
    inds=&output_lib..txn_with_velocity,
    outds=&output_lib..txn_with_deviation
);

%CREATE_TIME_FEATURES(
    inds=&output_lib..txn_with_deviation,
    outds=&output_lib..txn_with_time_features
);

%CREATE_LOCATION_FEATURES(
    inds=&output_lib..txn_with_time_features,
    outds=&output_lib..transactions_engineered
);

/* Display sample of engineered features */
PROC PRINT DATA=&output_lib..transactions_engineered(OBS=10);
    VAR transaction_id customer_id amount 
        txn_count_7d avg_txn_amount_7d amount_zscore
        time_of_day is_weekend is_unusual_hour;
    TITLE 'Sample of Engineered Features';
RUN;
```

## Content of 04_rule_based_detection
```sas
/*******************************************************************************
* Program: 04_rule_based_detection.sas
* Purpose: Apply rule-based fraud detection logic
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Define fraud detection rules */
%macro APPLY_FRAUD_RULES(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Initialize rule flags and scores */
        length rule_triggered $200;
        rule_triggered = '';
        rule_score = 0;

        /* RULE 1: High velocity (>10 transactions in 7 days) */
        if txn_count_7d > 10 then do;
            rule_triggered = CATX(', ', rule_triggered, 'HIGH_VELOCITY');
            rule_score = rule_score + 25;
        end;

        /* RULE 2: Large amount deviation (>3 standard deviations) */
        if ABS(amount_zscore) > 3 then do;
            rule_triggered = CATX(', ', rule_triggered, 'AMOUNT_DEVIATION');
            rule_score = rule_score + 30;
        end;

        /* RULE 3: High amount (>$5000) */
        if amount > 5000 then do;
            rule_triggered = CATX(', ', rule_triggered, 'HIGH_AMOUNT');
            rule_score = rule_score + 20;
        end;

        /* RULE 4: Unusual hour transaction */
        if is_unusual_hour = 1 then do;
            rule_triggered = CATX(', ', rule_triggered, 'UNUSUAL_HOUR');
            rule_score = rule_score + 15;
        end;

        /* RULE 5: International transaction */
        if is_international = 1 then do;
            rule_triggered = CATX(', ', rule_triggered, 'INTERNATIONAL');
            rule_score = rule_score + 10;
        end;

        /* RULE 6: Rare country */
        if is_rare_country = 1 then do;
            rule_triggered = CATX(', ', rule_triggered, 'RARE_COUNTRY');
            rule_score = rule_score + 15;
        end;

        /* RULE 7: Multiple transactions in short time */
        if days_since_last_txn < 0.042 then do;  /* Less than 1 hour */
            rule_triggered = CATX(', ', rule_triggered, 'RAPID_SUCCESSION');
            rule_score = rule_score + 25;
        end;

        /* RULE 8: Round amount (potentially suspicious) */
        if MOD(amount, 100) = 0 AND amount >= 1000 then do;
            rule_triggered = CATX(', ', rule_triggered, 'ROUND_AMOUNT');
            rule_score = rule_score + 10;
        end;

        /* Calculate final rule-based risk level */
        length rule_risk_level $10;
        if rule_score >= 75 then rule_risk_level = 'CRITICAL';
        else if rule_score >= 50 then rule_risk_level = 'HIGH';
        else if rule_score >= 25 then rule_risk_level = 'MEDIUM';
        else rule_risk_level = 'LOW';

        /* Flag for investigation */
        is_suspicious = (rule_score >= 50);

    RUN;

    %PUT NOTE: Applied fraud detection rules;

%mend APPLY_FRAUD_RULES;

/* MACRO 2: Generate rule-based alerts */
%macro GENERATE_RULE_ALERTS(inds=, outds=, threshold=50);

    /* Filter suspicious transactions */
    DATA &outds;
        SET &inds;
        WHERE rule_score >= &threshold;
    RUN;

    /* Sort by risk score */
    PROC SORT DATA=&outds;
        BY DESCENDING rule_score transaction_date_sas;
    RUN;

    /* Count alerts by risk level */
    PROC FREQ DATA=&outds;
        TABLES rule_risk_level / NOCUM;
        TITLE "Rule-Based Alerts by Risk Level (Score >= &threshold)";
    RUN;

    /* Log alert counts */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :alert_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %let alert_rate = %SYSEVALF((&alert_count / &total_count) * 100);
    %PUT NOTE: Generated &alert_count alerts (&alert_rate% of transactions);

%mend GENERATE_RULE_ALERTS;

/* MACRO 3: Create rule summary report */
%macro RULE_SUMMARY_REPORT(inds=);

    /* Count by rule */
    PROC SQL;
        CREATE TABLE rule_summary AS
        SELECT 
            'HIGH_VELOCITY' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'HIGH_VELOCITY') > 0 THEN 1 ELSE 0 END) AS trigger_count
        FROM &inds
        UNION ALL
        SELECT 
            'AMOUNT_DEVIATION' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'AMOUNT_DEVIATION') > 0 THEN 1 ELSE 0 END)
        FROM &inds
        UNION ALL
        SELECT 
            'HIGH_AMOUNT' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'HIGH_AMOUNT') > 0 THEN 1 ELSE 0 END)
        FROM &inds
        UNION ALL
        SELECT 
            'UNUSUAL_HOUR' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'UNUSUAL_HOUR') > 0 THEN 1 ELSE 0 END)
        FROM &inds
        UNION ALL
        SELECT 
            'INTERNATIONAL' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'INTERNATIONAL') > 0 THEN 1 ELSE 0 END)
        FROM &inds;
    QUIT;

    /* Display summary */
    PROC PRINT DATA=rule_summary;
        TITLE 'Fraud Rule Trigger Summary';
    RUN;

%mend RULE_SUMMARY_REPORT;

/* Execute rule-based detection */
%APPLY_FRAUD_RULES(
    inds=&input_lib..transactions_engineered,
    outds=&output_lib..transactions_with_rules
);

%GENERATE_RULE_ALERTS(
    inds=&output_lib..transactions_with_rules,
    outds=&output_lib..rule_based_alerts,
    threshold=50
);

%RULE_SUMMARY_REPORT(
    inds=&output_lib..transactions_with_rules
);

/* Display top alerts */
PROC PRINT DATA=&output_lib..rule_based_alerts(OBS=20);
    VAR transaction_id customer_id amount rule_score rule_risk_level rule_triggered;
    TITLE 'Top 20 Rule-Based Fraud Alerts';
RUN;
```

## Content of 05_ml_scoring_model
```sas
/*******************************************************************************
* Program: 05_ml_scoring_model.sas
* Purpose: Apply ML model for fraud probability scoring
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Prepare data for ML scoring */
%macro PREPARE_ML_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create binary flags for categorical variables */
        is_high_amount = (amount > 1000);
        is_very_high_amount = (amount > 5000);

        /* Normalize continuous variables (simple min-max scaling) */
        /* In production, use actual min/max from training data */
        amount_normalized = amount / 10000;  /* Assuming max ~$10k */
        txn_count_normalized = txn_count_7d / 20;  /* Assuming max ~20 */

        /* Handle missing values */
        if missing(amount_zscore) then amount_zscore = 0;
        if missing(days_since_last_txn) then days_since_last_txn = 999;

        /* Create interaction features */
        amount_x_velocity = amount_normalized * txn_count_normalized;
        amount_x_deviation = amount_normalized * ABS(amount_zscore);

    RUN;

    %PUT NOTE: Prepared data for ML scoring;

%mend PREPARE_ML_DATA;

/* MACRO 2: Calculate ML fraud score (simulated logistic regression) */
%macro CALCULATE_ML_SCORE(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Simulated logistic regression coefficients */
        /* In production, these would come from a trained model */

        /* Calculate logit score */
        logit_score = 
            -2.5                                    /* Intercept */
            + 0.8 * amount_normalized               /* Amount effect */
            + 0.6 * txn_count_normalized            /* Velocity effect */
            + 0.4 * ABS(amount_zscore)              /* Deviation effect */
            + 0.5 * is_unusual_hour                 /* Time effect */
            + 0.3 * is_international                /* Location effect */
            + 0.7 * amount_x_velocity               /* Interaction 1 */
            + 0.5 * amount_x_deviation              /* Interaction 2 */
            - 0.2 * customer_txn_count / 100;       /* Customer history */

        /* Convert logit to probability using sigmoid function */
        ml_fraud_probability = 1 / (1 + EXP(-logit_score));

        /* Convert probability to score (0-100) */
        ml_fraud_score = ml_fraud_probability * 100;

        /* Assign ML risk band */
        length ml_risk_band $10;
        if ml_fraud_score >= 80 then ml_risk_band = 'CRITICAL';
        else if ml_fraud_score >= 60 then ml_risk_band = 'HIGH';
        else if ml_fraud_score >= 40 then ml_risk_band = 'MEDIUM';
        else if ml_fraud_score >= 20 then ml_risk_band = 'LOW';
        else ml_risk_band = 'VERY_LOW';

        /* Create ML alert flag */
        ml_alert = (ml_fraud_score >= 60);

        FORMAT ml_fraud_probability PERCENT8.2;

    RUN;

    %PUT NOTE: Calculated ML fraud scores;

%mend CALCULATE_ML_SCORE;

/* MACRO 3: Generate ML performance metrics */
%macro ML_PERFORMANCE_METRICS(inds=);

    /* Distribution of scores */
    PROC MEANS DATA=&inds N MEAN STD MIN P25 MEDIAN P75 MAX;
        VAR ml_fraud_score ml_fraud_probability;
        TITLE 'ML Fraud Score Distribution';
    RUN;

    /* Distribution by risk band */
    PROC FREQ DATA=&inds;
        TABLES ml_risk_band / NOCUM;
        TITLE 'ML Risk Band Distribution';
    RUN;

    /* Alert rate */
    PROC FREQ DATA=&inds;
        TABLES ml_alert / NOCUM;
        TITLE 'ML Alert Rate';
    RUN;

%mend ML_PERFORMANCE_METRICS;

/* MACRO 4: Compare ML vs Rule-based */
%macro COMPARE_MODELS(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Categorize agreement */
        length model_agreement $30;

        if ml_alert = 1 AND is_suspicious = 1 then 
            model_agreement = 'BOTH_ALERT';
        else if ml_alert = 1 AND is_suspicious = 0 then 
            model_agreement = 'ML_ONLY';
        else if ml_alert = 0 AND is_suspicious = 1 then 
            model_agreement = 'RULE_ONLY';
        else 
            model_agreement = 'BOTH_CLEAR';

        /* Calculate combined score */
        combined_score = (ml_fraud_score * 0.6) + (rule_score * 0.4);

        /* Combined risk level */
        length combined_risk_level $10;
        if combined_score >= 75 then combined_risk_level = 'CRITICAL';
        else if combined_score >= 50 then combined_risk_level = 'HIGH';
        else if combined_score >= 25 then combined_risk_level = 'MEDIUM';
        else combined_risk_level = 'LOW';

    RUN;

    /* Model agreement summary */
    PROC FREQ DATA=&outds;
        TABLES model_agreement / NOCUM;
        TITLE 'Model Agreement Analysis';
    RUN;

    /* Correlation between scores */
    PROC CORR DATA=&outds NOSIMPLE;
        VAR ml_fraud_score rule_score;
        TITLE 'Correlation: ML Score vs Rule Score';
    RUN;

    %PUT NOTE: Generated model comparison;

%mend COMPARE_MODELS;

/* Execute ML scoring pipeline */
%PREPARE_ML_DATA(
    inds=&input_lib..transactions_with_rules,
    outds=&output_lib..ml_data_prepared
);

%CALCULATE_ML_SCORE(
    inds=&output_lib..ml_data_prepared,
    outds=&output_lib..transactions_ml_scored
);

%ML_PERFORMANCE_METRICS(
    inds=&output_lib..transactions_ml_scored
);

%COMPARE_MODELS(
    inds=&output_lib..transactions_ml_scored,
    outds=&output_lib..transactions_combined_score
);

/* Display top ML alerts */
PROC PRINT DATA=&output_lib..transactions_ml_scored(OBS=20);
    WHERE ml_alert = 1;
    VAR transaction_id customer_id amount ml_fraud_score ml_fraud_probability 
        ml_risk_band rule_score;
    TITLE 'Top 20 ML-Based Fraud Alerts';
RUN;
```

## Content of 06_case_management_output
```sas
/*******************************************************************************
* Program: 06_case_management_output.sas
* Purpose: Generate prioritized case management queue and reports
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;
%let report_path = /output/reports;

/* MACRO 1: Create investigation queue */
%macro CREATE_INVESTIGATION_QUEUE(inds=, outds=, priority_threshold=50);

    DATA &outds;
        SET &inds;

        /* Calculate final priority score */
        priority_score = combined_score;

        /* Add urgency factors */
        if amount > 10000 then priority_score = priority_score + 10;
        if is_international = 1 AND amount > 5000 then priority_score = priority_score + 5;
        if txn_count_7d > 15 then priority_score = priority_score + 5;

        /* Cap at 100 */
        if priority_score > 100 then priority_score = 100;

        /* Assign case priority */
        length case_priority $10;
        if priority_score >= 80 then case_priority = 'URGENT';
        else if priority_score >= 60 then case_priority = 'HIGH';
        else if priority_score >= 40 then case_priority = 'MEDIUM';
        else case_priority = 'LOW';

        /* Filter for investigation queue */
        if priority_score >= &priority_threshold;

        /* Generate case ID */
        length case_id $20;
        case_id = CATS('CASE_', PUT(_N_, Z8.));

        /* Create investigation reason */
        length investigation_reason $500;
        investigation_reason = CATX(' | ',
            'ML Score: ' || PUT(ml_fraud_score, 5.1),
            'Rule Score: ' || PUT(rule_score, 3.),
            'Rules: ' || rule_triggered
        );

        /* Assign to investigator (round-robin simulation) */
        investigator_id = MOD(_N_, 10) + 1;  /* 10 investigators */

        /* Set case status */
        case_status = 'PENDING_REVIEW';

        /* Add timestamp */
        case_created_datetime = DATETIME();
        FORMAT case_created_datetime DATETIME20.;

    RUN;

    /* Sort by priority */
    PROC SORT DATA=&outds;
        BY DESCENDING priority_score case_priority transaction_date_sas;
    RUN;

    /* Log queue statistics */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :queue_count FROM &outds;
        SELECT COUNT(DISTINCT customer_id) INTO :unique_customers FROM &outds;
    QUIT;

    %PUT NOTE: Created investigation queue with &queue_count cases;
    %PUT NOTE: Affecting &unique_customers unique customers;

%mend CREATE_INVESTIGATION_QUEUE;

/* MACRO 2: Generate daily summary report */
%macro GENERATE_DAILY_SUMMARY(inds=);

    /* Overall statistics */
    TITLE 'Daily Fraud Detection Summary';
    TITLE2 "Report Date: &SYSDATE9";

    PROC SQL;
        CREATE TABLE daily_summary AS
        SELECT 
            COUNT(*) AS total_transactions,
            SUM(ml_alert) AS ml_alerts,
            SUM(is_suspicious) AS rule_alerts,
            SUM(CASE WHEN ml_alert=1 OR is_suspicious=1 THEN 1 ELSE 0 END) AS total_alerts,
            SUM(amount) AS total_amount FORMAT=DOLLAR20.2,
            SUM(CASE WHEN ml_alert=1 OR is_suspicious=1 THEN amount ELSE 0 END) 
                AS flagged_amount FORMAT=DOLLAR20.2,
            CALCULATED total_alerts / CALCULATED total_transactions * 100 
                AS alert_rate FORMAT=5.2
        FROM &inds;
    QUIT;

    PROC PRINT DATA=daily_summary NOOBS;
        TITLE 'Overall Statistics';
    RUN;

    /* Alerts by priority */
    PROC FREQ DATA=&inds;
        TABLES case_priority / NOCUM;
        TITLE 'Cases by Priority Level';
    RUN;

    /* Top customers by alert count */
    PROC SQL OUTOBS=20;
        CREATE TABLE top_customers AS
        SELECT 
            customer_id,
            COUNT(*) AS alert_count,
            SUM(amount) AS total_flagged_amount FORMAT=DOLLAR15.2,
            AVG(combined_score) AS avg_score FORMAT=5.1,
            MAX(case_priority) AS highest_priority
        FROM &inds
        WHERE ml_alert = 1 OR is_suspicious = 1
        GROUP BY customer_id
        ORDER BY alert_count DESC, total_flagged_amount DESC;
    QUIT;

    PROC PRINT DATA=top_customers NOOBS;
        TITLE 'Top 20 Customers by Alert Count';
    RUN;

    /* Trend by hour */
    PROC SQL;
        CREATE TABLE hourly_trend AS
        SELECT 
            txn_hour,
            COUNT(*) AS transaction_count,
            SUM(CASE WHEN ml_alert=1 OR is_suspicious=1 THEN 1 ELSE 0 END) AS alert_count,
            CALCULATED alert_count / CALCULATED transaction_count * 100 
                AS alert_rate FORMAT=5.2
        FROM &inds
        GROUP BY txn_hour
        ORDER BY txn_hour;
    QUIT;

    PROC PRINT DATA=hourly_trend NOOBS;
        TITLE 'Hourly Alert Trend';
    RUN;

%mend GENERATE_DAILY_SUMMARY;

/* MACRO 3: Export investigation queue */
%macro EXPORT_INVESTIGATION_QUEUE(inds=, filepath=);

    /* Select key fields for investigators */
    DATA export_data;
        SET &inds;
        KEEP case_id transaction_id customer_id transaction_date_sas transaction_time
             amount merchant_name_clean country_code_clean
             priority_score case_priority ml_fraud_score rule_score
             investigation_reason case_status investigator_id
             case_created_datetime;
    RUN;

    /* Export to CSV */
    PROC EXPORT 
        DATA=export_data
        OUTFILE="&filepath/investigation_queue_&SYSDATE9..csv"
        DBMS=CSV
        REPLACE;
    RUN;

    %PUT NOTE: Exported investigation queue to &filepath;

%mend EXPORT_INVESTIGATION_QUEUE;

/* MACRO 4: Generate SAR report data */
%macro GENERATE_SAR_DATA(inds=, outds=, sar_threshold=80);

    /* Filter high-priority cases for SAR filing */
    DATA &outds;
        SET &inds;
        WHERE priority_score >= &sar_threshold;

        /* Add SAR-specific fields */
        length sar_type $50;
        sar_type = 'Suspicious Transaction - Fraud Indicators';

        /* Create narrative */
        length sar_narrative $1000;
        sar_narrative = CATX('. ',
            'Transaction flagged by automated fraud detection system',
            'ML Model Score: ' || PUT(ml_fraud_score, 5.1) || '/100',
            'Rule-Based Score: ' || PUT(rule_score, 3.) || '/100',
            'Triggered Rules: ' || rule_triggered,
            'Transaction Amount: $' || PUT(amount, COMMA12.2),
            'Customer Transaction Count (7d): ' || PUT(txn_count_7d, 3.)
        );

        /* SAR filing requirement */
        requires_sar = 1;
        sar_deadline_date = INTNX('DAY', case_created_datetime, 30);
        FORMAT sar_deadline_date DATE9.;

    RUN;

    /* Sort by deadline */
    PROC SORT DATA=&outds;
        BY sar_deadline_date DESCENDING priority_score;
    RUN;

    /* Count SAR cases */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :sar_count FROM &outds;
    QUIT;

    %PUT NOTE: Generated &sar_count SAR report cases;

%mend GENERATE_SAR_DATA;

/* Execute case management workflow */
%CREATE_INVESTIGATION_QUEUE(
    inds=&input_lib..transactions_combined_score,
    outds=&output_lib..investigation_queue,
    priority_threshold=50
);

%GENERATE_DAILY_SUMMARY(
    inds=&output_lib..investigation_queue
);

%EXPORT_INVESTIGATION_QUEUE(
    inds=&output_lib..investigation_queue,
    filepath=&report_path
);

%GENERATE_SAR_DATA(
    inds=&output_lib..investigation_queue,
    outds=&output_lib..sar_cases,
    sar_threshold=80
);

/* Final output - Investigation Queue */
PROC PRINT DATA=&output_lib..investigation_queue(OBS=50);
    VAR case_id transaction_id customer_id amount priority_score case_priority
        ml_fraud_score rule_score case_status investigator_id;
    TITLE 'Investigation Queue - Top 50 Cases';
    TITLE2 'Ready for Investigator Assignment';
RUN;

/* SAR Cases requiring filing */
PROC PRINT DATA=&output_lib..sar_cases(OBS=20);
    VAR case_id customer_id amount priority_score sar_deadline_date;
    TITLE 'SAR Cases Requiring Filing';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of SASPOC
```sas
/*******************************************************************************
** PROGRAM:       Program_Name.sas
** AUTHOR:        [Your Name]
** CREATED:       [Date created]
**
** DESCRIPTION:   
** This program performs [brief, high-level function of the program]. 
**
** FUNCTION:
** [Detailed description of the program's logic and goal. 
** e.g., "Reads raw data from the 'sasuser.raw_data' table, cleans missing 
** values, calculates BMI, and saves the final output to 'work.final_output'."]
**
** INPUT:
** - Library: sasuser 
** - Table:   raw_data (contains patient_id, height_cm, weight_kg, date_visit)
** - Parameters: &start_date, &end_date (macro variables for filtering)
**
** OUTPUT:
** - Library: work
** - Table:   final_output (contains patient_id, bmi, date_visit, status)
** - Log messages: Includes data quality checks for out-of-range values.
**
** HISTORY:
** DATE         AUTHOR        DESCRIPTION OF CHANGE
** -------------------------------------------------------------------------
** 2025-11-26   [Your Name]   Initial version created with basic data cleaning.
** 2025-12-01   [Collaborator] Added BMI calculation and 'status' variable logic.
** 2025-12-15   [Your Name]   Optimized for large datasets using specific data step techniques.
*******************************************************************************/

 %let SYSPARM1 = %UPCASE(%SCAN(&SYSPARM,1,"_"))
 %let SYSPARM2 = %UPCASE(%SCAN(&SYSPARM,2,"_"))
 %let gdate = &sysdate9.;
 % let PROGRAM = SASPOC;
 %let PROJECT = POC;
 %let FREQ = D;
 
 %include "MYLIB.&SYSPARM1..META(&FREQ.INI)"

 %INITIALIZE;

 %let PREVYEAR = %eval(%substr(&DATE,7,4)-1);
 %let YEAR =%substr(&DATE,7,4);

 options mprint mlogic symbolgen;

 %macro call;

   %ALLOCALIB(inputlib);
  
   %DREAD(OUT_DAT = POCOUT);
 
   %DUPDATE(prev_ds=OUTPUTP.customer_data, new_ds=OUTPUT.customer_data, out_ds=FINAL.customer_data);
  
   %DALLOCLIB(inputlib);
%mend;

%call;```

## Content of SASPOC
```sas
/*******************************************************************************
** PROGRAM:       Program_Name.sas
** AUTHOR:        [Your Name]
** CREATED:       [Date created]
**
** DESCRIPTION:   
** This program performs [brief, high-level function of the program]. 
**
** FUNCTION:
** [Detailed description of the program's logic and goal. 
** e.g., "Reads raw data from the 'sasuser.raw_data' table, cleans missing 
** values, calculates BMI, and saves the final output to 'work.final_output'."]
**
** INPUT:
** - Library: sasuser 
** - Table:   raw_data (contains patient_id, height_cm, weight_kg, date_visit)
** - Parameters: &start_date, &end_date (macro variables for filtering)
**
** OUTPUT:
** - Library: work
** - Table:   final_output (contains patient_id, bmi, date_visit, status)
** - Log messages: Includes data quality checks for out-of-range values.
**
** HISTORY:
** DATE         AUTHOR        DESCRIPTION OF CHANGE
** -------------------------------------------------------------------------
** 2025-11-26   [Your Name]   Initial version created with basic data cleaning.
** 2025-12-01   [Collaborator] Added BMI calculation and 'status' variable logic.
** 2025-12-15   [Your Name]   Optimized for large datasets using specific data step techniques.
*******************************************************************************/

 %let SYSPARM1 = %UPCASE(%SCAN(&SYSPARM,1,"_"))
 %let SYSPARM2 = %UPCASE(%SCAN(&SYSPARM,2,"_"))
 %let gdate = &sysdate9.;
 % let PROGRAM = SASPOC;
 %let PROJECT = POC;
 %let FREQ = D;
 
 %include "MYLIB.&SYSPARM1..META(&FREQ.INI)"

 %INITIALIZE;

 %let PREVYEAR = %eval(%substr(&DATE,7,4)-1);
 %let YEAR =%substr(&DATE,7,4);

 options mprint mlogic symbolgen;

 %macro call;

   %ALLOCALIB(inputlib);
  
   %DREAD(OUT_DAT = POCOUT);
 
   %DUPDATE(prev_ds=OUTPUTP.customer_data, new_ds=OUTPUT.customer_data, out_ds=FINAL.customer_data);
  
   %DALLOCLIB(inputlib);
%mend;

%call;```

## Content of SASPOC
```sas
/*******************************************************************************
** PROGRAM:       Program_Name.sas
** AUTHOR:        [Your Name]
** CREATED:       [Date created]
**
** DESCRIPTION:   
** This program performs [brief, high-level function of the program]. 
**
** FUNCTION:
** [Detailed description of the program's logic and goal. 
** e.g., "Reads raw data from the 'sasuser.raw_data' table, cleans missing 
** values, calculates BMI, and saves the final output to 'work.final_output'."]
**
** INPUT:
** - Library: sasuser 
** - Table:   raw_data (contains patient_id, height_cm, weight_kg, date_visit)
** - Parameters: &start_date, &end_date (macro variables for filtering)
**
** OUTPUT:
** - Library: work
** - Table:   final_output (contains patient_id, bmi, date_visit, status)
** - Log messages: Includes data quality checks for out-of-range values.
**
** HISTORY:
** DATE         AUTHOR        DESCRIPTION OF CHANGE
** -------------------------------------------------------------------------
** 2025-11-26   [Your Name]   Initial version created with basic data cleaning.
** 2025-12-01   [Collaborator] Added BMI calculation and 'status' variable logic.
** 2025-12-15   [Your Name]   Optimized for large datasets using specific data step techniques.
*******************************************************************************/

 %let SYSPARM1 = %UPCASE(%SCAN(&SYSPARM,1,"_"))
 %let SYSPARM2 = %UPCASE(%SCAN(&SYSPARM,2,"_"))
 %let gdate = &sysdate9.;
 % let PROGRAM = SASPOC;
 %let PROJECT = POC;
 %let FREQ = D;
 
 %include "MYLIB.&SYSPARM1..META(&FREQ.INI)"

 %INITIALIZE;

 %let PREVYEAR = %eval(%substr(&DATE,7,4)-1);
 %let YEAR =%substr(&DATE,7,4);

 options mprint mlogic symbolgen;

 %macro call;

   %ALLOCALIB(inputlib);
  
   %DREAD(OUT_DAT = POCOUT);
 
   %DUPDATE(prev_ds=OUTPUTP.customer_data, new_ds=OUTPUT.customer_data, out_ds=FINAL.customer_data);
  
   %DALLOCLIB(inputlib);
%mend;

%call;```

## Content of SASPOC
```sas
/*******************************************************************************
** PROGRAM:       Program_Name.sas
** AUTHOR:        [Your Name]
** CREATED:       [Date created]
**
** DESCRIPTION:   
** This program performs [brief, high-level function of the program]. 
**
** FUNCTION:
** [Detailed description of the program's logic and goal. 
** e.g., "Reads raw data from the 'sasuser.raw_data' table, cleans missing 
** values, calculates BMI, and saves the final output to 'work.final_output'."]
**
** INPUT:
** - Library: sasuser 
** - Table:   raw_data (contains patient_id, height_cm, weight_kg, date_visit)
** - Parameters: &start_date, &end_date (macro variables for filtering)
**
** OUTPUT:
** - Library: work
** - Table:   final_output (contains patient_id, bmi, date_visit, status)
** - Log messages: Includes data quality checks for out-of-range values.
**
** HISTORY:
** DATE         AUTHOR        DESCRIPTION OF CHANGE
** -------------------------------------------------------------------------
** 2025-11-26   [Your Name]   Initial version created with basic data cleaning.
** 2025-12-01   [Collaborator] Added BMI calculation and 'status' variable logic.
** 2025-12-15   [Your Name]   Optimized for large datasets using specific data step techniques.
*******************************************************************************/

 %let SYSPARM1 = %UPCASE(%SCAN(&SYSPARM,1,"_"))
 %let SYSPARM2 = %UPCASE(%SCAN(&SYSPARM,2,"_"))
 %let gdate = &sysdate9.;
 % let PROGRAM = SASPOC;
 %let PROJECT = POC;
 %let FREQ = D;
 
 %include "MYLIB.&SYSPARM1..META(&FREQ.INI)"

 %INITIALIZE;

 %let PREVYEAR = %eval(%substr(&DATE,7,4)-1);
 %let YEAR =%substr(&DATE,7,4);

 options mprint mlogic symbolgen;

 %macro call;

   %ALLOCALIB(inputlib);
  
   %DREAD(OUT_DAT = POCOUT);
 
   %DUPDATE(prev_ds=OUTPUTP.customer_data, new_ds=OUTPUT.customer_data, out_ds=FINAL.customer_data);
  
   %DALLOCLIB(inputlib);
%mend;

%call;```

## Content of SASPOC
```sas
/*******************************************************************************
** PROGRAM:       Program_Name.sas
** AUTHOR:        [Your Name]
** CREATED:       [Date created]
**
** DESCRIPTION:   
** This program performs [brief, high-level function of the program]. 
**
** FUNCTION:
** [Detailed description of the program's logic and goal. 
** e.g., "Reads raw data from the 'sasuser.raw_data' table, cleans missing 
** values, calculates BMI, and saves the final output to 'work.final_output'."]
**
** INPUT:
** - Library: sasuser 
** - Table:   raw_data (contains patient_id, height_cm, weight_kg, date_visit)
** - Parameters: &start_date, &end_date (macro variables for filtering)
**
** OUTPUT:
** - Library: work
** - Table:   final_output (contains patient_id, bmi, date_visit, status)
** - Log messages: Includes data quality checks for out-of-range values.
**
** HISTORY:
** DATE         AUTHOR        DESCRIPTION OF CHANGE
** -------------------------------------------------------------------------
** 2025-11-26   [Your Name]   Initial version created with basic data cleaning.
** 2025-12-01   [Collaborator] Added BMI calculation and 'status' variable logic.
** 2025-12-15   [Your Name]   Optimized for large datasets using specific data step techniques.
*******************************************************************************/

 %let SYSPARM1 = %UPCASE(%SCAN(&SYSPARM,1,"_"))
 %let SYSPARM2 = %UPCASE(%SCAN(&SYSPARM,2,"_"))
 %let gdate = &sysdate9.;
 % let PROGRAM = SASPOC;
 %let PROJECT = POC;
 %let FREQ = D;
 
 %include "MYLIB.&SYSPARM1..META(&FREQ.INI)"

 %INITIALIZE;

 %let PREVYEAR = %eval(%substr(&DATE,7,4)-1);
 %let YEAR =%substr(&DATE,7,4);

 options mprint mlogic symbolgen;

 %macro call;

   %ALLOCALIB(inputlib);
  
   %DREAD(OUT_DAT = POCOUT);
 
   %DUPDATE(prev_ds=OUTPUTP.customer_data, new_ds=OUTPUT.customer_data, out_ds=FINAL.customer_data);
  
   %DALLOCLIB(inputlib);
%mend;

%call;```

## Content of SASPOC
```sas
/*******************************************************************************
** PROGRAM:       Program_Name.sas
** AUTHOR:        [Your Name]
** CREATED:       [Date created]
**
** DESCRIPTION:   
** This program performs [brief, high-level function of the program]. 
**
** FUNCTION:
** [Detailed description of the program's logic and goal. 
** e.g., "Reads raw data from the 'sasuser.raw_data' table, cleans missing 
** values, calculates BMI, and saves the final output to 'work.final_output'."]
**
** INPUT:
** - Library: sasuser 
** - Table:   raw_data (contains patient_id, height_cm, weight_kg, date_visit)
** - Parameters: &start_date, &end_date (macro variables for filtering)
**
** OUTPUT:
** - Library: work
** - Table:   final_output (contains patient_id, bmi, date_visit, status)
** - Log messages: Includes data quality checks for out-of-range values.
**
** HISTORY:
** DATE         AUTHOR        DESCRIPTION OF CHANGE
** -------------------------------------------------------------------------
** 2025-11-26   [Your Name]   Initial version created with basic data cleaning.
** 2025-12-01   [Collaborator] Added BMI calculation and 'status' variable logic.
** 2025-12-15   [Your Name]   Optimized for large datasets using specific data step techniques.
*******************************************************************************/

 %let SYSPARM1 = %UPCASE(%SCAN(&SYSPARM,1,"_"))
 %let SYSPARM2 = %UPCASE(%SCAN(&SYSPARM,2,"_"))
 %let gdate = &sysdate9.;
 % let PROGRAM = SASPOC;
 %let PROJECT = POC;
 %let FREQ = D;
 
 %include "MYLIB.&SYSPARM1..META(&FREQ.INI)"

 %INITIALIZE;

 %let PREVYEAR = %eval(%substr(&DATE,7,4)-1);
 %let YEAR =%substr(&DATE,7,4);

 options mprint mlogic symbolgen;

 %macro call;

   %ALLOCALIB(inputlib);
  
   %DREAD(OUT_DAT = POCOUT);
 
   %DUPDATE(prev_ds=OUTPUTP.customer_data, new_ds=OUTPUT.customer_data, out_ds=FINAL.customer_data);
  
   %DALLOCLIB(inputlib);
%mend;

%call;```

## Content of SASPOC
```sas
/*******************************************************************************
** PROGRAM:       Program_Name.sas
** AUTHOR:        [Your Name]
** CREATED:       [Date created]
**
** DESCRIPTION:   
** This program performs [brief, high-level function of the program]. 
**
** FUNCTION:
** [Detailed description of the program's logic and goal. 
** e.g., "Reads raw data from the 'sasuser.raw_data' table, cleans missing 
** values, calculates BMI, and saves the final output to 'work.final_output'."]
**
** INPUT:
** - Library: sasuser 
** - Table:   raw_data (contains patient_id, height_cm, weight_kg, date_visit)
** - Parameters: &start_date, &end_date (macro variables for filtering)
**
** OUTPUT:
** - Library: work
** - Table:   final_output (contains patient_id, bmi, date_visit, status)
** - Log messages: Includes data quality checks for out-of-range values.
**
** HISTORY:
** DATE         AUTHOR        DESCRIPTION OF CHANGE
** -------------------------------------------------------------------------
** 2025-11-26   [Your Name]   Initial version created with basic data cleaning.
** 2025-12-01   [Collaborator] Added BMI calculation and 'status' variable logic.
** 2025-12-15   [Your Name]   Optimized for large datasets using specific data step techniques.
*******************************************************************************/

 %let SYSPARM1 = %UPCASE(%SCAN(&SYSPARM,1,"_"))
 %let SYSPARM2 = %UPCASE(%SCAN(&SYSPARM,2,"_"))
 %let gdate = &sysdate9.;
 % let PROGRAM = SASPOC;
 %let PROJECT = POC;
 %let FREQ = D;
 
 %include "MYLIB.&SYSPARM1..META(&FREQ.INI)"

 %INITIALIZE;

 %let PREVYEAR = %eval(%substr(&DATE,7,4)-1);
 %let YEAR =%substr(&DATE,7,4);

 options mprint mlogic symbolgen;

 %macro call;

   %ALLOCALIB(inputlib);
  
   %DREAD(OUT_DAT = POCOUT);
 
   %DUPDATE(prev_ds=OUTPUTP.customer_data, new_ds=OUTPUT.customer_data, out_ds=FINAL.customer_data);
  
   %DALLOCLIB(inputlib);
%mend;

%call;```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 02_data_quality_cleaning
```sas
/*******************************************************************************
* Program: 02_data_quality_cleaning.sas
* Purpose: Clean and standardize transaction data
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Clean transaction data */
%macro CLEAN_TRANSACTIONS(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Standardize transaction type */
        length transaction_type_clean $20;
        transaction_type_clean = UPCASE(STRIP(transaction_type));

        /* Clean merchant name */
        length merchant_name_clean $100;
        merchant_name_clean = PROPCASE(STRIP(merchant_name));

        /* Standardize country code */
        length country_code_clean $2;
        country_code_clean = UPCASE(SUBSTR(country_code, 1, 2));

        /* Handle missing amounts - replace with 0 */
        if missing(amount) then amount = 0;

        /* Convert transaction date to SAS date */
        if NOT missing(transaction_date) then do;
            transaction_date_sas = INPUT(transaction_date, YYMMDD10.);
            FORMAT transaction_date_sas DATE9.;
        end;

        /* Create transaction timestamp */
        transaction_datetime = DHMS(transaction_date_sas, 
                                   HOUR(transaction_time), 
                                   MINUTE(transaction_time), 
                                   SECOND(transaction_time));
        FORMAT transaction_datetime DATETIME20.;

    RUN;

    %PUT NOTE: Cleaned &inds to &outds;

%mend CLEAN_TRANSACTIONS;

/* MACRO 2: Remove duplicates */
%macro REMOVE_DUPLICATES(inds=, outds=, key=);

    /* Sort by key */
    PROC SORT DATA=&inds OUT=&outds NODUPKEY;
        BY &key;
    RUN;

    /* Log duplicate removal */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :before_count FROM &inds;
        SELECT COUNT(*) INTO :after_count FROM &outds;
    QUIT;

    %let dup_count = %EVAL(&before_count - &after_count);
    %PUT NOTE: Removed &dup_count duplicate records;

%mend REMOVE_DUPLICATES;

/* MACRO 3: Handle outliers */
%macro HANDLE_OUTLIERS(inds=, outds=, var=, method=WINSORIZE);

    /* Calculate percentiles */
    PROC MEANS DATA=&inds NOPRINT;
        VAR &var;
        OUTPUT OUT=percentiles
            P1=p1 P99=p99;
    RUN;

    /* Get percentile values */
    DATA _NULL_;
        SET percentiles;
        CALL SYMPUTX('p1_value', p1);
        CALL SYMPUTX('p99_value', p99);
    RUN;

    /* Apply outlier handling */
    DATA &outds;
        SET &inds;

        %if &method = WINSORIZE %then %do;
            /* Winsorize: Cap at 1st and 99th percentiles */
            if &var < &p1_value then &var = &p1_value;
            else if &var > &p99_value then &var = &p99_value;
        %end;
        %else %if &method = REMOVE %then %do;
            /* Remove outliers */
            if &var >= &p1_value AND &var <= &p99_value;
        %end;

    RUN;

    %PUT NOTE: Handled outliers in &var using &method method;

%mend HANDLE_OUTLIERS;

/* Execute cleaning pipeline */
%CLEAN_TRANSACTIONS(
    inds=&input_lib..transactions_validated,
    outds=&output_lib..transactions_cleaned
);

%REMOVE_DUPLICATES(
    inds=&output_lib..transactions_cleaned,
    outds=&output_lib..transactions_deduped,
    key=transaction_id
);

%HANDLE_OUTLIERS(
    inds=&output_lib..transactions_deduped,
    outds=&output_lib..transactions_final,
    var=amount,
    method=WINSORIZE
);

/* Display results */
PROC MEANS DATA=&output_lib..transactions_final N MEAN STD MIN MAX;
    VAR amount;
    TITLE 'Transaction Amount Statistics After Cleaning';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 02_data_quality_cleaning
```sas
/*******************************************************************************
* Program: 02_data_quality_cleaning.sas
* Purpose: Clean and standardize transaction data
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Clean transaction data */
%macro CLEAN_TRANSACTIONS(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Standardize transaction type */
        length transaction_type_clean $20;
        transaction_type_clean = UPCASE(STRIP(transaction_type));

        /* Clean merchant name */
        length merchant_name_clean $100;
        merchant_name_clean = PROPCASE(STRIP(merchant_name));

        /* Standardize country code */
        length country_code_clean $2;
        country_code_clean = UPCASE(SUBSTR(country_code, 1, 2));

        /* Handle missing amounts - replace with 0 */
        if missing(amount) then amount = 0;

        /* Convert transaction date to SAS date */
        if NOT missing(transaction_date) then do;
            transaction_date_sas = INPUT(transaction_date, YYMMDD10.);
            FORMAT transaction_date_sas DATE9.;
        end;

        /* Create transaction timestamp */
        transaction_datetime = DHMS(transaction_date_sas, 
                                   HOUR(transaction_time), 
                                   MINUTE(transaction_time), 
                                   SECOND(transaction_time));
        FORMAT transaction_datetime DATETIME20.;

    RUN;

    %PUT NOTE: Cleaned &inds to &outds;

%mend CLEAN_TRANSACTIONS;

/* MACRO 2: Remove duplicates */
%macro REMOVE_DUPLICATES(inds=, outds=, key=);

    /* Sort by key */
    PROC SORT DATA=&inds OUT=&outds NODUPKEY;
        BY &key;
    RUN;

    /* Log duplicate removal */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :before_count FROM &inds;
        SELECT COUNT(*) INTO :after_count FROM &outds;
    QUIT;

    %let dup_count = %EVAL(&before_count - &after_count);
    %PUT NOTE: Removed &dup_count duplicate records;

%mend REMOVE_DUPLICATES;

/* MACRO 3: Handle outliers */
%macro HANDLE_OUTLIERS(inds=, outds=, var=, method=WINSORIZE);

    /* Calculate percentiles */
    PROC MEANS DATA=&inds NOPRINT;
        VAR &var;
        OUTPUT OUT=percentiles
            P1=p1 P99=p99;
    RUN;

    /* Get percentile values */
    DATA _NULL_;
        SET percentiles;
        CALL SYMPUTX('p1_value', p1);
        CALL SYMPUTX('p99_value', p99);
    RUN;

    /* Apply outlier handling */
    DATA &outds;
        SET &inds;

        %if &method = WINSORIZE %then %do;
            /* Winsorize: Cap at 1st and 99th percentiles */
            if &var < &p1_value then &var = &p1_value;
            else if &var > &p99_value then &var = &p99_value;
        %end;
        %else %if &method = REMOVE %then %do;
            /* Remove outliers */
            if &var >= &p1_value AND &var <= &p99_value;
        %end;

    RUN;

    %PUT NOTE: Handled outliers in &var using &method method;

%mend HANDLE_OUTLIERS;

/* Execute cleaning pipeline */
%CLEAN_TRANSACTIONS(
    inds=&input_lib..transactions_validated,
    outds=&output_lib..transactions_cleaned
);

%REMOVE_DUPLICATES(
    inds=&output_lib..transactions_cleaned,
    outds=&output_lib..transactions_deduped,
    key=transaction_id
);

%HANDLE_OUTLIERS(
    inds=&output_lib..transactions_deduped,
    outds=&output_lib..transactions_final,
    var=amount,
    method=WINSORIZE
);

/* Display results */
PROC MEANS DATA=&output_lib..transactions_final N MEAN STD MIN MAX;
    VAR amount;
    TITLE 'Transaction Amount Statistics After Cleaning';
RUN;
```

## Content of 03_feature_engineering
```sas
/*******************************************************************************
* Program: 03_feature_engineering.sas
* Purpose: Create features for fraud detection
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Calculate velocity features */
%macro CALCULATE_VELOCITY(inds=, outds=, window_days=7);

    /* Sort by customer and date */
    PROC SORT DATA=&inds;
        BY customer_id transaction_date_sas transaction_time;
    RUN;

    /* Calculate velocity features */
    DATA &outds;
        SET &inds;
        BY customer_id;

        /* Retain variables for calculations */
        RETAIN txn_count_&window_days.d 0
               txn_amount_&window_days.d 0
               last_txn_date .;

        /* Reset on new customer */
        if FIRST.customer_id then do;
            txn_count_&window_days.d = 0;
            txn_amount_&window_days.d = 0;
            last_txn_date = .;
        end;

        /* Calculate days since last transaction */
        if NOT missing(last_txn_date) then 
            days_since_last_txn = transaction_date_sas - last_txn_date;
        else 
            days_since_last_txn = .;

        /* Update counters (rolling window) */
        if NOT missing(last_txn_date) then do;
            if days_since_last_txn <= &window_days then do;
                txn_count_&window_days.d + 1;
                txn_amount_&window_days.d + amount;
            end;
            else do;
                txn_count_&window_days.d = 1;
                txn_amount_&window_days.d = amount;
            end;
        end;
        else do;
            txn_count_&window_days.d = 1;
            txn_amount_&window_days.d = amount;
        end;

        /* Update last transaction date */
        last_txn_date = transaction_date_sas;

        /* Calculate average transaction amount in window */
        if txn_count_&window_days.d > 0 then 
            avg_txn_amount_&window_days.d = txn_amount_&window_days.d / txn_count_&window_days.d;
        else 
            avg_txn_amount_&window_days.d = 0;

        DROP last_txn_date;

    RUN;

    %PUT NOTE: Calculated velocity features for &window_days day window;

%mend CALCULATE_VELOCITY;

/* MACRO 2: Calculate amount deviation */
%macro CALCULATE_AMOUNT_DEVIATION(inds=, outds=);

    /* Calculate customer statistics */
    PROC MEANS DATA=&inds NOPRINT;
        BY customer_id;
        VAR amount;
        OUTPUT OUT=customer_stats
            MEAN=customer_avg_amount
            STD=customer_std_amount
            N=customer_txn_count;
    RUN;

    /* Merge statistics back */
    PROC SQL;
        CREATE TABLE &outds AS
        SELECT 
            a.*,
            b.customer_avg_amount,
            b.customer_std_amount,
            b.customer_txn_count,
            /* Calculate z-score */
            CASE 
                WHEN b.customer_std_amount > 0 THEN
                    (a.amount - b.customer_avg_amount) / b.customer_std_amount
                ELSE 0
            END AS amount_zscore,
            /* Calculate percentage deviation */
            CASE
                WHEN b.customer_avg_amount > 0 THEN
                    ((a.amount - b.customer_avg_amount) / b.customer_avg_amount) * 100
                ELSE 0
            END AS amount_pct_deviation
        FROM &inds a
        LEFT JOIN customer_stats b
        ON a.customer_id = b.customer_id;
    QUIT;

    %PUT NOTE: Calculated amount deviation features;

%mend CALCULATE_AMOUNT_DEVIATION;

/* MACRO 3: Create time-based features */
%macro CREATE_TIME_FEATURES(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Extract time components */
        txn_hour = HOUR(transaction_time);
        txn_day_of_week = WEEKDAY(transaction_date_sas);
        txn_day_of_month = DAY(transaction_date_sas);
        txn_month = MONTH(transaction_date_sas);

        /* Create time-of-day categories */
        length time_of_day $20;
        if txn_hour >= 0 AND txn_hour < 6 then time_of_day = 'NIGHT';
        else if txn_hour >= 6 AND txn_hour < 12 then time_of_day = 'MORNING';
        else if txn_hour >= 12 AND txn_hour < 18 then time_of_day = 'AFTERNOON';
        else time_of_day = 'EVENING';

        /* Create weekend flag */
        is_weekend = (txn_day_of_week IN (1, 7));  /* Sunday=1, Saturday=7 */

        /* Create unusual hour flag */
        is_unusual_hour = (txn_hour >= 0 AND txn_hour < 6);

    RUN;

    %PUT NOTE: Created time-based features;

%mend CREATE_TIME_FEATURES;

/* MACRO 4: Create location features */
%macro CREATE_LOCATION_FEATURES(inds=, outds=);

    /* Calculate country transaction counts */
    PROC SQL;
        CREATE TABLE country_counts AS
        SELECT 
            country_code_clean,
            COUNT(*) AS country_txn_count
        FROM &inds
        GROUP BY country_code_clean;
    QUIT;

    /* Merge back and create features */
    PROC SQL;
        CREATE TABLE &outds AS
        SELECT 
            a.*,
            b.country_txn_count,
            /* Flag for rare countries */
            CASE 
                WHEN b.country_txn_count < 10 THEN 1
                ELSE 0
            END AS is_rare_country,
            /* Check if international transaction */
            CASE
                WHEN a.country_code_clean NE 'US' THEN 1
                ELSE 0
            END AS is_international
        FROM &inds a
        LEFT JOIN country_counts b
        ON a.country_code_clean = b.country_code_clean;
    QUIT;

    %PUT NOTE: Created location-based features;

%mend CREATE_LOCATION_FEATURES;

/* Execute feature engineering pipeline */
%CALCULATE_VELOCITY(
    inds=&input_lib..transactions_final,
    outds=&output_lib..txn_with_velocity,
    window_days=7
);

%CALCULATE_AMOUNT_DEVIATION(
    inds=&output_lib..txn_with_velocity,
    outds=&output_lib..txn_with_deviation
);

%CREATE_TIME_FEATURES(
    inds=&output_lib..txn_with_deviation,
    outds=&output_lib..txn_with_time_features
);

%CREATE_LOCATION_FEATURES(
    inds=&output_lib..txn_with_time_features,
    outds=&output_lib..transactions_engineered
);

/* Display sample of engineered features */
PROC PRINT DATA=&output_lib..transactions_engineered(OBS=10);
    VAR transaction_id customer_id amount 
        txn_count_7d avg_txn_amount_7d amount_zscore
        time_of_day is_weekend is_unusual_hour;
    TITLE 'Sample of Engineered Features';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 02_data_quality_cleaning
```sas
/*******************************************************************************
* Program: 02_data_quality_cleaning.sas
* Purpose: Clean and standardize transaction data
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Clean transaction data */
%macro CLEAN_TRANSACTIONS(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Standardize transaction type */
        length transaction_type_clean $20;
        transaction_type_clean = UPCASE(STRIP(transaction_type));

        /* Clean merchant name */
        length merchant_name_clean $100;
        merchant_name_clean = PROPCASE(STRIP(merchant_name));

        /* Standardize country code */
        length country_code_clean $2;
        country_code_clean = UPCASE(SUBSTR(country_code, 1, 2));

        /* Handle missing amounts - replace with 0 */
        if missing(amount) then amount = 0;

        /* Convert transaction date to SAS date */
        if NOT missing(transaction_date) then do;
            transaction_date_sas = INPUT(transaction_date, YYMMDD10.);
            FORMAT transaction_date_sas DATE9.;
        end;

        /* Create transaction timestamp */
        transaction_datetime = DHMS(transaction_date_sas, 
                                   HOUR(transaction_time), 
                                   MINUTE(transaction_time), 
                                   SECOND(transaction_time));
        FORMAT transaction_datetime DATETIME20.;

    RUN;

    %PUT NOTE: Cleaned &inds to &outds;

%mend CLEAN_TRANSACTIONS;

/* MACRO 2: Remove duplicates */
%macro REMOVE_DUPLICATES(inds=, outds=, key=);

    /* Sort by key */
    PROC SORT DATA=&inds OUT=&outds NODUPKEY;
        BY &key;
    RUN;

    /* Log duplicate removal */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :before_count FROM &inds;
        SELECT COUNT(*) INTO :after_count FROM &outds;
    QUIT;

    %let dup_count = %EVAL(&before_count - &after_count);
    %PUT NOTE: Removed &dup_count duplicate records;

%mend REMOVE_DUPLICATES;

/* MACRO 3: Handle outliers */
%macro HANDLE_OUTLIERS(inds=, outds=, var=, method=WINSORIZE);

    /* Calculate percentiles */
    PROC MEANS DATA=&inds NOPRINT;
        VAR &var;
        OUTPUT OUT=percentiles
            P1=p1 P99=p99;
    RUN;

    /* Get percentile values */
    DATA _NULL_;
        SET percentiles;
        CALL SYMPUTX('p1_value', p1);
        CALL SYMPUTX('p99_value', p99);
    RUN;

    /* Apply outlier handling */
    DATA &outds;
        SET &inds;

        %if &method = WINSORIZE %then %do;
            /* Winsorize: Cap at 1st and 99th percentiles */
            if &var < &p1_value then &var = &p1_value;
            else if &var > &p99_value then &var = &p99_value;
        %end;
        %else %if &method = REMOVE %then %do;
            /* Remove outliers */
            if &var >= &p1_value AND &var <= &p99_value;
        %end;

    RUN;

    %PUT NOTE: Handled outliers in &var using &method method;

%mend HANDLE_OUTLIERS;

/* Execute cleaning pipeline */
%CLEAN_TRANSACTIONS(
    inds=&input_lib..transactions_validated,
    outds=&output_lib..transactions_cleaned
);

%REMOVE_DUPLICATES(
    inds=&output_lib..transactions_cleaned,
    outds=&output_lib..transactions_deduped,
    key=transaction_id
);

%HANDLE_OUTLIERS(
    inds=&output_lib..transactions_deduped,
    outds=&output_lib..transactions_final,
    var=amount,
    method=WINSORIZE
);

/* Display results */
PROC MEANS DATA=&output_lib..transactions_final N MEAN STD MIN MAX;
    VAR amount;
    TITLE 'Transaction Amount Statistics After Cleaning';
RUN;
```

## Content of 03_feature_engineering
```sas
/*******************************************************************************
* Program: 03_feature_engineering.sas
* Purpose: Create features for fraud detection
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Calculate velocity features */
%macro CALCULATE_VELOCITY(inds=, outds=, window_days=7);

    /* Sort by customer and date */
    PROC SORT DATA=&inds;
        BY customer_id transaction_date_sas transaction_time;
    RUN;

    /* Calculate velocity features */
    DATA &outds;
        SET &inds;
        BY customer_id;

        /* Retain variables for calculations */
        RETAIN txn_count_&window_days.d 0
               txn_amount_&window_days.d 0
               last_txn_date .;

        /* Reset on new customer */
        if FIRST.customer_id then do;
            txn_count_&window_days.d = 0;
            txn_amount_&window_days.d = 0;
            last_txn_date = .;
        end;

        /* Calculate days since last transaction */
        if NOT missing(last_txn_date) then 
            days_since_last_txn = transaction_date_sas - last_txn_date;
        else 
            days_since_last_txn = .;

        /* Update counters (rolling window) */
        if NOT missing(last_txn_date) then do;
            if days_since_last_txn <= &window_days then do;
                txn_count_&window_days.d + 1;
                txn_amount_&window_days.d + amount;
            end;
            else do;
                txn_count_&window_days.d = 1;
                txn_amount_&window_days.d = amount;
            end;
        end;
        else do;
            txn_count_&window_days.d = 1;
            txn_amount_&window_days.d = amount;
        end;

        /* Update last transaction date */
        last_txn_date = transaction_date_sas;

        /* Calculate average transaction amount in window */
        if txn_count_&window_days.d > 0 then 
            avg_txn_amount_&window_days.d = txn_amount_&window_days.d / txn_count_&window_days.d;
        else 
            avg_txn_amount_&window_days.d = 0;

        DROP last_txn_date;

    RUN;

    %PUT NOTE: Calculated velocity features for &window_days day window;

%mend CALCULATE_VELOCITY;

/* MACRO 2: Calculate amount deviation */
%macro CALCULATE_AMOUNT_DEVIATION(inds=, outds=);

    /* Calculate customer statistics */
    PROC MEANS DATA=&inds NOPRINT;
        BY customer_id;
        VAR amount;
        OUTPUT OUT=customer_stats
            MEAN=customer_avg_amount
            STD=customer_std_amount
            N=customer_txn_count;
    RUN;

    /* Merge statistics back */
    PROC SQL;
        CREATE TABLE &outds AS
        SELECT 
            a.*,
            b.customer_avg_amount,
            b.customer_std_amount,
            b.customer_txn_count,
            /* Calculate z-score */
            CASE 
                WHEN b.customer_std_amount > 0 THEN
                    (a.amount - b.customer_avg_amount) / b.customer_std_amount
                ELSE 0
            END AS amount_zscore,
            /* Calculate percentage deviation */
            CASE
                WHEN b.customer_avg_amount > 0 THEN
                    ((a.amount - b.customer_avg_amount) / b.customer_avg_amount) * 100
                ELSE 0
            END AS amount_pct_deviation
        FROM &inds a
        LEFT JOIN customer_stats b
        ON a.customer_id = b.customer_id;
    QUIT;

    %PUT NOTE: Calculated amount deviation features;

%mend CALCULATE_AMOUNT_DEVIATION;

/* MACRO 3: Create time-based features */
%macro CREATE_TIME_FEATURES(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Extract time components */
        txn_hour = HOUR(transaction_time);
        txn_day_of_week = WEEKDAY(transaction_date_sas);
        txn_day_of_month = DAY(transaction_date_sas);
        txn_month = MONTH(transaction_date_sas);

        /* Create time-of-day categories */
        length time_of_day $20;
        if txn_hour >= 0 AND txn_hour < 6 then time_of_day = 'NIGHT';
        else if txn_hour >= 6 AND txn_hour < 12 then time_of_day = 'MORNING';
        else if txn_hour >= 12 AND txn_hour < 18 then time_of_day = 'AFTERNOON';
        else time_of_day = 'EVENING';

        /* Create weekend flag */
        is_weekend = (txn_day_of_week IN (1, 7));  /* Sunday=1, Saturday=7 */

        /* Create unusual hour flag */
        is_unusual_hour = (txn_hour >= 0 AND txn_hour < 6);

    RUN;

    %PUT NOTE: Created time-based features;

%mend CREATE_TIME_FEATURES;

/* MACRO 4: Create location features */
%macro CREATE_LOCATION_FEATURES(inds=, outds=);

    /* Calculate country transaction counts */
    PROC SQL;
        CREATE TABLE country_counts AS
        SELECT 
            country_code_clean,
            COUNT(*) AS country_txn_count
        FROM &inds
        GROUP BY country_code_clean;
    QUIT;

    /* Merge back and create features */
    PROC SQL;
        CREATE TABLE &outds AS
        SELECT 
            a.*,
            b.country_txn_count,
            /* Flag for rare countries */
            CASE 
                WHEN b.country_txn_count < 10 THEN 1
                ELSE 0
            END AS is_rare_country,
            /* Check if international transaction */
            CASE
                WHEN a.country_code_clean NE 'US' THEN 1
                ELSE 0
            END AS is_international
        FROM &inds a
        LEFT JOIN country_counts b
        ON a.country_code_clean = b.country_code_clean;
    QUIT;

    %PUT NOTE: Created location-based features;

%mend CREATE_LOCATION_FEATURES;

/* Execute feature engineering pipeline */
%CALCULATE_VELOCITY(
    inds=&input_lib..transactions_final,
    outds=&output_lib..txn_with_velocity,
    window_days=7
);

%CALCULATE_AMOUNT_DEVIATION(
    inds=&output_lib..txn_with_velocity,
    outds=&output_lib..txn_with_deviation
);

%CREATE_TIME_FEATURES(
    inds=&output_lib..txn_with_deviation,
    outds=&output_lib..txn_with_time_features
);

%CREATE_LOCATION_FEATURES(
    inds=&output_lib..txn_with_time_features,
    outds=&output_lib..transactions_engineered
);

/* Display sample of engineered features */
PROC PRINT DATA=&output_lib..transactions_engineered(OBS=10);
    VAR transaction_id customer_id amount 
        txn_count_7d avg_txn_amount_7d amount_zscore
        time_of_day is_weekend is_unusual_hour;
    TITLE 'Sample of Engineered Features';
RUN;
```

## Content of 04_rule_based_detection
```sas
/*******************************************************************************
* Program: 04_rule_based_detection.sas
* Purpose: Apply rule-based fraud detection logic
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

%let input_lib = WORK;
%let output_lib = WORK;

/* MACRO 1: Define fraud detection rules */
%macro APPLY_FRAUD_RULES(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Initialize rule flags and scores */
        length rule_triggered $200;
        rule_triggered = '';
        rule_score = 0;

        /* RULE 1: High velocity (>10 transactions in 7 days) */
        if txn_count_7d > 10 then do;
            rule_triggered = CATX(', ', rule_triggered, 'HIGH_VELOCITY');
            rule_score = rule_score + 25;
        end;

        /* RULE 2: Large amount deviation (>3 standard deviations) */
        if ABS(amount_zscore) > 3 then do;
            rule_triggered = CATX(', ', rule_triggered, 'AMOUNT_DEVIATION');
            rule_score = rule_score + 30;
        end;

        /* RULE 3: High amount (>$5000) */
        if amount > 5000 then do;
            rule_triggered = CATX(', ', rule_triggered, 'HIGH_AMOUNT');
            rule_score = rule_score + 20;
        end;

        /* RULE 4: Unusual hour transaction */
        if is_unusual_hour = 1 then do;
            rule_triggered = CATX(', ', rule_triggered, 'UNUSUAL_HOUR');
            rule_score = rule_score + 15;
        end;

        /* RULE 5: International transaction */
        if is_international = 1 then do;
            rule_triggered = CATX(', ', rule_triggered, 'INTERNATIONAL');
            rule_score = rule_score + 10;
        end;

        /* RULE 6: Rare country */
        if is_rare_country = 1 then do;
            rule_triggered = CATX(', ', rule_triggered, 'RARE_COUNTRY');
            rule_score = rule_score + 15;
        end;

        /* RULE 7: Multiple transactions in short time */
        if days_since_last_txn < 0.042 then do;  /* Less than 1 hour */
            rule_triggered = CATX(', ', rule_triggered, 'RAPID_SUCCESSION');
            rule_score = rule_score + 25;
        end;

        /* RULE 8: Round amount (potentially suspicious) */
        if MOD(amount, 100) = 0 AND amount >= 1000 then do;
            rule_triggered = CATX(', ', rule_triggered, 'ROUND_AMOUNT');
            rule_score = rule_score + 10;
        end;

        /* Calculate final rule-based risk level */
        length rule_risk_level $10;
        if rule_score >= 75 then rule_risk_level = 'CRITICAL';
        else if rule_score >= 50 then rule_risk_level = 'HIGH';
        else if rule_score >= 25 then rule_risk_level = 'MEDIUM';
        else rule_risk_level = 'LOW';

        /* Flag for investigation */
        is_suspicious = (rule_score >= 50);

    RUN;

    %PUT NOTE: Applied fraud detection rules;

%mend APPLY_FRAUD_RULES;

/* MACRO 2: Generate rule-based alerts */
%macro GENERATE_RULE_ALERTS(inds=, outds=, threshold=50);

    /* Filter suspicious transactions */
    DATA &outds;
        SET &inds;
        WHERE rule_score >= &threshold;
    RUN;

    /* Sort by risk score */
    PROC SORT DATA=&outds;
        BY DESCENDING rule_score transaction_date_sas;
    RUN;

    /* Count alerts by risk level */
    PROC FREQ DATA=&outds;
        TABLES rule_risk_level / NOCUM;
        TITLE "Rule-Based Alerts by Risk Level (Score >= &threshold)";
    RUN;

    /* Log alert counts */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :alert_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %let alert_rate = %SYSEVALF((&alert_count / &total_count) * 100);
    %PUT NOTE: Generated &alert_count alerts (&alert_rate% of transactions);

%mend GENERATE_RULE_ALERTS;

/* MACRO 3: Create rule summary report */
%macro RULE_SUMMARY_REPORT(inds=);

    /* Count by rule */
    PROC SQL;
        CREATE TABLE rule_summary AS
        SELECT 
            'HIGH_VELOCITY' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'HIGH_VELOCITY') > 0 THEN 1 ELSE 0 END) AS trigger_count
        FROM &inds
        UNION ALL
        SELECT 
            'AMOUNT_DEVIATION' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'AMOUNT_DEVIATION') > 0 THEN 1 ELSE 0 END)
        FROM &inds
        UNION ALL
        SELECT 
            'HIGH_AMOUNT' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'HIGH_AMOUNT') > 0 THEN 1 ELSE 0 END)
        FROM &inds
        UNION ALL
        SELECT 
            'UNUSUAL_HOUR' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'UNUSUAL_HOUR') > 0 THEN 1 ELSE 0 END)
        FROM &inds
        UNION ALL
        SELECT 
            'INTERNATIONAL' AS rule_name,
            SUM(CASE WHEN INDEX(rule_triggered, 'INTERNATIONAL') > 0 THEN 1 ELSE 0 END)
        FROM &inds;
    QUIT;

    /* Display summary */
    PROC PRINT DATA=rule_summary;
        TITLE 'Fraud Rule Trigger Summary';
    RUN;

%mend RULE_SUMMARY_REPORT;

/* Execute rule-based detection */
%APPLY_FRAUD_RULES(
    inds=&input_lib..transactions_engineered,
    outds=&output_lib..transactions_with_rules
);

%GENERATE_RULE_ALERTS(
    inds=&output_lib..transactions_with_rules,
    outds=&output_lib..rule_based_alerts,
    threshold=50
);

%RULE_SUMMARY_REPORT(
    inds=&output_lib..transactions_with_rules
);

/* Display top alerts */
PROC PRINT DATA=&output_lib..rule_based_alerts(OBS=20);
    VAR transaction_id customer_id amount rule_score rule_risk_level rule_triggered;
    TITLE 'Top 20 Rule-Based Fraud Alerts';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

## Content of 01_transaction_data_import
```sas
/*******************************************************************************
* Program: 01_transaction_data_import.sas
* Purpose: Import transaction data from CSV file and perform initial validation
* Author: Generated Example
* Date: 2025-12-01
*******************************************************************************/

/* Macro Variables */
%let input_path = /data/raw;
%let output_lib = WORK;
%let transaction_file = transactions.csv;

/* MACRO 1: Import transaction data */
%macro IMPORT_TRANSACTIONS(filepath=, outds=);

    /* Import CSV file */
    PROC IMPORT 
        DATAFILE="&filepath"
        OUT=&outds
        DBMS=CSV
        REPLACE;
        GETNAMES=YES;
    RUN;

    /* Log import results */
    %PUT NOTE: Imported &filepath to &outds;

    /* Check for errors */
    %if &SYSERR > 0 %then %do;
        %PUT ERROR: Import failed with SYSERR=&SYSERR;
        %ABORT;
    %end;

%mend IMPORT_TRANSACTIONS;

/* MACRO 2: Validate imported data */
%macro VALIDATE_DATA(inds=, outds=);

    DATA &outds;
        SET &inds;

        /* Create validation flags */
        length validation_status $20;

        /* Check for missing values */
        if missing(transaction_id) then validation_status = 'MISSING_ID';
        else if missing(customer_id) then validation_status = 'MISSING_CUSTOMER';
        else if missing(amount) then validation_status = 'MISSING_AMOUNT';
        else if missing(transaction_date) then validation_status = 'MISSING_DATE';
        else if amount <= 0 then validation_status = 'INVALID_AMOUNT';
        else validation_status = 'VALID';

        /* Keep only valid records */
        if validation_status = 'VALID';

    RUN;

    /* Log validation results */
    PROC SQL NOPRINT;
        SELECT COUNT(*) INTO :valid_count FROM &outds;
        SELECT COUNT(*) INTO :total_count FROM &inds;
    QUIT;

    %PUT NOTE: Validated &valid_count of &total_count records;

%mend VALIDATE_DATA;

/* Execute macros */
%IMPORT_TRANSACTIONS(
    filepath=&input_path/&transaction_file,
    outds=&output_lib..raw_transactions
);

%VALIDATE_DATA(
    inds=&output_lib..raw_transactions,
    outds=&output_lib..transactions_validated
);

/* Display results */
PROC PRINT DATA=&output_lib..transactions_validated(OBS=10);
    TITLE 'First 10 Validated Transactions';
RUN;
```

